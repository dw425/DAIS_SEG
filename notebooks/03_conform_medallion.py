# Databricks notebook source
# MAGIC %md
# MAGIC # Pillar 3 — Conform to Medallion Architecture
# MAGIC
# MAGIC Maps synthetic Delta Tables through the **Bronze → Silver → Gold** medallion
# MAGIC architecture using DLT-style expectations. Establishes the conformed target
# MAGIC that all workstreams validate against.
# MAGIC
# MAGIC ### Prerequisites
# MAGIC - Synthetic tables generated by notebook 02
# MAGIC - `dais-seg` wheel installed on the cluster

# COMMAND ----------

# MAGIC %pip install /Workspace/Users/$current_user/dais-seg-*.whl --quiet

# COMMAND ----------

dbutils.widgets.text("blueprint_id", "", "Blueprint ID (optional, for schema enforcement)")
dbutils.widgets.text("catalog", "dais_seg", "Catalog")
dbutils.widgets.text("source_schema", "synthetic", "Source Schema (synthetic tables)")

# COMMAND ----------

blueprint_id = dbutils.widgets.get("blueprint_id")
catalog = dbutils.widgets.get("catalog")
source_schema = dbutils.widgets.get("source_schema")

print(f"Source: {catalog}.{source_schema}")
print(f"Blueprint: {blueprint_id or 'none (schema enforcement skipped)'}")

# COMMAND ----------

from dais_seg.config import SEGConfig, set_config

config = SEGConfig(catalog=catalog, schema="blueprints")
set_config(config)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Step 1: Load Blueprint (if provided)

# COMMAND ----------

blueprint = None
if blueprint_id:
    from dais_seg.profiler import BlueprintGenerator
    bp_loader = BlueprintGenerator(spark)
    blueprint = bp_loader.load_blueprint(blueprint_id)
    print(f"Blueprint loaded: {len(blueprint['tables'])} tables")
else:
    print("No blueprint specified — schema enforcement will be skipped")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Step 2: Run Medallion Pipeline

# COMMAND ----------

from dais_seg.conformer import MedallionPipeline

pipeline = MedallionPipeline(
    spark,
    source_catalog=catalog,
    source_schema=source_schema,
    target_catalog=catalog,
)

result = pipeline.run(blueprint=blueprint)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Step 3: Results Summary

# COMMAND ----------

print("=== BRONZE ===")
for table, count in result.bronze.row_counts.items():
    print(f"  {table}: {count:,} rows")

print("\n=== SILVER ===")
for table, count in result.silver.row_counts.items():
    print(f"  {table}: {count:,} rows")

print("\n=== GOLD ===")
for table, count in result.gold.row_counts.items():
    print(f"  {table}: {count:,} rows")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Quality Violations

# COMMAND ----------

violations = result.quality_violations
if violations:
    display(spark.createDataFrame(violations))
else:
    print("No quality violations detected")

# COMMAND ----------

print(f"\n✅ Medallion pipeline complete: {result.tables_processed} tables")
print(f"   Bronze: {len(result.bronze.tables)} tables in {catalog}.{result.bronze.schema}")
print(f"   Silver: {len(result.silver.tables)} tables in {catalog}.{result.silver.schema}")
print(f"   Gold:   {len(result.gold.tables)} tables in {catalog}.{result.gold.schema}")
print(f"   Quality violations: {len(violations)}")
print(f"\nNext step: Run notebook 04_validate_workspace")
