<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>SEG — Synthetic Environment Generator Demo</title>
<style>
:root {
  --bg: #0e1117; --surface: #1a1d27; --surface2: #262730;
  --border: #363842; --text: #fafafa; --text2: #808495;
  --primary: #ff4b4b; --primary-hover: #ff6b6b;
  --green: #21c354; --amber: #faca15; --red: #ff4b4b;
  --blue: #1d4ed8; --font: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  --mono: 'SF Mono', 'Fira Code', monospace;
}
* { box-sizing: border-box; margin: 0; padding: 0; }
body { background: var(--bg); color: var(--text); font-family: var(--font); line-height: 1.6; }
.container { max-width: 1200px; margin: 0 auto; padding: 20px; }
h1 { font-size: 2rem; margin-bottom: 4px; }
h2 { font-size: 1.4rem; margin: 24px 0 12px; border-bottom: 1px solid var(--border); padding-bottom: 8px; }
h3 { font-size: 1.1rem; margin: 16px 0 8px; }
.caption { color: var(--text2); font-size: 0.9rem; margin-bottom: 20px; }
.tabs { display: grid; grid-template-columns: repeat(5, 1fr); gap: 0; margin-bottom: 24px; }
.tab { padding: 10px 8px; cursor: pointer; color: var(--text2); border-bottom: 2px solid var(--border);
  white-space: nowrap; font-size: 0.88rem; transition: all 0.2s; text-align: center; }
.tab:hover { color: var(--text); }
.tab.active { color: var(--primary); border-bottom-color: var(--primary); font-weight: 600; }
.panel { display: none; } .panel.active { display: block; }
.row { display: flex; gap: 20px; flex-wrap: wrap; }
.col { flex: 1; min-width: 280px; }
.col-3 { flex: 1; min-width: 200px; }
.metrics { display: flex; gap: 16px; flex-wrap: wrap; margin: 16px 0; }
.metric { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 16px 20px; min-width: 140px; flex: 1; }
.metric .label { font-size: 0.8rem; color: var(--text2); text-transform: uppercase; letter-spacing: 0.5px; }
.metric .value { font-size: 1.8rem; font-weight: 700; margin-top: 4px; }
.metric .delta { font-size: 0.85rem; color: var(--red); }
textarea, input[type=text], input[type=number], select {
  width: 100%; padding: 10px 14px; background: var(--surface); border: 1px solid var(--border);
  border-radius: 6px; color: var(--text); font-family: var(--mono); font-size: 0.9rem; resize: vertical; }
textarea:focus, input:focus { outline: none; border-color: var(--primary); }
textarea { min-height: 200px; }
label { display: block; font-size: 0.85rem; color: var(--text2); margin-bottom: 6px; font-weight: 500; }
.btn { padding: 10px 24px; border: none; border-radius: 6px; cursor: pointer; font-size: 0.95rem;
  font-weight: 600; transition: all 0.2s; display: inline-flex; align-items: center; gap: 8px; }
.btn-primary { background: var(--primary); color: white; }
.btn-primary:hover { background: var(--primary-hover); }
.btn-secondary { background: var(--surface2); color: var(--text); border: 1px solid var(--border); }
.btn-secondary:hover { background: var(--border); }
.btn:disabled { opacity: 0.5; cursor: not-allowed; }
.alert { padding: 12px 16px; border-radius: 6px; margin: 12px 0; font-size: 0.9rem; }
.alert-info { background: #1e3a5f; border: 1px solid #2563eb; color: #93c5fd; }
.alert-success { background: #14532d; border: 1px solid var(--green); color: #86efac; }
.alert-warn { background: #713f12; border: 1px solid var(--amber); color: #fde68a; }
.alert-error { background: #450a0a; border: 1px solid var(--red); color: #fca5a5; }
table { width: 100%; border-collapse: collapse; margin: 12px 0; font-size: 0.85rem; }
th { text-align: left; padding: 8px 12px; background: var(--surface2); color: var(--text2);
  font-weight: 600; text-transform: uppercase; font-size: 0.75rem; letter-spacing: 0.5px;
  border-bottom: 2px solid var(--border); }
td { padding: 8px 12px; border-bottom: 1px solid var(--border); }
tr:hover td { background: var(--surface); }
.expander { border: 1px solid var(--border); border-radius: 8px; margin: 12px 0; overflow: hidden; }
.expander-header { padding: 12px 16px; cursor: pointer; display: flex; justify-content: space-between;
  align-items: center; background: var(--surface); font-weight: 500; }
.expander-header:hover { background: var(--surface2); }
.expander-body { padding: 16px; display: none; border-top: 1px solid var(--border); }
.expander.open .expander-body { display: block; }
.expander-arrow { transition: transform 0.2s; }
.expander.open .expander-arrow { transform: rotate(90deg); }
.badge { display: inline-block; padding: 2px 10px; border-radius: 12px; font-size: 0.8rem; font-weight: 600; }
.badge-green { background: #14532d; color: #86efac; }
.badge-amber { background: #713f12; color: #fde68a; }
.badge-red { background: #450a0a; color: #fca5a5; }
.progress-bar { height: 8px; background: var(--surface2); border-radius: 4px; overflow: hidden; margin: 6px 0; }
.progress-fill { height: 100%; border-radius: 4px; transition: width 0.3s; }
.progress-fill.green { background: var(--green); }
.progress-fill.amber { background: var(--amber); }
.progress-fill.red { background: var(--red); }
code { background: var(--surface2); padding: 2px 6px; border-radius: 4px; font-family: var(--mono); font-size: 0.85rem; }
pre { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 16px;
  overflow-x: auto; font-family: var(--mono); font-size: 0.85rem; margin: 12px 0; }
.score-big { font-size: 3rem; font-weight: 800; text-align: center; padding: 20px; }
.table-scroll { overflow-x: auto; }
.file-upload { border: 2px dashed var(--border); border-radius: 8px; padding: 40px 20px; text-align: center;
  cursor: pointer; transition: border-color 0.2s; }
.file-upload:hover { border-color: var(--primary); }
.file-upload input { display: none; }
.divider { border: none; border-top: 1px solid var(--border); margin: 24px 0; }
.hidden { display: none; }
@media (max-width: 768px) { .row { flex-direction: column; } .col, .col-3 { min-width: 100%; } }
/* Tab status indicators */
.tab { position: relative; }
.tab .check { display: none; margin-left: 6px; color: var(--green); font-size: 0.85rem; }
.tab.done .check { display: inline-block; animation: pop 0.4s ease; }
.tab.locked { opacity: 0.4; pointer-events: none; }
.tab .spinner-sm { display: none; width: 12px; height: 12px; border: 2px solid var(--border);
  border-top: 2px solid var(--primary); border-radius: 50%; animation: spin 0.6s linear infinite;
  margin-left: 6px; vertical-align: middle; }
.tab.processing .spinner-sm { display: inline-block; }
@keyframes pop { 0%{transform:scale(0)} 60%{transform:scale(1.3)} 100%{transform:scale(1)} }
@keyframes spin { to { transform: rotate(360deg); } }
/* Source system grid */
.sources-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(140px, 1fr)); gap: 8px; margin: 16px 0; }
.source-badge { background: var(--surface); border: 1px solid var(--border); border-radius: 6px;
  padding: 8px 12px; text-align: center; border-top: 3px solid var(--border); transition: border-color 0.2s; }
.source-badge:hover { border-color: var(--primary); }
.source-badge .src-name { font-weight: 600; font-size: 0.85rem; }
.source-badge .src-type { color: var(--text2); font-size: 0.7rem; text-transform: uppercase; letter-spacing: 0.3px; }
.detected-source { display: inline-flex; align-items: center; gap: 8px; padding: 6px 14px;
  background: var(--surface); border: 1px solid var(--green); border-radius: 6px; margin: 8px 0; font-size: 0.9rem; }
.detected-source .dot { width: 8px; height: 8px; border-radius: 50%; background: var(--green); }
/* Tier Diagram */
.tier-diagram { position: relative; overflow: auto; border: 1px solid var(--border); border-radius: 8px; background: var(--bg); min-height: 200px; margin: 16px 0; }
.tier-diagram svg.tier-svg { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; z-index: 1; }
.tier-band { padding: 16px 20px; border-bottom: 1px solid var(--border); position: relative; z-index: 2; }
.tier-band:last-child { border-bottom: none; }
.tier-band-label { font-size: 0.7rem; text-transform: uppercase; letter-spacing: 1px; font-weight: 700; margin-bottom: 10px; opacity: 0.8; }
.tier-nodes { display: flex; flex-wrap: wrap; gap: 12px; justify-content: center; }
.tier-node { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 10px 16px;
  min-width: 120px; max-width: 200px; text-align: center; cursor: pointer; transition: all 0.2s; position: relative; z-index: 3; }
.tier-node:hover { border-color: var(--primary); transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0,0,0,0.3); }
.tier-node.selected { border-color: var(--primary); box-shadow: 0 0 0 2px rgba(255,75,75,0.3); }
.tier-node.highlighted { border-color: var(--green); }
.tier-node.dimmed { opacity: 0.3; }
.tier-node .node-name { font-weight: 600; font-size: 0.85rem; word-break: break-all; }
.tier-node .node-meta { font-size: 0.7rem; color: var(--text2); margin-top: 4px; }
.tier-node .node-badge { position: absolute; top: -6px; right: -6px; background: var(--primary); color: white;
  border-radius: 10px; padding: 1px 6px; font-size: 0.65rem; font-weight: 700; }
.tier-node .node-badge.green { background: var(--green); }
.tier-node .node-badge.amber { background: var(--amber); color: #000; }
.tier-node .node-badge.red { background: var(--red); }
/* Session nodes — numbered circle + colored stat badges */
.tier-node .node-seq { display: inline-flex; align-items: center; justify-content: center; width: 22px; height: 22px;
  border-radius: 50%; background: var(--primary); color: white; font-size: 0.7rem; font-weight: 700; margin-bottom: 4px; }
.tier-node .node-stats { display: flex; gap: 4px; justify-content: center; margin-top: 6px; flex-wrap: wrap; }
.tier-node .node-stats .ns { padding: 1px 5px; border-radius: 3px; font-size: 0.6rem; font-weight: 700; }
.ns-tx { background: #3B82F6; color: white; }
.ns-ext { background: #21C354; color: white; }
.ns-lkp { background: #EAB308; color: #000; }
/* Table output nodes — smaller, distinct style */
.tier-node.table-output { background: var(--surface2); border-style: dashed; min-width: 100px; max-width: 180px; padding: 8px 12px; }
.tier-node.table-output .node-name { font-size: 0.75rem; }
.tier-node.table-output .node-class { font-size: 0.6rem; text-transform: uppercase; letter-spacing: 0.5px; margin-top: 2px; }
/* Conflict gate nodes — red border, warning icon */
.tier-node.conflict-gate { border-color: var(--red); background: #1a0a0a; min-width: 140px; }
.tier-node.conflict-gate .node-name { color: var(--red); }
/* Connection density sidebar */
.tier-diagram-wrapper { display: flex; gap: 0; }
.tier-diagram-main { flex: 1; min-width: 0; }
.tier-density-sidebar { width: 220px; flex-shrink: 0; border-left: 1px solid var(--border); background: var(--surface);
  padding: 12px; overflow-y: auto; max-height: 800px; font-size: 0.7rem; }
.tier-density-sidebar h4 { font-size: 0.75rem; margin: 0 0 8px; color: var(--text2); text-transform: uppercase; letter-spacing: 0.5px; }
.density-row { display: flex; align-items: center; gap: 6px; margin: 3px 0; }
.density-bar { height: 6px; border-radius: 3px; flex-shrink: 0; min-width: 2px; }
.density-label { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; color: var(--text2); max-width: 120px; }
@media (max-width: 900px) { .tier-density-sidebar { display: none; } .tier-diagram-wrapper { flex-direction: column; } }
.node-detail { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 16px;
  margin-top: 12px; font-size: 0.85rem; }
.node-detail h4 { margin: 0 0 8px; }
.diagram-legend { display: flex; gap: 16px; flex-wrap: wrap; margin: 8px 0; font-size: 0.75rem; color: var(--text2); }
.diagram-legend span { display: flex; align-items: center; gap: 4px; }
.diagram-legend .leg-line { width: 20px; height: 2px; border-radius: 1px; }
/* Cycle indicators */
.tier-node.in-cycle { border-color: #EF4444; animation: cyclePulse 2s ease-in-out infinite; }
@keyframes cyclePulse { 0%,100% { box-shadow: 0 0 0 0 rgba(239,68,68,0.4); } 50% { box-shadow: 0 0 0 6px rgba(239,68,68,0); } }
.cycle-badge { position: absolute; top: -6px; left: -6px; background: #EF4444; color: white;
  border-radius: 50%; width: 18px; height: 18px; font-size: 0.6rem; display: flex;
  align-items: center; justify-content: center; z-index: 4; }
/* Expandable process groups */
.tier-node .expand-indicator { font-size: 0.6rem; color: var(--text2); margin-top: 4px; }
.tier-node.expanded { border-color: var(--primary); box-shadow: 0 0 0 2px rgba(255,75,75,0.2); }
.tier-sub-band { padding: 8px 20px 12px 40px; border-bottom: 1px solid var(--border);
  background: rgba(255,255,255,0.02); position: relative; z-index: 2; }
.tier-sub-band .tier-band-label { font-size: 0.6rem; opacity: 0.6; margin-bottom: 6px; }
.tier-sub-band .tier-nodes { gap: 8px; }
.tier-sub-band .tier-node { min-width: 100px; max-width: 160px; padding: 6px 10px; }
.tier-sub-band .tier-node .node-name { font-size: 0.75rem; }
/* Progressive route tracing */
.tier-node.path-selected { border-color: #FACA15; box-shadow: 0 0 0 3px rgba(250,202,21,0.4); z-index: 10; }
.tier-node.path-selected::before { content: '\2713'; position: absolute; top: -8px; left: -8px;
  width: 18px; height: 18px; border-radius: 50%; background: #FACA15; color: #000;
  font-size: 0.65rem; font-weight: 700; display: flex; align-items: center; justify-content: center; z-index: 5; }
.tier-node.path-member { border-color: #FACA15; background: rgba(250,202,21,0.08); }
.tier-node.path-dimmed { opacity: 0.12; }
.path-trace-toast { position: fixed; bottom: 24px; left: 50%; transform: translateX(-50%);
  background: var(--surface2); border: 1px solid var(--border); border-radius: 8px;
  padding: 10px 20px; font-size: 0.85rem; color: var(--text); z-index: 1000;
  display: none; align-items: center; gap: 12px; box-shadow: 0 4px 24px rgba(0,0,0,0.5); }
.path-trace-toast .toast-hint { color: var(--text2); font-size: 0.75rem; }
.path-trace-toast .toast-clear { cursor: pointer; color: var(--primary); font-weight: 600; font-size: 0.8rem; }
/* Sidebar active filter */
.density-row { cursor: pointer; padding: 2px 4px; border-radius: 4px; transition: background 0.15s; }
.density-row:hover { background: rgba(255,255,255,0.06); }
.density-row.filter-active { background: rgba(250,202,21,0.15); border: 1px solid rgba(250,202,21,0.4); }
.density-row.filter-dimmed { opacity: 0.3; }
.sidebar-filter-hint { font-size: 0.6rem; color: var(--text2); margin-bottom: 6px; font-style: italic; }
.sidebar-clear-btn { font-size: 0.65rem; color: var(--primary); cursor: pointer; margin-top: 6px;
  display: none; text-align: center; padding: 4px; border-radius: 4px; }
.sidebar-clear-btn:hover { background: rgba(255,75,75,0.1); }
/* Notebook preview */
.notebook-preview { background: var(--surface); border: 1px solid var(--border); border-radius: 8px;
  max-height: 600px; overflow-y: auto; margin: 12px 0; }
.notebook-cell { padding: 10px 16px; border-bottom: 1px solid var(--border); font-family: 'SF Mono',Monaco,Consolas,monospace;
  font-size: 0.78rem; line-height: 1.5; white-space: pre-wrap; word-break: break-word; }
.notebook-cell:last-child { border-bottom: none; }
.notebook-cell.cell-md { background: rgba(59,130,246,0.06); color: #93c5fd; }
.notebook-cell.cell-sql { background: rgba(168,85,247,0.06); }
.notebook-cell.cell-code { background: var(--surface); }
.notebook-cell .cell-label { display: inline-block; padding: 1px 8px; border-radius: 3px;
  font-size: 0.65rem; font-weight: 700; margin-bottom: 4px; text-transform: uppercase; letter-spacing: 0.5px; }
.cell-label.lb-source { background: #1d3557; color: #93c5fd; }
.cell-label.lb-transform { background: #2d1b4e; color: #c4b5fd; }
.cell-label.lb-sink { background: #14532d; color: #86efac; }
.cell-label.lb-route { background: #422006; color: #fde68a; }
.cell-label.lb-process { background: #1e1b4b; color: #a5b4fc; }
.cell-label.lb-utility { background: #1f2937; color: #9ca3af; }
.cell-label.lb-config { background: #0c4a6e; color: #7dd3fc; }
.cell-label.lb-manual { background: #450a0a; color: #fca5a5; }
/* Gap cards */
.gap-card { background: var(--surface); border: 1px solid var(--border); border-radius: 8px;
  padding: 10px 14px; margin: 6px 0; border-left: 3px solid var(--red); }
.gap-card .gap-title { font-weight: 600; font-size: 0.85rem; margin-bottom: 2px; }
.gap-card .gap-meta { color: var(--text2); font-size: 0.75rem; }
.gap-card .gap-rec { color: var(--amber); font-size: 0.8rem; margin-top: 4px; }
/* Coverage ring */
.coverage-ring { width: 120px; height: 120px; border-radius: 50%; position: relative;
  display: inline-flex; align-items: center; justify-content: center; }
.coverage-ring .ring-text { font-size: 1.6rem; font-weight: 800; z-index: 1; }
/* Mapping table */
.mapping-table { width: 100%; border-collapse: collapse; font-size: 0.78rem; margin: 12px 0; }
.mapping-table th { text-align: left; padding: 6px 10px; border-bottom: 2px solid var(--border);
  font-size: 0.7rem; text-transform: uppercase; color: var(--text2); }
.mapping-table td { padding: 5px 10px; border-bottom: 1px solid var(--border); }
.mapping-table tr.unmapped { opacity: 0.5; }
.conf-badge { padding: 1px 6px; border-radius: 3px; font-size: 0.65rem; font-weight: 700; }
.conf-high { background: rgba(33,195,84,0.2); color: #86efac; }
.conf-med { background: rgba(234,179,8,0.2); color: #fde68a; }
.conf-low { background: rgba(239,68,68,0.2); color: #fca5a5; }
.conf-none { background: rgba(128,132,149,0.15); color: #9ca3af; }
/* Step 8: Comparison Dashboard */
.comparison-donuts { display:flex; gap:32px; justify-content:center; flex-wrap:wrap; margin:24px 0; }
.donut-chart { text-align:center; flex:0 0 160px; }
.donut-chart svg { filter:drop-shadow(0 2px 8px rgba(0,0,0,0.3)); }
.donut-label { font-size:0.85rem; font-weight:600; margin-top:8px; color:var(--text2); text-transform:uppercase; letter-spacing:0.5px; }
.donut-sub { font-size:0.75rem; color:var(--text2); margin-top:2px; }
.match-badge { display:inline-block; padding:1px 8px; border-radius:3px; font-size:0.7rem; font-weight:700; }
.match-exact { background:rgba(33,195,84,0.2); color:#86efac; }
.match-functional { background:rgba(234,179,8,0.2); color:#fde68a; }
.match-gap { background:rgba(239,68,68,0.2); color:#fca5a5; }
.comparison-detail { margin-top:16px; }
.comparison-detail summary { cursor:pointer; font-weight:600; font-size:0.95rem; padding:10px 0; color:var(--text); }
.comparison-detail summary:hover { color:var(--primary); }
.comparison-detail table { width:100%; font-size:0.8rem; }
.comparison-detail td, .comparison-detail th { padding:6px 8px; }
.comparison-detail tr:hover { background:var(--surface2); }
/* Step 9: Dual Execution Simulation */
.sim-progress { background:var(--surface); border:1px solid var(--border); border-radius:8px; padding:16px 20px; margin:16px 0; }
.sim-progress-bar { height:10px; background:var(--surface2); border-radius:5px; overflow:hidden; margin:8px 0; }
.sim-progress-fill { height:100%; border-radius:5px; background:linear-gradient(90deg,var(--primary),#ff8a4b); transition:width 0.4s ease; }
.sim-status { font-size:0.85rem; color:var(--text2); display:flex; justify-content:space-between; align-items:center; }
.sim-status .engine-label { font-weight:600; }
.sim-donuts { display:flex; gap:32px; justify-content:center; flex-wrap:wrap; margin:24px 0; }
.sim-split { display:grid; grid-template-columns:1fr 1fr; gap:0; margin:8px 0; border:1px solid var(--border); border-radius:6px; overflow:hidden; }
.sim-split-header { background:var(--surface2); padding:8px 12px; font-weight:600; font-size:0.8rem; text-transform:uppercase; letter-spacing:0.5px; text-align:center; }
.sim-split-header.nifi-side { border-right:1px solid var(--border); color:#728E9B; }
.sim-split-header.dbx-side { color:var(--primary); }
.sim-split-cell { padding:8px 12px; font-size:0.78rem; font-family:var(--mono); background:var(--surface); border-top:1px solid var(--border); overflow-x:auto; max-height:200px; overflow-y:auto; }
.sim-split-cell.nifi-side { border-right:1px solid var(--border); }
@keyframes simPulse { 0%,100%{opacity:1} 50%{opacity:0.5} }
.sim-running { animation:simPulse 1s ease-in-out infinite; }
/* VirtualEnv */
.sample-card { display:flex; gap:10px; align-items:center; padding:10px 14px; border:1px solid var(--border); border-radius:8px; cursor:pointer; transition:all 0.15s; background:var(--bg1); }
.sample-card:hover { border-color:var(--accent); background:rgba(255,107,53,0.05); transform:translateY(-1px); box-shadow:0 2px 8px rgba(0,0,0,0.1); }
.sample-icon { font-size:1.5rem; flex-shrink:0; width:32px; text-align:center; }
.sample-info { display:flex; flex-direction:column; gap:1px; min-width:0; }
.sample-info strong { font-size:0.85rem; color:var(--text1); }
.sample-info span { font-size:0.75rem; color:var(--text2); }
.sample-tags { font-size:0.7rem !important; color:var(--accent) !important; opacity:0.8; }
.ops-log { max-height:400px; overflow-y:auto; font-family:var(--mono); font-size:0.78rem; }
.ops-log-row { display:grid; grid-template-columns:50px 180px 100px 1fr 80px; gap:4px; padding:3px 0; border-bottom:1px solid var(--border); align-items:center; }
.ops-log-row:hover { background:rgba(255,107,53,0.05); }
.ops-log-row.header { font-weight:700; color:var(--text2); font-size:0.72rem; text-transform:uppercase; border-bottom:2px solid var(--border); }
.ops-action { font-weight:600; font-size:0.75rem; }
.ops-action.file { color:#4285F4; } .ops-action.sql { color:#21C354; } .ops-action.token { color:#FACA15; } .ops-action.signal { color:#FF6D70; } .ops-action.counter { color:#8B5CF6; } .ops-action.queue { color:#29B5E8; }
.resource-dot { display:inline-block; width:8px; height:8px; border-radius:50%; margin-right:4px; vertical-align:middle; }
.resource-dot.used { background:#21C354; } .resource-dot.orphaned { background:#FACA15; } .resource-dot.missing { background:#FF4B4B; }
.manifest-grid { display:grid; grid-template-columns:repeat(auto-fill,minmax(120px,1fr)); gap:8px; margin:8px 0; }
.manifest-stat { text-align:center; padding:8px; border-radius:8px; background:var(--surface2); }
.manifest-stat .num { font-size:1.3rem; font-weight:700; color:var(--accent); }
.manifest-stat .lbl { font-size:0.72rem; color:var(--text2); }
.venv-tree { font-family:var(--mono); font-size:0.82rem; line-height:1.7; padding:8px 0; }
.venv-tree .dir { color:var(--text2); font-weight:600; }
.venv-tree .file { color:var(--accent); }
.venv-tree .venv-badge { display:inline-block; background:var(--surface2); border-radius:4px; padding:1px 6px; font-size:0.72rem; margin-left:6px; }
.action-log { max-height:300px; overflow-y:auto; border:1px solid var(--border); border-radius:6px; margin:8px 0; }
.action-log-entry { display:grid; grid-template-columns:100px 1fr 1fr; gap:8px; padding:6px 10px; border-bottom:1px solid var(--border); font-size:0.78rem; align-items:start; }
.action-log-entry:last-child { border-bottom:none; }
.action-log-entry .action-type { font-weight:600; font-size:0.75rem; text-transform:uppercase; }
.action-log-entry .action-type.file-op { color:#21C354; }
.action-log-entry .action-type.sql-op { color:#6366F1; }
.action-log-entry .action-type.token-op { color:#EAB308; }
.action-log-entry .action-type.signal-op { color:#F97316; }
.action-log-entry .action-type.queue-op { color:#06B6D4; }
.state-diff { display:grid; grid-template-columns:1fr 1fr; gap:16px; margin:12px 0; }
.state-diff-panel { background:var(--bg2); border-radius:8px; padding:12px; }
.state-diff-panel h4 { margin:0 0 8px 0; font-size:0.85rem; color:var(--text2); }
.state-diff-panel pre { font-size:0.72rem; max-height:200px; overflow-y:auto; }
.venv-summary { display:flex; gap:16px; flex-wrap:wrap; margin:12px 0; }
.venv-stat { background:var(--surface); border:1px solid var(--border); border-radius:8px; padding:12px 16px; text-align:center; flex:1; min-width:100px; }
.venv-stat .venv-stat-num { font-size:1.5rem; font-weight:700; color:var(--primary); }
.venv-stat .venv-stat-label { font-size:0.75rem; color:var(--text2); margin-top:4px; }
.conform-check { padding:4px 0; font-size:0.82rem; }
.conform-check .check-icon { margin-right:6px; }
</style>
</head>
<body>
<div class="container">
  <h1>SEG — Synthetic Environment Generator</h1>
  <p class="caption">Upload from 20+ source systems — Oracle, Snowflake, Redshift, Informatica, NiFi, dbt, PySpark, and more — generate a full synthetic environment instantly in your browser</p>

  <div class="tabs" id="tabs">
    <div class="tab active" data-tab="parse">1. Load &amp; Parse<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="blueprint">2. Blueprint<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="generate">3. Generate<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="conform">4. Conform<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="validate">5. Validate<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="notebook">6. Notebook<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="report">7. Report<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="comparison">8. Compare<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="simulate">9. Simulate<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
    <div class="tab locked" data-tab="reportFinal">10. Report<span class="check">&#10003;</span><span class="spinner-sm"></span></div>
  </div>

  <!-- STEP 1: PARSE -->
  <div class="panel active" id="panel-parse">
    <h2>Step 1: Load &amp; Parse Input</h2>
    <h3>Supported Sources</h3>
    <div class="sources-grid">
      <div class="source-badge" style="border-top-color:#4285F4"><div class="src-name">Google BigQuery</div><div class="src-type">Cloud Platform</div></div>
      <div class="source-badge" style="border-top-color:#FF9900"><div class="src-name">AWS Redshift</div><div class="src-type">Data Warehouse</div></div>
      <div class="source-badge" style="border-top-color:#FF4A00"><div class="src-name">Informatica</div><div class="src-type">ETL &amp; Integration</div></div>
      <div class="source-badge" style="border-top-color:#29B5E8"><div class="src-name">Snowflake</div><div class="src-type">Data Cloud</div></div>
      <div class="source-badge" style="border-top-color:#F37440"><div class="src-name">Teradata</div><div class="src-type">Enterprise DW</div></div>
      <div class="source-badge" style="border-top-color:#FF3621"><div class="src-name">Databricks</div><div class="src-type">Unity Catalog</div></div>
      <div class="source-badge" style="border-top-color:#0FAAFF"><div class="src-name">SAP HANA</div><div class="src-type">ERP / BW</div></div>
      <div class="source-badge" style="border-top-color:#0078D4"><div class="src-name">Azure Synapse</div><div class="src-type">Analytics</div></div>
      <div class="source-badge" style="border-top-color:#CC2927"><div class="src-name">SQL Server</div><div class="src-type">Microsoft SQL</div></div>
      <div class="source-badge" style="border-top-color:#F80000"><div class="src-name">Oracle</div><div class="src-type">Database</div></div>
      <div class="source-badge" style="border-top-color:#4169E1"><div class="src-name">PostgreSQL</div><div class="src-type">Database</div></div>
      <div class="source-badge" style="border-top-color:#4479A1"><div class="src-name">MySQL</div><div class="src-type">Database</div></div>
      <div class="source-badge" style="border-top-color:#FF694B"><div class="src-name">dbt</div><div class="src-type">Transformation</div></div>
      <div class="source-badge" style="border-top-color:#E25A1C"><div class="src-name">PySpark</div><div class="src-type">Spark Schema</div></div>
      <div class="source-badge" style="border-top-color:#DC382D"><div class="src-name">Scala / Spark</div><div class="src-type">Case Classes</div></div>
      <div class="source-badge" style="border-top-color:#FF6D70"><div class="src-name">Talend</div><div class="src-type">Data Integration</div></div>
      <div class="source-badge" style="border-top-color:#728E9B"><div class="src-name">Apache NiFi</div><div class="src-type">Flow Definition</div></div>
      <div class="source-badge" style="border-top-color:#3ECF8E"><div class="src-name">Avro / Protobuf</div><div class="src-type">Schema Files</div></div>
      <div class="source-badge" style="border-top-color:#8B5CF6"><div class="src-name">Dependency Graph</div><div class="src-type">Session Lineage</div></div>
    </div>
    <div class="row">
      <div class="col">
        <h3>Upload File</h3>
        <div class="file-upload" id="fileDropZone">
          <p>Drop a file here or click to browse</p>
          <p style="color:var(--text2);font-size:0.85rem">SQL, DDL, CSV, JSON, YAML, XML, Avro, Protobuf, PySpark, Scala, NiFi, dbt</p>
          <input type="file" id="fileInput" accept=".sql,.ddl,.hql,.bteq,.psql,.csv,.tsv,.json,.avsc,.yaml,.yml,.xml,.py,.scala,.proto">
        </div>
        <div id="fileName" class="alert alert-info hidden" style="margin-top:12px"></div>
      </div>
      <div class="col">
        <h3>Paste Text</h3>
        <textarea id="pasteInput" placeholder="CREATE TABLE customers (
  id INT PRIMARY KEY,
  name VARCHAR(100) NOT NULL,
  email VARCHAR(200),
  status VARCHAR(20) CHECK (status IN ('active','inactive'))
);"></textarea>
      </div>
    </div>
    <div style="margin-top:16px;display:flex;gap:8px;flex-wrap:wrap;align-items:center">
      <button class="btn btn-primary" onclick="parseInput()">Parse Input</button>
    </div>
    <div style="margin-top:20px;border:1px solid var(--border);border-radius:12px;padding:16px;background:var(--bg2)">
      <h3 style="margin:0 0 4px 0;font-size:0.95rem">Sample Files — Click to Load &amp; Run</h3>
      <p style="color:var(--text2);font-size:0.8rem;margin:0 0 12px 0">Pre-built samples that demonstrate the full pipeline. Each one auto-parses and runs all steps.</p>
      <div style="display:grid;grid-template-columns:repeat(auto-fill,minmax(220px,1fr));gap:8px">
        <div class="sample-card" onclick="loadSampleFlow('etl')">
          <div class="sample-icon">&#128640;</div>
          <div class="sample-info"><strong>ETL Pipeline</strong><span>NiFi XML &bull; 9 processors</span><span class="sample-tags">GetFile, SQL, Route, PutFile</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFlow('streaming')">
          <div class="sample-icon">&#9889;</div>
          <div class="sample-info"><strong>Streaming IoT</strong><span>NiFi XML &bull; 10 processors</span><span class="sample-tags">Kafka, JSON, Merge, HDFS</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFlow('full')">
          <div class="sample-icon">&#127981;</div>
          <div class="sample-info"><strong>Manufacturing Migration</strong><span>NiFi XML &bull; 17 processors</span><span class="sample-tags">ListFile, SFTP, Wait/Notify, SQL</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFile('samples/ecommerce_schema.sql','ecommerce_schema.sql')">
          <div class="sample-icon">&#128722;</div>
          <div class="sample-info"><strong>E-Commerce Warehouse</strong><span>SQL DDL &bull; 8 tables</span><span class="sample-tags">PostgreSQL, FKs, constraints</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFile('samples/healthcare_warehouse.sql','healthcare_warehouse.sql')">
          <div class="sample-icon">&#127973;</div>
          <div class="sample-info"><strong>Healthcare Analytics</strong><span>Oracle DDL &bull; 7 tables</span><span class="sample-tags">Oracle, HL7, lab results</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFile('samples/financial_dbt.yml','financial_dbt.yml')">
          <div class="sample-icon">&#128176;</div>
          <div class="sample-info"><strong>Financial Services</strong><span>dbt YAML &bull; 5 models</span><span class="sample-tags">AML, risk events, balances</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFile('samples/supply_chain_pyspark.py','supply_chain_pyspark.py')">
          <div class="sample-icon">&#128666;</div>
          <div class="sample-info"><strong>Supply Chain</strong><span>PySpark &bull; 8 schemas</span><span class="sample-tags">StructType, inventory, shipments</span></div>
        </div>
        <div class="sample-card" onclick="loadSampleFile('samples/telco_informatica.csv','telco_informatica.csv')">
          <div class="sample-icon">&#128225;</div>
          <div class="sample-info"><strong>Telecom Network</strong><span>CSV Metadata &bull; 6 tables</span><span class="sample-tags">Informatica-style, CDR, towers</span></div>
        </div>
      </div>
    </div>
    <div id="parseResults"></div>
  </div>

  <!-- STEP 2: BLUEPRINT -->
  <div class="panel" id="panel-blueprint">
    <h2>Step 2: Blueprint Assembly</h2>
    <div id="blueprintNotReady" class="alert alert-info">Complete Step 1 first — parse a file or paste text.</div>
    <div id="blueprintReady" class="hidden">
      <div style="margin-top:8px">
        <button class="btn btn-primary" onclick="assembleBlueprint()">Assemble Blueprint</button>
      </div>
      <div id="blueprintResults"></div>
      <div id="tierDiagramContainer" class="hidden">
        <h3>Environment Visualization</h3>
        <div id="tierDiagramLegend" class="diagram-legend"></div>
        <div class="tier-diagram-wrapper">
          <div id="tierDiagram" class="tier-diagram tier-diagram-main"></div>
          <div id="tierDensitySidebar" class="tier-density-sidebar hidden">
            <h4>Connection Density</h4>
            <div id="densityBars"></div>
          </div>
        </div>
        <div id="tierNodeDetail"></div>
      </div>
    </div>
  </div>

  <!-- STEP 3: GENERATE -->
  <div class="panel" id="panel-generate">
    <h2>Step 3: Generate Synthetic Data</h2>
    <div id="generateNotReady" class="alert alert-info">Complete Step 2 first.</div>
    <div id="generateReady" class="hidden">
      <p style="color:var(--text2);font-size:0.9rem;margin-bottom:12px">Configure synthetic data generation — row counts default to actuals from the source when available.</p>
      <div class="row">
        <div class="col">
          <label>Override rows per table <span style="color:var(--text2);font-weight:400">(0 = use source actuals)</span></label>
          <input type="number" id="rowCount" value="0" min="0" max="100000" step="100">
        </div>
        <div class="col">
          <label>Random seed <span style="color:var(--text2);font-weight:400">(for reproducibility)</span></label>
          <input type="number" id="seed" value="42" min="0">
        </div>
      </div>
      <div style="margin-top:12px">
        <button class="btn btn-primary" onclick="generateData()">Generate Synthetic Data</button>
      </div>
      <div id="generateResults"></div>
    </div>
  </div>

  <!-- STEP 4: CONFORM -->
  <div class="panel" id="panel-conform">
    <h2>Step 4: Conform — Medallion Architecture</h2>
    <div id="conformNotReady" class="alert alert-info">Complete Step 3 first.</div>
    <div id="conformReady" class="hidden">
      <button class="btn btn-primary" onclick="runConform()">Run Medallion Pipeline</button>
      <div id="conformResults"></div>
    </div>
  </div>

  <!-- STEP 5: VALIDATE -->
  <div class="panel" id="panel-validate">
    <h2>Step 5: Validate &amp; Confidence Score</h2>
    <div id="validateNotReady" class="alert alert-info">Complete Steps 3-4 first.</div>
    <div id="validateReady" class="hidden">
      <button class="btn btn-primary" onclick="runValidation()">Run Validation</button>
      <div id="validateResults"></div>
    </div>
  </div>
  <!-- STEP 6: NOTEBOOK -->
  <div class="panel" id="panel-notebook">
    <h2>Step 6: NiFi &rarr; Databricks Notebook</h2>
    <div id="notebookNotReady" class="alert alert-info">Complete validation first with a NiFi flow.</div>
    <div id="notebookNotNifi" class="alert alert-info hidden">This step is only available for NiFi flow inputs.</div>
    <div id="notebookReady" class="hidden">
      <p style="color:var(--text2);font-size:0.9rem;margin-bottom:12px">
        Reverse-engineer your NiFi flow into a Databricks Python notebook with PySpark equivalents,
        Unity Catalog definitions, and a Databricks workflow.
      </p>
      <div class="expander" id="dbxConfigExpander"><div class="expander-header" onclick="this.parentElement.classList.toggle('open')"><span>Databricks Configuration</span><span class="expander-arrow">&#9654;</span></div><div class="expander-body">
        <p style="font-size:0.82rem;color:var(--text2);margin-bottom:12px">Configure these to generate a runnable notebook with resolved placeholders. Leave blank for generic templates.</p>
        <div class="row">
          <div class="col"><label>Unity Catalog</label><input type="text" id="cfgCatalog" placeholder="e.g. main"></div>
          <div class="col"><label>Schema</label><input type="text" id="cfgSchema" placeholder="e.g. nifi_migration"></div>
          <div class="col"><label>Secret Scope</label><input type="text" id="cfgScope" placeholder="e.g. migration_secrets"></div>
        </div>
        <div class="row" style="margin-top:8px">
          <div class="col"><label>Cloud Provider</label><select id="cfgCloud"><option value="azure">Azure</option><option value="aws">AWS</option><option value="gcp">GCP</option></select></div>
          <div class="col"><label>Spark Version</label><input type="text" id="cfgSparkVersion" value="14.3.x-scala2.12"></div>
          <div class="col"><label>Node Type</label><input type="text" id="cfgNodeType" value="Standard_DS3_v2"></div>
        </div>
        <div class="row" style="margin-top:8px">
          <div class="col"><label>Workers</label><input type="number" id="cfgWorkers" value="2" min="1" max="100"></div>
          <div class="col" style="flex:2"><label>Workspace Path</label><input type="text" id="cfgWorkspacePath" value="/Workspace/Migrations/NiFi"></div>
        </div>
        <div style="margin-top:8px"><button class="btn" onclick="saveDbxConfig(getDbxConfig());this.textContent='Saved!';setTimeout(()=>this.textContent='Save Configuration',1500)">Save Configuration</button></div>
      </div></div>
      <div style="margin-top:12px"><button class="btn btn-primary" onclick="generateNotebook()">Generate Notebook</button></div>
      <div id="notebookResults"></div>
    </div>
  </div>
  <!-- STEP 7: MIGRATION REPORT -->
  <div class="panel" id="panel-report">
    <h2>Step 7: Migration Report</h2>
    <div id="reportNotReady" class="alert alert-info">Generate the notebook first (Step 6).</div>
    <div id="reportReady" class="hidden">
      <button class="btn btn-primary" onclick="generateReport()">Generate Report</button>
      <div id="reportResults"></div>
    </div>
  </div>
  <!-- STEP 8: CROSS-COMPARISON -->
  <div class="panel" id="panel-comparison">
    <h2>Step 8: Cross-Comparison Dashboard</h2>
    <div id="comparisonNotReady" class="alert alert-info">Generate the migration report first (Step 7).</div>
    <div id="comparisonReady" class="hidden">
      <p style="color:var(--text2);font-size:0.9rem;margin-bottom:12px">
        Compare the original NiFi flow against the generated Databricks notebook —
        exact code matches, functional intent coverage, and pipeline action conversion.
      </p>
      <button class="btn btn-primary" onclick="generateComparison()">Run Comparison</button>
      <div id="comparisonResults"></div>
    </div>
  </div>
  <!-- STEP 9: DUAL EXECUTION SIMULATION -->
  <div class="panel" id="panel-simulate">
    <h2>Step 9: Dual Execution Simulation</h2>
    <div id="simulateNotReady" class="alert alert-info">Complete the cross-comparison first (Step 8).</div>
    <div id="simulateReady" class="hidden">
      <p style="color:var(--text2);font-size:0.9rem;margin-bottom:12px">
        Simulate running both the NiFi flow and the Databricks pipeline against the same
        synthetic data. High-confidence mappings produce identical outputs &mdash; proving the migration works.
      </p>
      <button class="btn btn-primary" onclick="runDualSimulation()">Run Dual Simulation</button>
      <div id="simulateResults"></div>
    </div>
  </div>

  <!-- STEP 10: FINAL REPORT -->
  <div class="panel" id="panel-reportFinal">
    <h2>Step 10: Final Report</h2>
    <div id="reportFinalNotReady" class="alert alert-info">Complete the dual simulation first (Step 9).</div>
    <div id="reportFinalReady" class="hidden">
      <p style="color:var(--text2);font-size:0.9rem;margin-bottom:12px">
        Generate a comprehensive end-to-end report of the entire migration pipeline &mdash;
        every step, every processor, every gap. Download as JSON for detailed analysis.
      </p>
      <button class="btn btn-primary" onclick="generateFinalReport()">Generate Final Report</button>
      <div id="reportFinalResults"></div>
    </div>
  </div>
</div>

<script>
// ================================================================
// STATE
// ================================================================
let STATE = { parsed: null, blueprint: null, tables: null, medallion: null, validation: null, notebook: null, migrationReport: null, comparison: null, simulation: null, finalReport: null, virtualEnv: null, manifest: null };

// ================================================================
// TAB NAVIGATION
// ================================================================
document.querySelectorAll('.tab').forEach(tab => {
  tab.addEventListener('click', () => {
    if (tab.classList.contains('locked')) return;
    document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
    document.querySelectorAll('.panel').forEach(p => p.classList.remove('active'));
    tab.classList.add('active');
    document.getElementById('panel-' + tab.dataset.tab).classList.add('active');
  });
});

function switchTab(name) {
  document.querySelectorAll('.tab').forEach(t => { t.classList.toggle('active', t.dataset.tab === name); });
  document.querySelectorAll('.panel').forEach(p => { p.classList.toggle('active', p.id === 'panel-' + name); });
}

function setTabStatus(name, status) {
  const tab = document.querySelector(`.tab[data-tab="${name}"]`);
  if (!tab) return;
  tab.classList.remove('locked','processing','done');
  if (status === 'locked') tab.classList.add('locked');
  else if (status === 'processing') tab.classList.add('processing');
  else if (status === 'done') tab.classList.add('done');
  // 'ready' = no extra class, just clickable
  if (status !== 'locked') {
    tab.style.pointerEvents = '';
    tab.style.opacity = '';
  }
}

function unlockTab(name) { setTabStatus(name, 'ready'); }

// FILE UPLOAD
const fileInput = document.getElementById('fileInput');
const dropZone = document.getElementById('fileDropZone');
dropZone.addEventListener('click', () => fileInput.click());
dropZone.addEventListener('dragover', e => { e.preventDefault(); dropZone.style.borderColor = 'var(--primary)'; });
dropZone.addEventListener('dragleave', () => { dropZone.style.borderColor = 'var(--border)'; });
dropZone.addEventListener('drop', e => { e.preventDefault(); dropZone.style.borderColor = 'var(--border)';
  if (e.dataTransfer.files.length) { fileInput.files = e.dataTransfer.files; handleFile(); }
});
fileInput.addEventListener('change', handleFile);

let uploadedContent = '', uploadedName = '';
function handleFile() {
  const f = fileInput.files[0]; if (!f) return;
  uploadedName = f.name;
  document.getElementById('fileName').textContent = 'Loaded: ' + f.name;
  document.getElementById('fileName').classList.remove('hidden');
  const reader = new FileReader();
  reader.onload = e => { uploadedContent = e.target.result; };
  reader.readAsText(f);
}

// ================================================================
// SAMPLE NIFI FLOWS — Embedded demos for one-click testing
// ================================================================
const SAMPLE_FLOWS = {
  etl: `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<flowController encoding-version="1.4">
  <rootGroup><name>ETL_Demo_Pipeline</name>
    <processor><id>p1</id><name>Read Source CSV</name><class>org.apache.nifi.processors.standard.GetFile</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>5 min</schedulingPeriod><state>RUNNING</state>
      <property><name>Input Directory</name><value>/data/input/sales</value></property>
      <property><name>File Filter</name><value>[^\\.].*\\.csv</value></property>
      <autoTerminatedRelationship>failure</autoTerminatedRelationship>
    </processor>
    <processor><id>p2</id><name>Validate Schema</name><class>org.apache.nifi.processors.standard.ValidateRecord</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Record Reader</name><value>CSVReader</value></property>
      <property><name>Record Writer</name><value>CSVWriter</value></property>
    </processor>
    <processor><id>p3</id><name>Route by Region</name><class>org.apache.nifi.processors.standard.RouteOnAttribute</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Routing Strategy</name><value>Route to Property name</value></property>
      <property><name>us_east</name><value>\${region:equals("US-East")}</value></property>
      <property><name>us_west</name><value>\${region:equals("US-West")}</value></property>
      <property><name>europe</name><value>\${region:equals("EU")}</value></property>
    </processor>
    <processor><id>p4</id><name>Transform Sales Data</name><class>org.apache.nifi.processors.standard.ReplaceText</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Search Value</name><value>"amount":"(\\d+)"</value></property>
      <property><name>Replacement Value</name><value>"amount_cents":"\${1}00"</value></property>
      <property><name>Replacement Strategy</name><value>Regex Replace</value></property>
    </processor>
    <processor><id>p5</id><name>Query Sales Summary</name><class>org.apache.nifi.processors.standard.ExecuteSQL</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Database Connection Pooling Service</name><value>DBCPService</value></property>
      <property><name>SQL select query</name><value>SELECT region, product, SUM(amount) as total, COUNT(*) as cnt FROM sales.transactions WHERE trade_date >= CURRENT_DATE - 7 GROUP BY region, product</value></property>
    </processor>
    <processor><id>p6</id><name>Update Attributes</name><class>org.apache.nifi.processors.standard.UpdateAttribute</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>output.filename</name><value>\${filename:substringBefore('.')}_processed_\${now():format('yyyyMMdd')}.csv</value></property>
      <property><name>batch.id</name><value>\${UUID()}</value></property>
    </processor>
    <processor><id>p7</id><name>Write to Data Lake</name><class>org.apache.nifi.processors.standard.PutFile</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Directory</name><value>/data/output/processed_sales</value></property>
      <property><name>Conflict Resolution Strategy</name><value>replace</value></property>
    </processor>
    <processor><id>p8</id><name>Insert to Warehouse</name><class>org.apache.nifi.processors.standard.PutDatabaseRecord</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Database Connection Pooling Service</name><value>DBCPService</value></property>
      <property><name>Table Name</name><value>warehouse.sales_processed</value></property>
      <property><name>Statement Type</name><value>INSERT</value></property>
    </processor>
    <processor><id>p9</id><name>Log Completion</name><class>org.apache.nifi.processors.standard.LogMessage</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
      <property><name>Log Level</name><value>info</value></property>
      <property><name>Log Message</name><value>ETL batch complete: \${batch.id}</value></property>
    </processor>
    <connection><id>c1</id><source><id>p1</id><type>PROCESSOR</type></source><destination><id>p2</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>c2</id><source><id>p2</id><type>PROCESSOR</type></source><destination><id>p3</id><type>PROCESSOR</type></destination><relationship>valid</relationship></connection>
    <connection><id>c3</id><source><id>p3</id><type>PROCESSOR</type></source><destination><id>p4</id><type>PROCESSOR</type></destination><relationship>us_east</relationship></connection>
    <connection><id>c4</id><source><id>p3</id><type>PROCESSOR</type></source><destination><id>p4</id><type>PROCESSOR</type></destination><relationship>us_west</relationship></connection>
    <connection><id>c5</id><source><id>p3</id><type>PROCESSOR</type></source><destination><id>p4</id><type>PROCESSOR</type></destination><relationship>europe</relationship></connection>
    <connection><id>c6</id><source><id>p4</id><type>PROCESSOR</type></source><destination><id>p5</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>c7</id><source><id>p5</id><type>PROCESSOR</type></source><destination><id>p6</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>c8</id><source><id>p6</id><type>PROCESSOR</type></source><destination><id>p7</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>c9</id><source><id>p6</id><type>PROCESSOR</type></source><destination><id>p8</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>c10</id><source><id>p8</id><type>PROCESSOR</type></source><destination><id>p9</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
  </rootGroup>
  <controllerServices>
    <controllerService><id>cs1</id><name>DBCPService</name><class>org.apache.nifi.dbcp.DBCPConnectionPool</class><property><name>Database Connection URL</name><value>jdbc:postgresql://db.example.com:5432/analytics</value></property><property><name>Database User</name><value>etl_user</value></property><property><name>Password</name><value>s3cur3_p4ss</value></property></controllerService>
  </controllerServices>
</flowController>`,

  streaming: `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<flowController encoding-version="1.4">
  <rootGroup><name>Streaming_IoT_Pipeline</name>
    <processGroup><name>IoT Ingestion</name>
      <processor><id>s1</id><name>Consume Kafka Events</name><class>org.apache.nifi.processors.kafka.pubsub.ConsumeKafka_2_6</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>100 ms</schedulingPeriod><state>RUNNING</state>
        <property><name>Kafka Brokers</name><value>kafka-broker-1:9092,kafka-broker-2:9092</value></property>
        <property><name>Topic Name(s)</name><value>iot.sensor.readings</value></property>
        <property><name>Group ID</name><value>nifi-iot-consumer</value></property>
      </processor>
      <processor><id>s2</id><name>Parse JSON Payload</name><class>org.apache.nifi.processors.standard.EvaluateJsonPath</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Destination</name><value>flowfile-attribute</value></property>
        <property><name>sensor_id</name><value>$.sensor_id</value></property>
        <property><name>temperature</name><value>$.readings.temperature</value></property>
        <property><name>humidity</name><value>$.readings.humidity</value></property>
        <property><name>timestamp</name><value>$.event_time</value></property>
      </processor>
      <processor><id>s3</id><name>Route by Threshold</name><class>org.apache.nifi.processors.standard.RouteOnAttribute</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Routing Strategy</name><value>Route to Property name</value></property>
        <property><name>alert</name><value>\${temperature:gt(100):or(\${humidity:gt(95)})}</value></property>
        <property><name>normal</name><value>\${temperature:le(100):and(\${humidity:le(95)})}</value></property>
      </processor>
      <connection><id>sc1</id><source><id>s1</id><type>PROCESSOR</type></source><destination><id>s2</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>sc2</id><source><id>s2</id><type>PROCESSOR</type></source><destination><id>s3</id><type>PROCESSOR</type></destination><relationship>matched</relationship></connection>
    </processGroup>
    <processGroup><name>Alert Processing</name>
      <processor><id>s4</id><name>Enrich Alert Data</name><class>org.apache.nifi.processors.standard.LookupAttribute</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Lookup Service</name><value>DeviceRegistry</value></property>
        <property><name>device.name</name><value>\${sensor_id}</value></property>
      </processor>
      <processor><id>s5</id><name>Format Alert Notification</name><class>org.apache.nifi.processors.standard.ReplaceText</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Replacement Value</name><value>{"alert":"THRESHOLD_EXCEEDED","sensor":"\${sensor_id}","temp":"\${temperature}","humidity":"\${humidity}","device":"\${device.name}","time":"\${timestamp}"}</value></property>
        <property><name>Replacement Strategy</name><value>Always Replace</value></property>
      </processor>
      <processor><id>s6</id><name>Send Alert to API</name><class>org.apache.nifi.processors.standard.InvokeHTTP</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Remote URL</name><value>https://alerts.example.com/api/v2/notify</value></property>
        <property><name>HTTP Method</name><value>POST</value></property>
        <property><name>Content-Type</name><value>application/json</value></property>
      </processor>
      <connection><id>sc3</id><source><id>s4</id><type>PROCESSOR</type></source><destination><id>s5</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>sc4</id><source><id>s5</id><type>PROCESSOR</type></source><destination><id>s6</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    </processGroup>
    <processGroup><name>Data Storage</name>
      <processor><id>s7</id><name>Batch Readings</name><class>org.apache.nifi.processors.standard.MergeContent</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Merge Strategy</name><value>Bin-Packing Algorithm</value></property>
        <property><name>Minimum Number of Entries</name><value>100</value></property>
        <property><name>Maximum Number of Entries</name><value>1000</value></property>
        <property><name>Max Bin Age</name><value>30 sec</value></property>
      </processor>
      <processor><id>s8</id><name>Convert to Parquet</name><class>org.apache.nifi.processors.standard.ConvertRecord</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Record Reader</name><value>JsonTreeReader</value></property>
        <property><name>Record Writer</name><value>ParquetRecordSetWriter</value></property>
      </processor>
      <processor><id>s9</id><name>Write to Delta Lake</name><class>org.apache.nifi.processors.standard.PutHDFS</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Directory</name><value>/data/iot/sensor_readings/\${now():format('yyyy/MM/dd')}</value></property>
        <property><name>Conflict Resolution Strategy</name><value>replace</value></property>
      </processor>
      <processor><id>s10</id><name>Insert to Timeseries DB</name><class>org.apache.nifi.processors.standard.PutDatabaseRecord</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Database Connection Pooling Service</name><value>TimeseriesDBCP</value></property>
        <property><name>Table Name</name><value>iot.sensor_readings</value></property>
        <property><name>Statement Type</name><value>INSERT</value></property>
      </processor>
      <connection><id>sc5</id><source><id>s7</id><type>PROCESSOR</type></source><destination><id>s8</id><type>PROCESSOR</type></destination><relationship>merged</relationship></connection>
      <connection><id>sc6</id><source><id>s8</id><type>PROCESSOR</type></source><destination><id>s9</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>sc7</id><source><id>s8</id><type>PROCESSOR</type></source><destination><id>s10</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    </processGroup>
    <connection><id>sc_g1</id><source><id>s3</id><type>PROCESSOR</type></source><destination><id>s4</id><type>PROCESSOR</type></destination><relationship>alert</relationship></connection>
    <connection><id>sc_g2</id><source><id>s3</id><type>PROCESSOR</type></source><destination><id>s7</id><type>PROCESSOR</type></destination><relationship>normal</relationship></connection>
    <connection><id>sc_g3</id><source><id>s3</id><type>PROCESSOR</type></source><destination><id>s7</id><type>PROCESSOR</type></destination><relationship>alert</relationship></connection>
  </rootGroup>
</flowController>`,

  full: `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<flowController encoding-version="1.4">
  <rootGroup><name>Manufacturing_Data_Pipeline</name>
    <processGroup><name>Data Ingestion</name>
      <processor><id>f1</id><name>Scan Input Directory</name><class>org.apache.nifi.processors.standard.GetFile</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>1 min</schedulingPeriod><state>RUNNING</state>
        <property><name>Input Directory</name><value>/data/mfg/incoming</value></property>
        <property><name>File Filter</name><value>.*\\.(csv|json|xml)</value></property>
        <property><name>Keep Source File</name><value>false</value></property>
      </processor>
      <processor><id>f2</id><name>List SFTP Uploads</name><class>org.apache.nifi.processors.standard.ListFile</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>5 min</schedulingPeriod><state>RUNNING</state>
        <property><name>Input Directory</name><value>/sftp/uploads/mfg_data</value></property>
        <property><name>File Filter</name><value>production_.*\\.csv</value></property>
      </processor>
      <processor><id>f3</id><name>Fetch Upload Contents</name><class>org.apache.nifi.processors.standard.FetchFile</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>File to Fetch</name><value>\${absolute.path}/\${filename}</value></property>
      </processor>
      <processor><id>f4</id><name>Query Production Metrics</name><class>org.apache.nifi.processors.standard.ExecuteSQL</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>10 min</schedulingPeriod><state>RUNNING</state>
        <property><name>Database Connection Pooling Service</name><value>MfgDBCP</value></property>
        <property><name>SQL select query</name><value>SELECT lot_id, wafer_id, step_name, measurement, result, operator, meas_time FROM mfg_data.production_steps WHERE meas_time >= CURRENT_TIMESTAMP - INTERVAL '1' HOUR ORDER BY meas_time</value></property>
      </processor>
      <connection><id>fc1</id><source><id>f2</id><type>PROCESSOR</type></source><destination><id>f3</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    </processGroup>
    <processGroup><name>Data Transformation</name>
      <processor><id>f5</id><name>Route by File Type</name><class>org.apache.nifi.processors.standard.RouteOnAttribute</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Routing Strategy</name><value>Route to Property name</value></property>
        <property><name>csv_files</name><value>\${filename:endsWith('.csv')}</value></property>
        <property><name>json_files</name><value>\${filename:endsWith('.json')}</value></property>
        <property><name>xml_files</name><value>\${filename:endsWith('.xml')}</value></property>
      </processor>
      <processor><id>f6</id><name>Parse JSON Metrics</name><class>org.apache.nifi.processors.standard.EvaluateJsonPath</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Destination</name><value>flowfile-attribute</value></property>
        <property><name>lot_id</name><value>$.lot_id</value></property>
        <property><name>status</name><value>$.quality_status</value></property>
        <property><name>yield_pct</name><value>$.yield_percentage</value></property>
      </processor>
      <processor><id>f7</id><name>Normalize Data Format</name><class>org.apache.nifi.processors.standard.ConvertRecord</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Record Reader</name><value>InferAvroReader</value></property>
        <property><name>Record Writer</name><value>CSVRecordSetWriter</value></property>
      </processor>
      <processor><id>f8</id><name>Add Processing Metadata</name><class>org.apache.nifi.processors.standard.UpdateAttribute</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>processing.timestamp</name><value>\${now():format('yyyy-MM-dd HH:mm:ss')}</value></property>
        <property><name>source.system</name><value>nifi_mfg_pipeline</value></property>
        <property><name>batch.id</name><value>\${UUID()}</value></property>
        <property><name>output.filename</name><value>\${filename:substringBefore('.')}_enriched_\${now():format('yyyyMMdd_HHmmss')}.csv</value></property>
      </processor>
      <connection><id>fc2</id><source><id>f5</id><type>PROCESSOR</type></source><destination><id>f6</id><type>PROCESSOR</type></destination><relationship>json_files</relationship></connection>
      <connection><id>fc3</id><source><id>f5</id><type>PROCESSOR</type></source><destination><id>f7</id><type>PROCESSOR</type></destination><relationship>csv_files</relationship></connection>
      <connection><id>fc4</id><source><id>f6</id><type>PROCESSOR</type></source><destination><id>f8</id><type>PROCESSOR</type></destination><relationship>matched</relationship></connection>
      <connection><id>fc5</id><source><id>f7</id><type>PROCESSOR</type></source><destination><id>f8</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    </processGroup>
    <processGroup><name>Data Loading</name>
      <processor><id>f9</id><name>Write to Staging</name><class>org.apache.nifi.processors.standard.PutFile</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Directory</name><value>/data/mfg/staging</value></property>
        <property><name>Conflict Resolution Strategy</name><value>replace</value></property>
      </processor>
      <processor><id>f10</id><name>Upload to HDFS</name><class>org.apache.nifi.processors.hadoop.PutHDFS</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Directory</name><value>/data/warehouse/mfg_production</value></property>
        <property><name>Conflict Resolution Strategy</name><value>replace</value></property>
      </processor>
      <processor><id>f11</id><name>Insert Production Records</name><class>org.apache.nifi.processors.standard.PutDatabaseRecord</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Database Connection Pooling Service</name><value>MfgDBCP</value></property>
        <property><name>Table Name</name><value>mfg_data.production_processed</value></property>
        <property><name>Statement Type</name><value>INSERT</value></property>
      </processor>
      <processor><id>f12</id><name>Transfer to Partner SFTP</name><class>org.apache.nifi.processors.standard.PutSFTP</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Hostname</name><value>sftp.partner.example.com</value></property>
        <property><name>Port</name><value>22</value></property>
        <property><name>Username</name><value>mfg_data_xfer</value></property>
        <property><name>Password</name><value>xfer_s3cret!</value></property>
        <property><name>Remote Path</name><value>/incoming/mfg/\${now():format('yyyyMMdd')}</value></property>
      </processor>
      <connection><id>fc6</id><source><id>f9</id><type>PROCESSOR</type></source><destination><id>f10</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>fc7</id><source><id>f9</id><type>PROCESSOR</type></source><destination><id>f11</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>fc8</id><source><id>f10</id><type>PROCESSOR</type></source><destination><id>f12</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    </processGroup>
    <processGroup><name>Orchestration</name>
      <processor><id>f13</id><name>Signal Data Ready</name><class>org.apache.nifi.processors.standard.Notify</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Signal Counter Name</name><value>mfg_data_ready</value></property>
        <property><name>Signal Counter Delta</name><value>1</value></property>
      </processor>
      <processor><id>f14</id><name>Wait for All Sources</name><class>org.apache.nifi.processors.standard.Wait</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>5 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Signal Counter Name</name><value>mfg_data_ready</value></property>
        <property><name>Target Signal Count</name><value>3</value></property>
      </processor>
      <processor><id>f15</id><name>Run Aggregation Script</name><class>org.apache.nifi.processors.standard.ExecuteStreamCommand</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Command</name><value>/opt/scripts/aggregate_mfg.sh</value></property>
        <property><name>Command Arguments</name><value>/data/mfg/staging /data/mfg/aggregated</value></property>
      </processor>
      <processor><id>f16</id><name>Refresh Impala Tables</name><class>org.apache.nifi.processors.standard.ExecuteStreamCommand</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Command</name><value>impala-shell</value></property>
        <property><name>Command Arguments</name><value>-q INVALIDATE METADATA mfg_data.production_processed; COMPUTE STATS mfg_data.production_processed;</value></property>
      </processor>
      <processor><id>f17</id><name>Log Pipeline Status</name><class>org.apache.nifi.processors.standard.LogMessage</class><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><schedulingPeriod>0 sec</schedulingPeriod><state>RUNNING</state>
        <property><name>Log Level</name><value>info</value></property>
        <property><name>Log Message</name><value>Manufacturing pipeline complete: batch=\${batch.id}, files=\${file.count}, timestamp=\${processing.timestamp}</value></property>
      </processor>
      <connection><id>fc9</id><source><id>f14</id><type>PROCESSOR</type></source><destination><id>f15</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>fc10</id><source><id>f15</id><type>PROCESSOR</type></source><destination><id>f16</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
      <connection><id>fc11</id><source><id>f16</id><type>PROCESSOR</type></source><destination><id>f17</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    </processGroup>
    <connection><id>fc_g1</id><source><id>f1</id><type>PROCESSOR</type></source><destination><id>f5</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>fc_g2</id><source><id>f3</id><type>PROCESSOR</type></source><destination><id>f5</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>fc_g3</id><source><id>f4</id><type>PROCESSOR</type></source><destination><id>f8</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>fc_g4</id><source><id>f8</id><type>PROCESSOR</type></source><destination><id>f9</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>fc_g5</id><source><id>f11</id><type>PROCESSOR</type></source><destination><id>f13</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
    <connection><id>fc_g6</id><source><id>f12</id><type>PROCESSOR</type></source><destination><id>f13</id><type>PROCESSOR</type></destination><relationship>success</relationship></connection>
  </rootGroup>
  <controllerServices>
    <controllerService><id>cs_mfg</id><name>MfgDBCP</name><class>org.apache.nifi.dbcp.DBCPConnectionPool</class>
      <property><name>Database Connection URL</name><value>jdbc:oracle:thin:@mfg-db.example.com:1521/MFGPRD</value></property>
      <property><name>Database User</name><value>mfg_reader</value></property>
      <property><name>Password</name><value>mfg_r34d3r!</value></property>
      <property><name>Database Driver Class Name</name><value>oracle.jdbc.driver.OracleDriver</value></property>
    </controllerService>
  </controllerServices>
</flowController>`
};

function loadSampleFlow(flowType) {
  const xml = SAMPLE_FLOWS[flowType];
  if (!xml) return;
  const labels = { etl: 'ETL Pipeline (9 processors)', streaming: 'Streaming IoT (10 processors)', full: 'Manufacturing Migration (17 processors)' };
  uploadedContent = xml;
  uploadedName = `sample_${flowType}_flow.xml`;
  document.getElementById('fileName').textContent = 'Sample: ' + (labels[flowType] || flowType);
  document.getElementById('fileName').classList.remove('hidden');
  document.getElementById('pasteInput').value = '';
  parseInput();
}

async function loadSampleFile(path, filename) {
  const el = document.getElementById('fileName');
  el.textContent = 'Loading: ' + filename + '...';
  el.classList.remove('hidden');
  try {
    const resp = await fetch(path);
    if (!resp.ok) throw new Error('HTTP ' + resp.status);
    const text = await resp.text();
    uploadedContent = text;
    uploadedName = filename;
    el.textContent = 'Sample: ' + filename;
    document.getElementById('pasteInput').value = '';
    parseInput();
  } catch(e) {
    el.textContent = 'Failed to load ' + filename + ' — ' + e.message;
    el.style.color = 'var(--red)';
    setTimeout(() => { el.style.color = ''; }, 3000);
  }
}

// ================================================================
// SMART PARSE ENGINE — Resilient Cascading Parser
// ================================================================
function cleanInput(content) {
  if (!content) return '';
  let c = content;
  // Strip BOM
  if (c.charCodeAt(0) === 0xFEFF) c = c.substring(1);
  // Normalize line endings
  c = c.replace(/\r\n/g, '\n').replace(/\r/g, '\n');
  // Remove NULL bytes
  c = c.replace(/\x00/g, '');
  // Replace non-breaking spaces
  c = c.replace(/\u00A0/g, ' ');
  // Replace smart quotes
  c = c.replace(/[\u201C\u201D]/g, '"').replace(/[\u2018\u2019]/g, "'");
  return c.trim();
}

function rankFormats(content, filename) {
  const candidates = [];
  // Extension-based (high confidence)
  if (filename) {
    const ext = filename.split('.').pop().toLowerCase();
    const extMap = {sql:'ddl',ddl:'ddl',hql:'ddl',bteq:'ddl',psql:'ddl',csv:'csv',tsv:'csv',json:'json',avsc:'avro',yaml:'yaml',yml:'yaml',xml:'xml',py:'pyspark',scala:'scala',proto:'protobuf'};
    if (extMap[ext]) {
      let fmt = extMap[ext];
      if (fmt === 'xml') fmt = detectXMLFormat(content);
      if (fmt === 'json') { try { const d=JSON.parse(content.trim()); if(d.type==='record'&&d.fields) fmt='avro'; } catch(e){} }
      candidates.push({format: fmt, confidence: 0.9});
    }
  }
  const s = content.trim();
  // NiFi template
  if (/<template[\s>][\s\S]{0,1000}<snippet>/i.test(s.substring(0,3000))) candidates.push({format:'nifi_xml',confidence:0.95});
  if (/org\.apache\.nifi\./i.test(s.substring(0,15000))) candidates.push({format:'nifi_xml',confidence:0.90});
  // Informatica
  if (/<(REPOSITORY|FOLDER|POWERMART|INFORMATICA)/i.test(s)) candidates.push({format:'informatica_xml',confidence:0.95});
  // Talend
  if (/<(TalendProperties|talendfile|ProcessType)/i.test(s)) candidates.push({format:'talend_xml',confidence:0.95});
  // Protobuf
  if (/\bmessage\s+\w+\s*\{[\s\S]*?(?:string|int32|int64|bool|double)\s+\w+\s*=\s*\d+/i.test(s.substring(0,5000))) candidates.push({format:'protobuf',confidence:0.88});
  // PySpark
  if (/StructType\s*\(|StructField\s*\(/i.test(s)) candidates.push({format:'pyspark',confidence:0.88});
  // Scala
  if (/case\s+class\s+\w+/i.test(s)) candidates.push({format:'scala',confidence:0.85});
  // Spark printSchema
  if (/root\s*\n\s*\|--/.test(s)) candidates.push({format:'spark_schema',confidence:0.90});
  // dbt
  if (/\{\{\s*(ref|source|config)\s*\(/.test(s)) candidates.push({format:'dbt',confidence:0.88});
  // Avro
  if (s.startsWith('{')) { try { const d=JSON.parse(s); if(d.type==='record'&&d.fields) candidates.push({format:'avro',confidence:0.92}); if(d.sessions&&(d.dependency_edges||d.table_index)) candidates.push({format:'dependency_json',confidence:0.95}); } catch(e){} }
  // DDL
  if (/CREATE\s+(?:OR\s+REPLACE\s+)?(?:TEMPORARY\s+|GLOBAL\s+TEMPORARY\s+|VOLATILE\s+|TRANSIENT\s+|EXTERNAL\s+|MULTISET\s+|SET\s+|COLUMN\s+|ROW\s+|UNLOGGED\s+|TEMP\s+)*TABLE\b/i.test(s)) candidates.push({format:'ddl',confidence:0.82});
  // JSON
  if (s.startsWith('{') || s.startsWith('[')) { try { JSON.parse(s); candidates.push({format:'json',confidence:0.70}); } catch(e){} }
  // XML
  if (s.startsWith('<')) candidates.push({format:'xml',confidence:0.60});
  // YAML
  if (/^(tables|models|sources)\s*:/m.test(s)) candidates.push({format:'yaml',confidence:0.80});
  // CSV
  const fl = s.split('\n')[0].toLowerCase();
  if (['source_table','target_table','src_table','tgt_table','table_name','column_name'].some(h => fl.includes(h))) candidates.push({format:'csv',confidence:0.80});
  // Fallback DDL from type keywords
  if (/\b(INT|VARCHAR|DECIMAL|TIMESTAMP|BOOLEAN|BIGINT|FLOAT|DOUBLE|NUMBER)\b/i.test(s)) candidates.push({format:'ddl',confidence:0.30});
  // Always include DDL as absolute fallback
  if (!candidates.some(c=>c.format==='ddl')) candidates.push({format:'ddl',confidence:0.10});
  // Dedupe: keep highest confidence per format
  const best = {};
  candidates.forEach(c => { if (!best[c.format] || c.confidence > best[c.format].confidence) best[c.format] = c; });
  return Object.values(best).sort((a,b) => b.confidence - a.confidence);
}

function routeParser(format, content, filename) {
  const sn = filename || 'Parsed Input';
  if (format==='yaml') return parseYAML(content, sn);
  if (format==='pyspark') return parsePySpark(content, sn);
  if (format==='scala') return parseScala(content, sn);
  if (format==='dbt') return parseDBT(content, sn);
  if (format==='avro') return parseAvro(content, sn);
  if (format==='protobuf') return parseProtobuf(content, sn);
  if (format==='spark_schema') return parseSparkSchema(content, sn);
  if (format==='informatica_xml') { const doc=new DOMParser().parseFromString(content,'text/xml'); return parseInformaticaXML(doc, sn); }
  if (format==='talend_xml') { const doc=new DOMParser().parseFromString(content,'text/xml'); return parseTalendXML(doc, sn); }
  if (format==='nifi_xml') { const doc=new DOMParser().parseFromString(content,'text/xml'); return parseNiFiXML(doc, sn); }
  if (format==='dependency_json') return parseJSON(content, sn);
  if (format==='json') return parseJSON(content, sn);
  if (format==='xml') return parseXML(content, sn);
  if (format==='csv') return parseCSV(content, sn);
  return parseDDL(content, sn);
}

function validateParseResult(result) {
  let score = 0;
  const warnings = [];
  if (!result || !result.tables) return {score:0, warnings:['No result'], result};
  if (result.tables.length > 0) score += 0.3;
  const withCols = result.tables.filter(t => t.columns && t.columns.length > 0);
  if (withCols.length === result.tables.length) score += 0.3;
  else if (withCols.length > 0) { score += 0.15; warnings.push(`${result.tables.length - withCols.length} tables have no columns`); }
  const allCols = result.tables.flatMap(t => t.columns || []);
  const typedCols = allCols.filter(c => c.data_type && c.data_type !== 'varchar');
  if (typedCols.length > allCols.length * 0.3) score += 0.2;
  else if (allCols.length > 0) score += 0.1;
  const namedTables = result.tables.filter(t => t.name && t.name.length > 0);
  if (namedTables.length === result.tables.length) score += 0.1;
  const names = result.tables.map(t => t.name);
  if (new Set(names).size === names.length) score += 0.1;
  return {score, warnings, result};
}

function bruteForceExtract(content, filename, priorErrors) {
  const tables = [];
  // Strategy 1: column-type patterns
  const colPattern = /\b(\w{2,30})\s+(INT(?:EGER)?|VARCHAR\d*|CHAR|TEXT|DECIMAL|FLOAT|DOUBLE|DATE|TIMESTAMP|BOOLEAN|BIGINT|SMALLINT|TINYINT|NUMBER|STRING|BINARY|BLOB|CLOB)\b/gi;
  const matches = [...content.matchAll(colPattern)];
  if (matches.length >= 2) {
    const seen = new Set();
    const cols = matches.filter(m => { const k=m[1].toLowerCase(); if(seen.has(k))return false; seen.add(k); return true; }).map(m => ({
      name:m[1], data_type:TYPE_NORM[m[2].toLowerCase()]||m[2].toLowerCase(), raw_type:m[2],
      nullable:true, is_primary_key:false, is_unique:false, check_constraints:[], max_length:null, precision:null, scale:null, default_value:null
    }));
    if (cols.length >= 2) tables.push({name:filename?filename.replace(/\.[^.]+$/,''):'extracted_table', schema:'unknown', columns:cols, foreign_keys:[], row_count:1000});
  }
  // Strategy 2: XML name/type attributes
  if (content.trim().startsWith('<')) {
    try {
      const doc = new DOMParser().parseFromString(content, 'text/xml');
      const groups = {};
      doc.querySelectorAll('*').forEach(el => {
        const name = el.getAttribute('name')||el.getAttribute('Name')||el.getAttribute('NAME');
        const type = el.getAttribute('type')||el.getAttribute('Type')||el.getAttribute('TYPE')||el.getAttribute('datatype')||el.getAttribute('DATATYPE');
        if (name && type) {
          const parent = el.parentElement?.getAttribute('name')||el.parentElement?.getAttribute('Name')||'xml_table';
          if (!groups[parent]) groups[parent] = [];
          groups[parent].push({name, data_type:TYPE_NORM[type.toLowerCase()]||type.toLowerCase(), raw_type:type,
            nullable:true, is_primary_key:false, is_unique:false, check_constraints:[], max_length:null, precision:null, scale:null, default_value:null});
        }
      });
      Object.entries(groups).forEach(([tn, cols]) => {
        if (cols.length >= 2 && !tables.find(t=>t.name===tn)) tables.push({name:tn, schema:'unknown', columns:cols, foreign_keys:[], row_count:1000});
      });
    } catch(e) {}
  }
  const warnings = ['Primary parsers failed — used brute-force extraction'];
  if (priorErrors && priorErrors.length) priorErrors.forEach(e => warnings.push(`${e.format}: ${e.error}`));
  return {source_name:filename||'Unknown', source_type:'brute_force', tables, input_format:'unknown', parse_warnings:warnings};
}

function smartParse(content, filename) {
  content = cleanInput(content);
  if (!content) return null;
  const candidates = rankFormats(content, filename);
  const errors = [];
  for (const {format, confidence} of candidates) {
    try {
      const result = routeParser(format, content, filename);
      if (result && result.tables && result.tables.length > 0) {
        const validated = validateParseResult(result);
        if (validated.score > 0.3) {
          result.detected_format = format;
          result.parse_confidence = confidence;
          result.parse_attempts = errors.length + 1;
          if (validated.warnings.length) result.parse_warnings = (result.parse_warnings||[]).concat(validated.warnings);
          return result;
        }
      }
    } catch(e) { errors.push({format, error: e.message}); }
  }
  // Final fallback
  return bruteForceExtract(content, filename, errors);
}

// ================================================================
// PARSERS
// ================================================================
const TYPE_NORM = {
  // Oracle
  number:'decimal',varchar2:'varchar',nvarchar2:'varchar',clob:'text',nclob:'text',blob:'binary',
  raw:'binary','long raw':'binary',long:'text',binary_float:'float',binary_double:'double',
  xmltype:'text',rowid:'varchar',urowid:'varchar',
  // SQL Server / Azure Synapse
  nvarchar:'varchar',nchar:'char',bit:'boolean',money:'decimal',smallmoney:'decimal',
  datetime2:'timestamp',datetimeoffset:'timestamp',smalldatetime:'timestamp',
  image:'binary',ntext:'text',uniqueidentifier:'varchar',sql_variant:'varchar',
  hierarchyid:'varchar',varbinary:'binary',xml:'text',
  // PostgreSQL
  serial:'int',bigserial:'bigint',smallserial:'smallint',real:'float',
  'double precision':'double','character varying':'varchar',character:'char',
  bytea:'binary',inet:'varchar',cidr:'varchar',macaddr:'varchar',uuid:'varchar',
  jsonb:'text',json:'text',tsquery:'text',tsvector:'text',interval:'varchar',
  int2:'smallint',int4:'int',int8:'bigint',float4:'float',float8:'double',
  bool:'boolean',timestamptz:'timestamp',
  // MySQL
  mediumint:'int',mediumtext:'text',longtext:'text',tinytext:'text',
  enum:'varchar',set:'varchar',year:'int',mediumblob:'binary',longblob:'binary',
  tinyblob:'binary',tinyint:'int',
  // Snowflake
  variant:'text',object:'text',array:'text',string:'varchar',
  timestamp_ltz:'timestamp',timestamp_ntz:'timestamp',timestamp_tz:'timestamp',
  // Redshift
  super:'text',hllsketch:'varchar',bpchar:'char',
  // Teradata
  byteint:'int',st_geometry:'varchar',
  // SAP HANA
  cs_string:'varchar',cs_int:'int',cs_double:'double',cs_decimal:'decimal',
  alphanum:'varchar',shorttext:'varchar',seconddate:'timestamp',daydate:'date',
  // BigQuery
  int64:'bigint',float64:'double',bignumeric:'decimal',record:'text',struct:'text',
  geography:'varchar',geometry:'varchar',
  // Databricks / Spark
  short:'smallint',byte:'tinyint',binary:'binary',map:'text',void:'varchar',
  // Informatica / Talend
  nstring:'varchar',
};
const MW_TYPES = ['double precision','character varying','timestamp with time zone',
  'timestamp without time zone','timestamp with local time zone','long raw',
  'long varchar','binary varying','national character varying','national character'];

function detectFormat(content, filename) {
  if (filename) {
    const ext = filename.split('.').pop().toLowerCase();
    const map = {sql:'ddl',ddl:'ddl',hql:'ddl',bteq:'ddl',psql:'ddl',csv:'csv',tsv:'csv',json:'json',avsc:'avro',yaml:'yaml',yml:'yaml',xml:'xml',py:'pyspark',scala:'scala',proto:'protobuf'};
    if (map[ext]) {
      // For XML files, do deeper detection
      if (map[ext]==='xml') return detectXMLFormat(content);
      // For JSON, check if it's Avro
      if (map[ext]==='json') { try { const d=JSON.parse(content.trim()); if(d.type==='record'&&d.fields)return 'avro'; } catch(e){} return 'json'; }
      return map[ext];
    }
  }
  const s = content.trim();
  // Protobuf
  if (/\bmessage\s+\w+\s*\{[\s\S]*?(?:string|int32|int64|bool|double)\s+\w+\s*=\s*\d+/i.test(s)) return 'protobuf';
  // PySpark
  if (/StructType\s*\(|StructField\s*\(/i.test(s)) return 'pyspark';
  // Scala case class
  if (/case\s+class\s+\w+\s*\(/i.test(s)) return 'scala';
  // Spark printSchema
  if (/root\s*\n\s*\|--/.test(s)) return 'spark_schema';
  // dbt
  if (/\{\{\s*(ref|source|config)\s*\(/.test(s)) return 'dbt';
  // XML
  if (s.startsWith('<')) return detectXMLFormat(s);
  // DDL (enhanced regex)
  if (/\bCREATE\s+(?:OR\s+REPLACE\s+)?(?:TEMPORARY\s+|GLOBAL\s+TEMPORARY\s+|VOLATILE\s+|TRANSIENT\s+|EXTERNAL\s+|MULTISET\s+|SET\s+|COLUMN\s+|ROW\s+|UNLOGGED\s+)*TABLE\b/i.test(s)) return 'ddl';
  // JSON / Avro
  if (s.startsWith('{') || s.startsWith('[')) { try { const d=JSON.parse(s); if(d.type==='record'&&d.fields)return 'avro'; if(d.tables||d.models)return 'json'; return 'json'; } catch(e){} }
  // YAML
  if (/^(tables|models|sources)\s*:/m.test(s)) return 'yaml';
  // CSV
  const fl = s.split('\n')[0].toLowerCase();
  if (['source_table','target_table','src_table','tgt_table','table_name','column_name'].some(h => fl.includes(h))) return 'csv';
  // Fallback DDL
  if (/\b(INT|VARCHAR|DECIMAL|TIMESTAMP|BOOLEAN|BIGINT|FLOAT|DOUBLE|NUMBER)\b/i.test(s)) return 'ddl';
  return 'unknown';
}

function detectXMLFormat(content) {
  if (/<(REPOSITORY|FOLDER|POWERMART|INFORMATICA)/i.test(content)) return 'informatica_xml';
  if (/<(SOURCE\s|TARGET\s).*?(DATABASETYPE|SOURCEFIELD|TARGETFIELD)/i.test(content)) return 'informatica_xml';
  if (/<(TalendProperties|talendfile|ProcessType|talend)/i.test(content)) return 'talend_xml';
  // NiFi: template exports have <template><snippet><processGroups>
  if (/<template[\s>][\s\S]{0,500}<snippet>/i.test(content.substring(0,2000))) return 'nifi_xml';
  if (/<snippet>[\s\S]{0,500}<(processGroups|controllerServices|processors)/i.test(content.substring(0,5000))) return 'nifi_xml';
  if (/<(flowController|rootGroup|processGroupFlow)\b/i.test(content)) return 'nifi_xml';
  if (/org\.apache\.nifi\./i.test(content.substring(0,10000))) return 'nifi_xml';
  return 'xml';
}

function prepareDDL(content) {
  // Strip block comments (non-nested)
  let clean = content.replace(/\/\*[\s\S]*?\*\//g, ' ');
  // Strip line comments
  clean = clean.replace(/--[^\n]*/g, '');
  // Replace string literals with safe placeholders to prevent paren confusion
  clean = clean.replace(/'(?:[^'\\]|\\.)*'/g, match => "'" + ' '.repeat(Math.max(0,match.length-2)) + "'");
  return clean;
}

function parseDDL(content, sourceName) {
  const tables = [], warnings = [];
  const prepared = prepareDDL(content);
  const hp = /CREATE\s+(?:OR\s+REPLACE\s+)?(?:TEMPORARY\s+|GLOBAL\s+TEMPORARY\s+|VOLATILE\s+|TRANSIENT\s+|EXTERNAL\s+|MULTISET\s+|SET\s+|COLUMN\s+|ROW\s+|UNLOGGED\s+|TEMP\s+)*TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?([^\s(]+)\s*\(/gi;
  let hm;
  while ((hm = hp.exec(prepared)) !== null) {
    const rawName = hm[1]; let start = hm.index + hm[0].length, depth = 1, i = start;
    let limit = 100000;
    while (i < prepared.length && depth > 0 && limit-- > 0) { if (prepared[i]==='(') depth++; else if (prepared[i]===')') depth--; i++; }
    if (depth === 0) {
      // Use original content for body to preserve actual defaults/strings
      const body = content.substring(start, i-1);
      const clean = rawName.replace(/[\[\]`"]/g,''); const parts = clean.split('.');
      const tName = parts[parts.length-1], schema = parts.length>=2 ? parts[parts.length-2] : 'dbo';
      const {cols, fks} = parseTableBody(body);
      if (cols.length > 0) tables.push({name:tName, schema, columns:cols, foreign_keys:fks, row_count:1000});
      else warnings.push(`Table ${tName}: no columns extracted`);
    } else { warnings.push(`Table ${rawName}: unbalanced parentheses`); }
  }
  // ALTER TABLE FKs
  const ap = /ALTER\s+TABLE\s+(\S+)\s+ADD\s+(?:CONSTRAINT\s+\S+\s+)?FOREIGN\s+KEY\s*\(\s*[\[`"]?(\w+)[\]`"]?\s*\)\s*REFERENCES\s+(\S+)\s*\(\s*[\[`"]?(\w+)[\]`"]?\s*\)/gi;
  let am;
  while ((am = ap.exec(content)) !== null) {
    const tn = am[1].replace(/[\[\]`"]/g,'').split('.').pop();
    const fk = {fk_column:am[2], referenced_table:am[3].replace(/[\[\]`"]/g,'').split('.').pop(), referenced_column:am[4]};
    const t = tables.find(t => t.name.toLowerCase() === tn.toLowerCase());
    if (t) t.foreign_keys.push(fk);
  }
  return {source_name:sourceName||'DDL Import', source_type:'sql', tables, input_format:'ddl', parse_warnings:warnings};
}

function parseTableBody(body) {
  const cols = [], fks = [];
  const elems = splitDefs(body);
  for (let el of elems) {
    el = el.trim(); if (!el) continue;
    const upper = el.toUpperCase().trim();
    if (upper.startsWith('PRIMARY KEY')) {
      const pks = extractParensList(el);
      cols.forEach(c => { if (pks.some(p => p.toLowerCase()===c.name.toLowerCase())) c.is_primary_key = true; });
      continue;
    }
    if (upper.startsWith('FOREIGN KEY')) {
      const m = el.match(/FOREIGN\s+KEY\s*\(\s*(\w+)\s*\)\s*REFERENCES\s+(\S+)\s*\(\s*(\w+)\s*\)/i);
      if (m) fks.push({fk_column:m[1], referenced_table:m[2].replace(/[\[\]`"]/g,'').split('.').pop(), referenced_column:m[3]});
      continue;
    }
    if (/^(UNIQUE|CHECK|CONSTRAINT|INDEX)/i.test(upper)) continue;
    const r = parseColDef(el);
    if (r.col) { cols.push(r.col); if (r.fk) fks.push(r.fk); }
  }
  return {cols, fks};
}

function parseColDef(el) {
  const s = el.trim();
  const nm = s.match(/^([`"\[\]]?\w+[`"\]\]]?)\s+/);
  if (!nm) return {};
  const rawName = nm[1].replace(/[\[\]`"]/g,'');
  let rest = s.substring(nm[0].length);
  let rawType = '', typeArgs = null;
  const rl = rest.toLowerCase();
  for (const mwt of MW_TYPES.sort((a,b)=>b.length-a.length)) {
    if (rl.startsWith(mwt)) { rawType = mwt; rest = rest.substring(mwt.length).trim(); break; }
  }
  if (!rawType) {
    const tm = rest.match(/^([A-Za-z_]\w*)/);
    if (!tm) return {};
    rawType = tm[1].toLowerCase(); rest = rest.substring(tm[0].length).trim();
  }
  if (rest.startsWith('(')) {
    const pe = rest.indexOf(')');
    if (pe > 0) { typeArgs = rest.substring(1, pe); rest = rest.substring(pe+1).trim(); }
  }
  const modsOrig = rest, mods = rest.toUpperCase();
  const ctype = TYPE_NORM[rawType] || rawType;
  let prec=null, scl=null, maxl=null;
  if (typeArgs) {
    const pts = typeArgs.split(',').map(p=>p.trim());
    if (['decimal','numeric'].includes(ctype)) { prec = parseInt(pts[0])||null; scl = pts[1]?parseInt(pts[1]):null; }
    else if (['varchar','char','text'].includes(ctype)) { if (/^\d+$/.test(pts[0])) maxl = parseInt(pts[0]); }
  }
  const nullable = !mods.includes('NOT NULL'), isPK = mods.includes('PRIMARY KEY'), isUnique = mods.includes('UNIQUE');
  let checkVals = [];
  const cm = modsOrig.match(/CHECK\s*\(.*?IN\s*\(([^)]+)\)/i);
  if (cm) checkVals = cm[1].split(',').map(v=>v.trim().replace(/^['"]|['"]$/g,''));
  let defaultVal = null;
  const dm = modsOrig.match(/DEFAULT\s+(\S+)/i);
  if (dm) defaultVal = dm[1].replace(/^['"]|['"]$/g,'');
  let fk = null;
  const rm = modsOrig.match(/REFERENCES\s+([\w`"\[\]]+)(?:\s*\(\s*(\w+)\s*\))?/i);
  if (rm) fk = {fk_column:rawName, referenced_table:rm[1].replace(/[\[\]`"]/g,''), referenced_column:rm[2]||'id'};
  let pk = isPK;
  if (mods.includes('IDENTITY') || mods.includes('AUTO_INCREMENT')) pk = true;
  if (['serial','bigserial','smallserial'].includes(rawType)) pk = true;
  return { col: {name:rawName, data_type:ctype, raw_type:typeArgs?`${rawType}(${typeArgs})`:rawType,
    nullable, is_primary_key:pk, is_unique:isUnique, default_value:defaultVal,
    check_constraints:checkVals, precision:prec, scale:scl, max_length:maxl}, fk };
}

function splitDefs(body) {
  const elems = []; let cur = '', depth = 0;
  for (const c of body) {
    if (c==='(') { depth++; cur+=c; } else if (c===')') { depth--; cur+=c; }
    else if (c===',' && depth===0) { elems.push(cur); cur=''; } else cur+=c;
  }
  if (cur) elems.push(cur);
  return elems;
}

function extractParensList(el) {
  const m = el.match(/\(([^)]+)\)/);
  return m ? m[1].split(',').map(n=>n.trim().replace(/[\[\]`"]/g,'')) : [];
}

function parseJSON(content, sourceName) {
  let data;
  try { data = JSON.parse(content.trim()); } catch(e) { return {source_name:sourceName||'JSON',source_type:'json',tables:[],input_format:'json',parse_warnings:['Invalid JSON: '+e.message]}; }
  // Detect dependency graph format (sessions + dependency_edges + table_index)
  if (data.sessions && (data.dependency_edges || data.table_index)) return parseDependencyGraph(data, sourceName);
  const src = data.tables || data.models || (Array.isArray(data) ? data : []);
  const tables = (Array.isArray(src) ? src : Object.values(src)).map(t => {
    if (!t || typeof t !== 'object') return null;
    const cols = (t.columns||[]).map(c => {
      if (typeof c === 'string') { const p = c.split(':'); return {name:p[0].trim(), data_type:p[1]?p[1].trim():'varchar', raw_type:p[1]||'varchar', nullable:true, is_primary_key:false, is_unique:false, check_constraints:[], max_length:null, precision:null, scale:null, default_value:null}; }
      return {name:c.name||c.column_name||'', data_type:c.type||c.data_type||'varchar', raw_type:c.type||c.data_type||'varchar', nullable:c.nullable!==false, is_primary_key:!!c.pk||!!c.primary_key||!!c.is_primary_key, is_unique:false, check_constraints:c.values||c.allowed_values||[], max_length:c.length||c.max_length||null, precision:null, scale:null, default_value:null};
    });
    const fks = (t.foreign_keys||t.fks||[]).map(fk=>({fk_column:fk.column||'', referenced_table:fk.references||fk.referenced_table||'', referenced_column:fk.references_column||fk.referenced_column||'id'}));
    return {name:t.name||'', schema:t.schema||'dbo', columns:cols, foreign_keys:fks, row_count:1000};
  }).filter(Boolean);
  return {source_name:data.name||sourceName||'JSON Import', source_type:data.type||'json', tables, input_format:'json', parse_warnings:[]};
}

// ================================================================
// PARSERS — Dependency Graph JSON (session lineage + table dependencies)
// ================================================================
function parseDependencyGraph(data, sourceName) {
  const tables = [], warnings = [];
  const sessions = data.sessions || {};
  const edges = data.dependency_edges || [];
  const order = data.recommended_order || [];
  const conflicts = data.conflicts || [];
  const sessionNames = Object.keys(sessions);

  // Collect all unique tables across all sessions
  const allTables = {};
  for (const [sName, sess] of Object.entries(sessions)) {
    (sess.source_tables||[]).forEach(t => {
      const key = t.name;
      if (!allTables[key]) allTables[key] = {name:t.name, schema:t.schema||'', roles:new Set(), sessions:new Set()};
      allTables[key].roles.add('source');
      allTables[key].sessions.add(sName);
    });
    (sess.target_tables||[]).forEach(t => {
      const key = t.name;
      if (!allTables[key]) allTables[key] = {name:t.name, schema:t.schema||t.load_type||'', roles:new Set(), sessions:new Set()};
      allTables[key].roles.add('target');
      allTables[key].sessions.add(sName);
    });
    (sess.lookup_tables||[]).forEach(t => {
      const key = t.name;
      if (!allTables[key]) allTables[key] = {name:t.name, schema:t.schema||'', roles:new Set(), sessions:new Set()};
      allTables[key].roles.add('lookup');
      allTables[key].sessions.add(sName);
    });
  }

  // Build sessions inventory table
  const sessionStates = sessionNames.map(s => {
    const sess = sessions[s];
    return {name:s, sources:(sess.source_tables||[]).length, targets:(sess.target_tables||[]).length, lookups:(sess.lookup_tables||[]).length};
  });
  const allSessionNames = sessionNames.slice(0,50);
  tables.push({name:'etl_sessions', schema:'dependency_graph', row_count:sessionNames.length, columns:[
    {name:'session_name',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:true,is_unique:true,check_constraints:allSessionNames,max_length:200,precision:null,scale:null,default_value:null},
    {name:'source_table_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
    {name:'target_table_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
    {name:'lookup_table_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
    {name:'execution_order',data_type:'int',raw_type:'int',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
  ], foreign_keys:[]});

  // Build tables inventory
  const tableNames = Object.keys(allTables);
  const roleValues = ['source','target','lookup'];
  tables.push({name:'etl_tables', schema:'dependency_graph', row_count:tableNames.length, columns:[
    {name:'table_name',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
    {name:'schema_name',data_type:'varchar',raw_type:'string',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:100,precision:null,scale:null,default_value:null},
    {name:'role',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:roleValues,max_length:20,precision:null,scale:null,default_value:null},
    {name:'session_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
  ], foreign_keys:[]});

  // Build dependency edges table
  if (edges.length) {
    tables.push({name:'dependency_edges', schema:'dependency_graph', row_count:edges.length, columns:[
      {name:'edge_id',data_type:'int',raw_type:'int',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
      {name:'upstream_session',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'downstream_session',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'via_table',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null}
    ], foreign_keys:[
      {fk_column:'upstream_session',referenced_table:'etl_sessions',referenced_column:'session_name'},
      {fk_column:'downstream_session',referenced_table:'etl_sessions',referenced_column:'session_name'}
    ]});
  }

  // Build conflicts table
  if (conflicts.length) {
    const conflictTypes = [...new Set(conflicts.map(c=>c.conflict_type))];
    tables.push({name:'etl_conflicts', schema:'dependency_graph', row_count:conflicts.length, columns:[
      {name:'conflict_id',data_type:'int',raw_type:'int',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
      {name:'table_name',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'conflict_type',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:conflictTypes,max_length:50,precision:null,scale:null,default_value:null},
      {name:'writer_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
      {name:'reader_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
    ], foreign_keys:[]});
  }

  if (conflicts.length) warnings.push(`${conflicts.length} conflicts detected: ${conflicts.map(c=>c.table_name+' ('+c.conflict_type+')').join(', ')}`);

  const result = {
    source_name: sourceName || 'Dependency Graph',
    source_type: 'dependency_graph',
    tables, input_format: 'dependency_json',
    parse_warnings: warnings
  };
  // Store dependency metadata for tier diagram
  result._dependency = {sessions: sessionStates, edges, order, conflicts, allTables, rawSessions: sessions};
  return result;
}

function parseXML(content, sourceName) {
  let doc;
  try { doc = new DOMParser().parseFromString(content, 'text/xml'); } catch(e) { return {source_name:sourceName||'XML',source_type:'xml',tables:[],input_format:'xml',parse_warnings:['Invalid XML: '+e.message]}; }
  // Check for parse errors
  const parseErr = doc.querySelector('parsererror');
  if (parseErr) return {source_name:sourceName||'XML',source_type:'xml',tables:[],input_format:'xml',parse_warnings:['XML parse error: '+parseErr.textContent.substring(0,200)]};
  const tables = [];
  function getAttrCI(el, names) { for (const n of names) { const v = el.getAttribute(n); if (v) return v; } return ''; }
  function isBoolTrue(v) { return ['true','yes','1','y'].includes((v||'').toLowerCase()); }
  // Find table elements (case-insensitive, namespace-aware)
  const allEls = doc.querySelectorAll('*');
  const tableEls = [...allEls].filter(el => el.localName.toLowerCase() === 'table');
  tableEls.forEach(te => {
    const name = getAttrCI(te, ['name','Name','NAME']); if (!name) return;
    const cols = [], fks = [];
    const colEls = [...te.querySelectorAll('*')].filter(el => el.localName.toLowerCase() === 'column');
    colEls.forEach(ce => {
      const cn = getAttrCI(ce, ['name','Name','NAME']); if (!cn) return;
      const rt = getAttrCI(ce, ['type','Type','TYPE','dataType','datatype','DATATYPE'])||'varchar';
      const dtRaw = rt.toLowerCase().split('(')[0];
      const dt = TYPE_NORM[dtRaw] || dtRaw;
      const nullable = !['false','no','0'].includes((getAttrCI(ce, ['nullable','Nullable','NULLABLE'])||'true').toLowerCase());
      const pk = isBoolTrue(getAttrCI(ce, ['primaryKey','pk','PK','primary_key','isPrimaryKey','KEYTYPE']));
      const ml = getAttrCI(ce, ['length','Length','LENGTH','maxLength','PRECISION']);
      const checkStr = getAttrCI(ce, ['check','values','Values','CHECK','accepted_values'])||'';
      const checks = checkStr ? checkStr.split(',').map(v=>v.trim()).filter(Boolean) : [];
      cols.push({name:cn, data_type:dt, raw_type:rt, nullable, is_primary_key:pk, is_unique:false, check_constraints:checks, max_length:ml?parseInt(ml)||null:null, precision:null, scale:null, default_value:null});
      const ref = getAttrCI(ce, ['references','References','REFERENCES']);
      if (ref) { const r = parseRefStr(cn, ref); if (r) fks.push(r); }
    });
    const fkEls = [...te.querySelectorAll('*')].filter(el => ['foreignkey','foreign_key','fk'].includes(el.localName.toLowerCase()));
    fkEls.forEach(fe => {
      const col = getAttrCI(fe, ['column','Column','COLUMN'])||'';
      const ref = getAttrCI(fe, ['references','References','REFERENCES'])||'';
      if (col && ref) { const r = parseRefStr(col, ref); if (r) fks.push(r); }
    });
    tables.push({name, schema:getAttrCI(te, ['schema','Schema','SCHEMA'])||'dbo', columns:cols, foreign_keys:fks, row_count:1000});
  });
  return {source_name:sourceName||'XML Import', source_type:'xml', tables, input_format:'xml', parse_warnings:[]};
}

function parseRefStr(fkCol, refStr) {
  const m = refStr.match(/^(\w+)\((\w+)\)$/);
  if (m) return {fk_column:fkCol, referenced_table:m[1], referenced_column:m[2]};
  if (refStr.includes('.')) { const p = refStr.split('.'); return {fk_column:fkCol, referenced_table:p[0], referenced_column:p[1]}; }
  return {fk_column:fkCol, referenced_table:refStr.trim(), referenced_column:'id'};
}

function splitCSVLine(line) {
  const fields = [];
  let current = '', inQuotes = false;
  for (let i = 0; i < line.length; i++) {
    const c = line[i];
    if (c === '"') {
      if (inQuotes && line[i+1] === '"') { current += '"'; i++; }
      else inQuotes = !inQuotes;
    } else if (c === ',' && !inQuotes) { fields.push(current.trim()); current = ''; }
    else if (c === '\r') { /* skip */ }
    else current += c;
  }
  fields.push(current.trim());
  return fields;
}

function parseCSV(content, sourceName) {
  const lines = content.trim().split('\n');
  if (lines.length < 2) return {source_name:sourceName, source_type:'csv', tables:[], input_format:'csv', parse_warnings:['No data rows']};
  const headers = splitCSVLine(lines[0]).map(h=>h.toLowerCase());
  const findH = (syns) => { for (const s of syns) { const i = headers.indexOf(s); if (i>=0) return i; } return -1; };
  const iTT = findH(['target_table','tgt_table','to_table','dest_table','source_table','src_table']);
  const iTC = findH(['target_column','tgt_column','to_column','dest_column','source_column','src_column']);
  const iType = findH(['target_type','tgt_type','source_type','src_type','data_type','type']);
  const iPK = findH(['primary_key','pk','is_pk']);
  const iNull = findH(['nullable','is_nullable','null']);
  const iFKT = findH(['foreign_key_table','fk_table','ref_table','references_table']);
  const iFKC = findH(['foreign_key_column','fk_column','ref_column','references_column']);
  const tablesMap = {};
  for (let r = 1; r < lines.length; r++) {
    const vals = splitCSVLine(lines[r]);
    const tbl = iTT>=0?vals[iTT]:''; const col = iTC>=0?vals[iTC]:'';
    if (!tbl||!col) continue;
    if (!tablesMap[tbl]) tablesMap[tbl] = {columns:[], foreign_keys:[]};
    const dtype = (iType>=0?vals[iType]:'varchar').toLowerCase().split('(')[0];
    const nullable = iNull>=0 ? !['false','no','0'].includes(vals[iNull].toLowerCase()) : true;
    const pk = iPK>=0 ? ['true','yes','1','pk'].includes(vals[iPK].toLowerCase()) : false;
    tablesMap[tbl].columns.push({name:col, data_type:dtype, raw_type:iType>=0?vals[iType]:'varchar', nullable, is_primary_key:pk, is_unique:false, check_constraints:[], max_length:null, precision:null, scale:null, default_value:null});
    const fkTbl = iFKT>=0?vals[iFKT]:''; const fkCol = iFKC>=0?vals[iFKC]:'id';
    if (fkTbl) tablesMap[tbl].foreign_keys.push({fk_column:col, referenced_table:fkTbl, referenced_column:fkCol});
  }
  const tables = Object.entries(tablesMap).map(([n,d])=>({name:n, schema:'dbo', columns:d.columns, foreign_keys:d.foreign_keys, row_count:1000}));
  return {source_name:sourceName||'CSV Import', source_type:'csv', tables, input_format:'csv', parse_warnings:[]};
}

// ================================================================
// PARSERS — YAML (table definitions + dbt schema.yml)
// ================================================================
function parseSimpleYAML(text) {
  // Normalize tabs to 2 spaces and strip inline comments
  let normalized = text.replace(/\t/g, '  ');
  const lines = normalized.split('\n').map((l,i) => {
    // Strip inline comments (outside quotes)
    let tr = l.replace(/\s+#(?![^'"]*['"][^'"]*$).*$/, '').trimEnd();
    const ind = tr.search(/\S/) < 0 ? 999 : tr.search(/\S/);
    return {raw:l, ind, tr:tr.trim(), i};
  }).filter(l=>l.tr&&!l.tr.startsWith('#'));
  let pos = 0;
  function scalar(s) { s=s.trim(); if(s==='true')return true; if(s==='false')return false; if(s==='null'||s==='~'||!s)return null; if(/^-?\d+$/.test(s))return parseInt(s); if(/^-?\d+\.\d+$/.test(s))return parseFloat(s); return s.replace(/^['"]|['"]$/g,''); }
  function parseAt(base) {
    if(pos>=lines.length)return null;
    return lines[pos].tr.startsWith('-')?parseList(base):parseMap(base);
  }
  function parseMap(base) {
    const r={}; while(pos<lines.length&&lines[pos].ind>=base) {
      if(lines[pos].ind>base||lines[pos].tr.startsWith('-'))break;
      const ci=lines[pos].tr.indexOf(':'); if(ci<0){pos++;continue;}
      const k=lines[pos].tr.substring(0,ci).trim(), v=lines[pos].tr.substring(ci+1).trim(); pos++;
      if(v) r[k]=scalar(v); else if(pos<lines.length&&lines[pos].ind>base) r[k]=parseAt(lines[pos].ind); else r[k]=null;
    } return r;
  }
  function parseList(base) {
    const r=[]; while(pos<lines.length&&lines[pos].ind>=base) {
      if(lines[pos].ind>base&&!lines[pos].tr.startsWith('-'))break;
      if(!lines[pos].tr.startsWith('-'))break;
      const item=lines[pos].tr.substring(lines[pos].tr.indexOf('-')+1).trim();
      const itemInd=lines[pos].ind; pos++;
      if(item.includes(':')) {
        const obj={}; const ci=item.indexOf(':'); const k=item.substring(0,ci).trim(); const v=item.substring(ci+1).trim();
        if(v) obj[k]=scalar(v); else if(pos<lines.length&&lines[pos].ind>itemInd) obj[k]=parseAt(lines[pos].ind); else obj[k]=null;
        while(pos<lines.length&&lines[pos].ind>itemInd&&!lines[pos].tr.startsWith('-')) {
          const ci2=lines[pos].tr.indexOf(':'); if(ci2<0)break;
          const k2=lines[pos].tr.substring(0,ci2).trim(), v2=lines[pos].tr.substring(ci2+1).trim();
          const curInd=lines[pos].ind; pos++;
          if(v2) obj[k2]=scalar(v2); else if(pos<lines.length&&lines[pos].ind>curInd) obj[k2]=parseAt(lines[pos].ind); else obj[k2]=null;
        } r.push(obj);
      } else { r.push(item?scalar(item):null); }
    } return r;
  }
  if(!lines.length)return {}; return parseAt(lines[0].ind);
}

function parseYAML(content, sourceName) {
  const data = parseSimpleYAML(content);
  const tables = [];
  const src = data.tables || data.models || data.sources || [];
  if (!Array.isArray(src)) return {source_name:sourceName||'YAML',source_type:'yaml',tables:[],input_format:'yaml',parse_warnings:['No tables/models found']};
  src.forEach(t => {
    if (!t || !t.name) return;
    const cols = (t.columns||[]).map(c => {
      if (typeof c === 'string') { const p=c.split(':'); return {name:p[0].trim(),data_type:p[1]?p[1].trim():'varchar',raw_type:p[1]||'varchar',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}; }
      const dt = (c.type||c.data_type||'varchar').toLowerCase().split('(')[0];
      const pk = !!c.primary_key||!!c.pk||(Array.isArray(c.tests)&&(c.tests.includes('unique')||c.tests.includes('not_null')));
      return {name:c.name||'',data_type:TYPE_NORM[dt]||dt,raw_type:c.type||c.data_type||'varchar',nullable:c.nullable!==false,is_primary_key:pk,is_unique:false,check_constraints:c.accepted_values||[],max_length:c.length||null,precision:null,scale:null,default_value:null};
    });
    const fks = (t.foreign_keys||[]).map(fk=>({fk_column:fk.column||'',referenced_table:fk.references||fk.ref||'',referenced_column:fk.references_column||fk.ref_column||'id'}));
    tables.push({name:t.name,schema:t.schema||'dbo',columns:cols,foreign_keys:fks,row_count:1000});
  });
  return {source_name:sourceName||'YAML Import',source_type:'yaml',tables,input_format:'yaml',parse_warnings:[]};
}

// ================================================================
// PARSERS — PySpark (StructType / StructField)
// ================================================================
function parsePySpark(content, sourceName) {
  const tables = [], warnings = [];
  const sparkTypeMap = {string:'varchar',integer:'int',long:'bigint',short:'smallint',byte:'tinyint',float:'float',double:'double',decimal:'decimal',boolean:'boolean',date:'date',timestamp:'timestamp',binary:'binary',array:'text',map:'text',struct:'text',int:'int'};
  const stPat = /(?:(\w+)\s*=\s*)?StructType\s*\(\s*\[([\s\S]*?)\]\s*\)/g;
  let m;
  while ((m=stPat.exec(content))!==null) {
    const varName = m[1]||'table'; const body = m[2]; const cols = [];
    // Flexible: handles StringType() or StringType or "string" — with or without Type suffix
    const fPat = /StructField\s*\(\s*["']([^"']+)["']\s*,\s*(?:["'])?(\w+?)(?:Type)?(?:["'])?\s*(?:\(\s*(?:(\d+)(?:\s*,\s*(\d+))?)?\s*\))?\s*(?:,\s*(True|False|true|false))?\s*\)/g;
    let fm;
    while ((fm=fPat.exec(body))!==null) {
      const dt = sparkTypeMap[fm[2].toLowerCase()]||'varchar';
      cols.push({name:fm[1],data_type:dt,raw_type:fm[2]+'Type',nullable:fm[5]?fm[5].toLowerCase()!=='false':true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:fm[3]?parseInt(fm[3]):null,scale:fm[4]?parseInt(fm[4]):null,default_value:null});
    }
    if (cols.length) { const tn=varName.replace(/_?schema$/i,'')||'table'; tables.push({name:tn,schema:'default',columns:cols,foreign_keys:[],row_count:1000}); }
  }
  // Also try spark.sql("CREATE TABLE ...")
  const sqlM = content.match(/spark\.sql\s*\(\s*["']{1,3}([\s\S]*?)["']{1,3}\s*\)/);
  if (sqlM && /CREATE\s+TABLE/i.test(sqlM[1])) { const ddl = parseDDL(sqlM[1],'PySpark SQL'); tables.push(...ddl.tables); }
  return {source_name:sourceName||'PySpark Schema',source_type:'pyspark',tables,input_format:'pyspark',parse_warnings:warnings};
}

// ================================================================
// PARSERS — Scala (case class)
// ================================================================
function parseScala(content, sourceName) {
  const tables = [];
  const scalaTypeMap = {String:'varchar',Int:'int',Long:'bigint',Short:'smallint',Double:'double',Float:'float',BigDecimal:'decimal',Boolean:'boolean',Date:'date',Timestamp:'timestamp',Byte:'tinyint',Char:'char',Array:'text',List:'text',Seq:'text',Set:'text',Map:'text',Vector:'text',UUID:'varchar'};
  // Handle generic type params: case class Foo[T](...) — skip the [T] part
  const ccPat = /case\s+class\s+(\w+)(?:\[[\w\s,<>\[\]]+\])?\s*\(([\s\S]*?)\)/g;
  let m;
  while ((m=ccPat.exec(content))!==null) {
    const className = m[1]; const body = m[2]; const cols = [];
    const fPat = /(\w+)\s*:\s*(Option\s*\[\s*)?([\w.\[\],\s]+)\]?\s*/g;
    let fm;
    while ((fm=fPat.exec(body))!==null) {
      const nullable = !!fm[2]; let st = fm[3].trim().replace(/\s/g,'');
      // Extract inner type from generics: List[String] → String, Map[String,Int] → text
      if (/^(List|Seq|Set|Vector|Array)\[/.test(st)) st = 'Array';
      else if (/^Map\[/.test(st)) st = 'Map';
      else if (/^Option\[/.test(st)) { const inner = st.match(/^Option\[(\w+)\]/); if(inner) st = inner[1]; }
      // Smart CamelCase: HTTPServer → http_server, not h_t_t_p_server
      const dt = scalaTypeMap[st] || scalaTypeMap[st.replace(/.*\./, '')] || 'varchar';
      cols.push({name:fm[1],data_type:dt,raw_type:st,nullable,is_primary_key:fm[1].toLowerCase()==='id',is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null});
    }
    if (cols.length) {
      const tn = className.replace(/([A-Z]+)([A-Z][a-z])/g,'$1_$2').replace(/([a-z])([A-Z])/g,'$1_$2').toLowerCase();
      tables.push({name:tn,schema:'default',columns:cols,foreign_keys:[],row_count:1000});
    }
  }
  return {source_name:sourceName||'Scala Case Classes',source_type:'scala',tables,input_format:'scala',parse_warnings:[]};
}

// ================================================================
// PARSERS — dbt (model SQL with Jinja)
// ================================================================
function parseDBT(content, sourceName) {
  const tables = [], warnings = [];
  const refs = [];
  const refPat = /\{\{\s*(?:ref|source)\s*\(\s*['"](\w+)['"](?:\s*,\s*['"](\w+)['"])?\s*\)\s*\}\}/g;
  let rm; while ((rm=refPat.exec(content))!==null) refs.push(rm[2]||rm[1]);
  let cleanSQL = content.replace(/\{\{[\s\S]*?\}\}/g,'__JINJA__').replace(/\{%[\s\S]*?%\}/g,'');
  // Strip window functions OVER(...) before column extraction
  cleanSQL = cleanSQL.replace(/\bOVER\s*\([^)]*\)/gi, '');
  if (/CREATE\s+TABLE/i.test(cleanSQL)) return parseDDL(cleanSQL.replace(/__JINJA__/g,'dual'), sourceName||'dbt Model');
  // Handle CTEs: WITH cte AS (SELECT ...) SELECT ... — use the final SELECT
  let selectSQL = cleanSQL;
  const cteMatch = cleanSQL.match(/\bWITH\b[\s\S]*?\)\s*(SELECT[\s\S]*$)/i);
  if (cteMatch) selectSQL = cteMatch[1];
  const selM = selectSQL.match(/SELECT\s+([\s\S]*?)\s+FROM/i);
  if (selM) {
    const cols = []; const parts = selM[1].split(',').map(c=>c.trim()).filter(Boolean);
    for (const p of parts) {
      if (p==='*' || p==='__JINJA__') continue;
      const asM = p.match(/(?:AS\s+)?["']?(\w+)["']?\s*$/i); if (!asM) continue;
      let dt = 'varchar'; const castM = p.match(/(?:CAST\s*\(.*?AS\s+(\w+)|::(\w+))/i);
      if (castM) dt = (castM[1]||castM[2]).toLowerCase();
      cols.push({name:asM[1],data_type:TYPE_NORM[dt]||dt,raw_type:dt,nullable:true,is_primary_key:cols.length===0&&asM[1].toLowerCase().endsWith('_id'),is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null});
    }
    if (cols.length) { const cfgM=content.match(/alias\s*=\s*['"](\w+)['"]/); tables.push({name:cfgM?cfgM[1]:'dbt_model',schema:'dbt',columns:cols,foreign_keys:[],row_count:1000}); }
  }
  return {source_name:sourceName||'dbt Model',source_type:'dbt',tables,input_format:'dbt',parse_warnings:refs.length?['References: '+refs.join(', ')]:warnings};
}

// ================================================================
// PARSERS — Avro (.avsc)
// ================================================================
function avroTypeMap(t) {
  const m={null:'varchar',boolean:'boolean',int:'int',long:'bigint',float:'float',double:'double',bytes:'binary',string:'varchar',fixed:'binary',enum:'varchar',array:'text',map:'text',record:'text',decimal:'decimal',date:'date','time-millis':'int','timestamp-millis':'timestamp','timestamp-micros':'timestamp',uuid:'varchar'};
  return m[t]||'varchar';
}
function parseAvro(content, sourceName) {
  let data; try { data = JSON.parse(content.trim()); } catch(e) { return {source_name:sourceName||'Avro',source_type:'avro',tables:[],input_format:'avro',parse_warnings:['Invalid JSON in Avro: '+e.message]}; }
  const tables = [];
  function parseRecord(rec) {
    if (!rec||rec.type!=='record'||!rec.fields) return null;
    const cols = rec.fields.map(f => {
      let dt='varchar',nullable=false,raw='';
      if (typeof f.type==='string') { raw=f.type; dt=avroTypeMap(f.type); }
      else if (Array.isArray(f.type)) { nullable=f.type.includes('null'); const nn=f.type.filter(t=>t!=='null')[0]; raw=typeof nn==='string'?nn:JSON.stringify(nn); dt=typeof nn==='string'?avroTypeMap(nn):avroTypeMap((nn&&nn.logicalType)||nn?.type||'string'); }
      else if (typeof f.type==='object') { raw=f.type.logicalType||f.type.type||'string'; dt=avroTypeMap(f.type.logicalType||f.type.type); }
      return {name:f.name,data_type:dt,raw_type:raw,nullable,is_primary_key:/^(id|key)$/i.test(f.name),is_unique:false,check_constraints:[],max_length:null,precision:f.type?.precision||null,scale:f.type?.scale||null,default_value:f.default??null};
    });
    const tn=rec.name.replace(/([A-Z])/g,'_$1').toLowerCase().replace(/^_/,'');
    return {name:tn,schema:rec.namespace||'default',columns:cols,foreign_keys:[],row_count:1000};
  }
  if (data.type==='record') { const t=parseRecord(data); if(t)tables.push(t); }
  else if (Array.isArray(data)) data.forEach(d=>{const t=parseRecord(d);if(t)tables.push(t);});
  return {source_name:sourceName||'Avro Schema',source_type:'avro',tables,input_format:'avro',parse_warnings:[]};
}

// ================================================================
// PARSERS — Protobuf (.proto)
// ================================================================
function parseProtobuf(content, sourceName) {
  const tables = [];
  const protoTypeMap={double:'double',float:'float',int32:'int',int64:'bigint',uint32:'int',uint64:'bigint',sint32:'int',sint64:'bigint',fixed32:'int',fixed64:'bigint',sfixed32:'int',sfixed64:'bigint',bool:'boolean',string:'varchar',bytes:'binary'};
  // Strip comments
  let clean = content.replace(/\/\*[\s\S]*?\*\//g, ' ').replace(/\/\/[^\n]*/g, '');
  // Depth-aware message extraction to handle nested messages
  function extractMessages(src, prefix) {
    const msgPat = /message\s+(\w+)\s*\{/g;
    let mm;
    while ((mm=msgPat.exec(src))!==null) {
      const msgName = mm[1]; let depth=1, i=mm.index+mm[0].length;
      while (i < src.length && depth > 0) { if(src[i]==='{')depth++; else if(src[i]==='}')depth--; i++; }
      const body = src.substring(mm.index+mm[0].length, i-1);
      const cols = [];
      // Parse fields including map<K,V>
      const fPat = /(?:(optional|required|repeated)\s+)?(?:map\s*<\s*\w+\s*,\s*\w+\s*>|(\w+))\s+(\w+)\s*=\s*\d+/g;
      let fm;
      while ((fm=fPat.exec(body))!==null) {
        if (fm[0].includes('map<')) {
          cols.push({name:fm[3],data_type:'text',raw_type:'map',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null});
        } else if (fm[2] && !['message','enum','oneof','option','reserved','extensions'].includes(fm[2])) {
          cols.push({name:fm[3],data_type:protoTypeMap[fm[2]]||'varchar',raw_type:fm[2],nullable:fm[1]!=='required',is_primary_key:fm[3].toLowerCase()==='id',is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null});
        }
      }
      // Extract oneof fields
      const oneofPat = /oneof\s+\w+\s*\{([\s\S]*?)\}/g;
      let om;
      while ((om=oneofPat.exec(body))!==null) {
        const ofPat = /(\w+)\s+(\w+)\s*=\s*\d+/g; let ofm;
        while ((ofm=ofPat.exec(om[1]))!==null) {
          cols.push({name:ofm[2],data_type:protoTypeMap[ofm[1]]||'varchar',raw_type:ofm[1],nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null});
        }
      }
      // Extract enum values as check constraints
      const enumPat = /enum\s+(\w+)\s*\{([\s\S]*?)\}/g;
      let em;
      while ((em=enumPat.exec(body))!==null) {
        const enumVals = []; const evPat = /(\w+)\s*=\s*\d+/g; let evm;
        while ((evm=evPat.exec(em[2]))!==null) enumVals.push(evm[1]);
        const enumCol = cols.find(c=>c.raw_type.toLowerCase()===em[1].toLowerCase());
        if (enumCol) enumCol.check_constraints = enumVals;
      }
      if (cols.length) {
        const fullName = prefix ? prefix+'_'+msgName : msgName;
        const tn = fullName.replace(/([A-Z]+)([A-Z][a-z])/g,'$1_$2').replace(/([a-z])([A-Z])/g,'$1_$2').toLowerCase();
        tables.push({name:tn,schema:'default',columns:cols,foreign_keys:[],row_count:1000});
      }
      // Recurse for nested messages
      extractMessages(body, prefix ? prefix+'_'+msgName : msgName);
    }
  }
  extractMessages(clean, '');
  return {source_name:sourceName||'Protobuf Schema',source_type:'protobuf',tables,input_format:'protobuf',parse_warnings:[]};
}

// ================================================================
// PARSERS — Spark printSchema output
// ================================================================
function parseSparkSchema(content, sourceName) {
  const cols = [];
  const fPat = /\|--\s+(\w+):\s+(\w+)(?:\(([^)]*)\))?\s*\(nullable\s*=\s*(true|false)\)/g;
  let m;
  while ((m=fPat.exec(content))!==null) {
    const sparkMap={string:'varchar',integer:'int',long:'bigint',short:'smallint',byte:'tinyint',float:'float',double:'double',decimal:'decimal',boolean:'boolean',date:'date',timestamp:'timestamp',binary:'binary'};
    cols.push({name:m[1],data_type:sparkMap[m[2]]||'varchar',raw_type:m[2]+(m[3]?`(${m[3]})`:''),nullable:m[4]==='true',is_primary_key:m[1]==='id',is_unique:false,check_constraints:[],max_length:null,precision:m[3]?parseInt(m[3].split(',')[0]):null,scale:m[3]&&m[3].includes(',')?parseInt(m[3].split(',')[1]):null,default_value:null});
  }
  if (!cols.length) return null;
  return {source_name:sourceName||'Spark Schema',source_type:'spark',tables:[{name:'spark_table',schema:'default',columns:cols,foreign_keys:[],row_count:1000}],input_format:'spark_schema',parse_warnings:[]};
}

// ================================================================
// PARSERS — Informatica XML (PowerCenter / IICS)
// ================================================================
function parseInformaticaXML(doc, sourceName) {
  const tables = [];
  const allEls = [...doc.querySelectorAll('*')];
  function findByLocal(name) { return allEls.filter(el => el.localName.toLowerCase() === name.toLowerCase()); }
  function getAttr(el, names) { for (const n of names) { const v = el.getAttribute(n); if (v != null) return v; } return ''; }
  function parseFields(parent, fieldNames) {
    const cols = [];
    const children = [...parent.querySelectorAll('*')].filter(el => fieldNames.some(fn => el.localName.toLowerCase() === fn));
    children.forEach(sf => {
      const cn = getAttr(sf, ['NAME','name','Name']); if(!cn) return;
      const rt = getAttr(sf, ['DATATYPE','datatype','DataType','type'])||'varchar';
      const prec = parseInt(getAttr(sf, ['PRECISION','precision','Precision'])||'0')||0;
      const scale = parseInt(getAttr(sf, ['SCALE','scale','Scale'])||'0')||0;
      const nullVal = getAttr(sf, ['NULLABLE','nullable','Nullable'])||'NULL';
      const nullable = nullVal !== 'NOTNULL' && nullVal.toLowerCase() !== 'false';
      const keyType = getAttr(sf, ['KEYTYPE','keytype','KeyType'])||'';
      const pk = keyType === 'PRIMARY KEY' || keyType.toLowerCase() === 'primary';
      const dt = TYPE_NORM[rt.toLowerCase()]||rt.toLowerCase().split('(')[0];
      cols.push({name:cn,data_type:dt,raw_type:rt,nullable,is_primary_key:pk,is_unique:false,check_constraints:[],max_length:prec||null,precision:['decimal','numeric','number'].includes(dt)?prec:null,scale:scale||null,default_value:null});
    });
    return cols;
  }
  // Find SOURCE elements (any case, any namespace)
  findByLocal('source').forEach(src => {
    const name = getAttr(src, ['NAME','name','Name']); if(!name) return;
    const cols = parseFields(src, ['sourcefield']);
    if (cols.length) tables.push({name,schema:'dbo',columns:cols,foreign_keys:[],row_count:1000});
  });
  findByLocal('target').forEach(tgt => {
    const name = getAttr(tgt, ['NAME','name','Name']); if(!name) return;
    if (tables.find(t=>t.name===name)) return;
    const cols = parseFields(tgt, ['targetfield']);
    if (cols.length) tables.push({name,schema:'dbo',columns:cols,foreign_keys:[],row_count:1000});
  });
  return {source_name:sourceName||'Informatica Import',source_type:'informatica',tables,input_format:'informatica_xml',parse_warnings:[]};
}

// ================================================================
// PARSERS — Talend XML
// ================================================================
function parseTalendXML(doc, sourceName) {
  const tables = [];
  const talendTypeMap = {id_String:'varchar',id_Integer:'int',id_Long:'bigint',id_Short:'smallint',id_Byte:'tinyint',id_Float:'float',id_Double:'double',id_BigDecimal:'decimal',id_Boolean:'boolean',id_Date:'date',id_Character:'char',id_byte_array:'binary',id_Object:'text',id_List:'text',id_Document:'text',id_Dynamic:'text'};
  doc.querySelectorAll('schema, Schema, metadata').forEach(schema => {
    const name = schema.getAttribute('name')||schema.getAttribute('Name')||schema.getAttribute('label')||'talend_table';
    const cols = [];
    schema.querySelectorAll('column, Column').forEach(col => {
      const cn = col.getAttribute('name')||col.getAttribute('label')||''; if(!cn) return;
      const tt = col.getAttribute('type')||col.getAttribute('talendType')||'id_String';
      const length = parseInt(col.getAttribute('length')||'0');
      const nullable = (col.getAttribute('nullable')||'true')!=='false';
      const pk = (col.getAttribute('key')||'false')==='true';
      cols.push({name:cn,data_type:talendTypeMap[tt]||'varchar',raw_type:tt,nullable,is_primary_key:pk,is_unique:false,check_constraints:[],max_length:length||null,precision:null,scale:null,default_value:null});
    });
    if (cols.length) tables.push({name,schema:'dbo',columns:cols,foreign_keys:[],row_count:1000});
  });
  return {source_name:sourceName||'Talend Import',source_type:'talend',tables,input_format:'talend_xml',parse_warnings:[]};
}

// ================================================================
// PARSERS — Apache NiFi XML (template / flow definition)
// ================================================================
function parseNiFiXML(doc, sourceName) {
  const tables = [], processors = [], connections = [], controllerServices = [], processGroups = [];
  const idToName = {};

  // NiFi templates nest everything: template > snippet > processGroups > contents > processors
  // Recursively extract all processors, connections, etc. from nested processGroups
  function extractFromGroup(groupEl, groupName) {
    const contents = groupEl.querySelector(':scope > contents') || groupEl;
    // Processors — direct children of contents
    contents.querySelectorAll(':scope > processors').forEach(proc => {
      const name = getChildText(proc, 'name');
      const type = getChildText(proc, 'type');
      const shortType = type.split('.').pop();
      const state = getChildText(proc, 'state');
      const props = extractProperties(proc);
      const schedPeriod = proc.querySelector('config > schedulingPeriod')?.textContent || '';
      const schedStrategy = proc.querySelector('config > schedulingStrategy')?.textContent || '';
      const id = getChildText(proc, 'id');
      if (id) idToName[id] = name || shortType;
      processors.push({name, type:shortType, fullType:type, state, properties:props, group:groupName, schedulingPeriod:schedPeriod, schedulingStrategy:schedStrategy, _id:id||('gen_'+processors.length)});
    });
    // Connections — direct children of contents
    contents.querySelectorAll(':scope > connections').forEach(conn => {
      const srcId = conn.querySelector('source > id')?.textContent || getChildText(conn, 'sourceId') || '';
      const dstId = conn.querySelector('destination > id')?.textContent || getChildText(conn, 'destinationId') || '';
      const srcType = conn.querySelector('source > type')?.textContent || '';
      const dstType = conn.querySelector('destination > type')?.textContent || '';
      const rels = [];
      conn.querySelectorAll(':scope > selectedRelationships').forEach(r => { if(r.textContent) rels.push(r.textContent); });
      const bp = getChildText(conn, 'backPressureObjectThreshold');
      connections.push({sourceId:srcId, destinationId:dstId, sourceType:srcType, destinationType:dstType, relationships:rels, backPressure:bp});
    });
    // Input/output ports
    contents.querySelectorAll(':scope > inputPorts').forEach(p => {
      const id = getChildText(p, 'id'), name = getChildText(p, 'name');
      if(id) idToName[id] = name || 'input_port';
    });
    contents.querySelectorAll(':scope > outputPorts').forEach(p => {
      const id = getChildText(p, 'id'), name = getChildText(p, 'name');
      if(id) idToName[id] = name || 'output_port';
    });
    // Nested processGroups
    contents.querySelectorAll(':scope > processGroups').forEach(pg => {
      const pgName = getChildText(pg, 'name');
      const pgId = getChildText(pg, 'id');
      if(pgId) idToName[pgId] = pgName;
      processGroups.push({name:pgName, parentGroup:groupName});
      extractFromGroup(pg, pgName);
    });
  }

  function getChildText(el, tag) {
    const child = el.querySelector(':scope > ' + tag);
    return child ? child.textContent.trim() : '';
  }

  function extractProperties(el) {
    const props = {};
    // NiFi template format: config > properties > entry > key + value
    el.querySelectorAll('config > properties > entry').forEach(entry => {
      const key = entry.querySelector(':scope > key')?.textContent || '';
      const valEl = entry.querySelector(':scope > value');
      if (key && valEl) props[key] = valEl.textContent || '';
    });
    // Also try direct properties > entry (for controllerServices at snippet level)
    if (!Object.keys(props).length) {
      el.querySelectorAll(':scope > properties > entry').forEach(entry => {
        const key = entry.querySelector(':scope > key')?.textContent || '';
        const valEl = entry.querySelector(':scope > value');
        if (key && valEl) props[key] = valEl.textContent || '';
      });
    }
    return props;
  }

  // Start from snippet (template format), flowController (NiFi registry), or root
  const snippet = doc.querySelector('template > snippet') || doc.querySelector('snippet') ||
    doc.querySelector('flowController > rootGroup') || doc.querySelector('rootGroup') ||
    doc.querySelector('processGroupFlow > flow') || doc.documentElement;

  // Top-level controllerServices
  snippet.querySelectorAll(':scope > controllerServices').forEach(cs => {
    const name = getChildText(cs, 'name');
    const type = getChildText(cs, 'type');
    const state = getChildText(cs, 'state');
    const props = {};
    cs.querySelectorAll(':scope > properties > entry').forEach(entry => {
      const key = entry.querySelector(':scope > key')?.textContent || '';
      const valEl = entry.querySelector(':scope > value');
      if (key && valEl) props[key] = valEl.textContent || '';
    });
    controllerServices.push({name, type:type.split('.').pop(), fullType:type, state, properties:props});
  });

  // Top-level processGroups
  snippet.querySelectorAll(':scope > processGroups').forEach(pg => {
    const pgName = getChildText(pg, 'name');
    const pgId = getChildText(pg, 'id');
    if(pgId) idToName[pgId] = pgName;
    processGroups.push({name:pgName, parentGroup:'(root)'});
    extractFromGroup(pg, pgName);
  });

  // Also check for top-level processors directly in snippet
  snippet.querySelectorAll(':scope > processors').forEach(proc => {
    const name = getChildText(proc, 'name');
    const type = getChildText(proc, 'type');
    const id = getChildText(proc, 'id');
    if(id) idToName[id] = name || type.split('.').pop();
    const props = extractProperties(proc);
    processors.push({name, type:type.split('.').pop(), fullType:type, state:getChildText(proc,'state'), properties:props, group:'(root)', schedulingPeriod:'', schedulingStrategy:'', _id:id||('gen_'+processors.length)});
  });

  // Resolve connection IDs to processor names
  connections.forEach(c => {
    c.sourceName = idToName[c.sourceId] || c.sourceId.substring(0,12)+'...';
    c.destinationName = idToName[c.destinationId] || c.destinationId.substring(0,12)+'...';
  });

  // Extract SQL and table refs from processor properties
  const sqlTables = new Set();
  processors.forEach(p => {
    Object.values(p.properties).forEach(v => {
      if (!v) return;
      // Try to find CREATE TABLE
      if (/CREATE\s+(?:EXTERNAL\s+)?TABLE/i.test(v)) {
        try { const r = parseDDL(v, p.name); tables.push(...r.tables); } catch(e) {}
      }
      // Extract table name refs from SQL
      const tblRefs = v.match(/(?:FROM|JOIN|INTO|TABLE|UPDATE)\s+(?:\$\{[^}]+\}|[\w.]+)/gi);
      if (tblRefs) tblRefs.forEach(m => {
        const tn = m.replace(/^(FROM|JOIN|INTO|TABLE|UPDATE)\s+/i,'').trim();
        if (tn && !tn.startsWith('(') && tn.length > 2 && !/^(select|where|set|and|or|as|on|in|is|not|null|case|when|then|else|end|group|order|by|having|limit|offset|union|all|exists|between|like|true|false|values|into|for|if|with|from|table|now|production|varchar|int|bigint|text|date|timestamp|decimal|boolean|float|double)$/i.test(tn)) sqlTables.add(tn);
      });
    });
    // Extract table names from specific NiFi properties
    ['Table Name','table-name','put-db-record-table-name'].forEach(k => {
      if (p.properties[k]) sqlTables.add(p.properties[k]);
    });
  });

  // Build NiFi flow inventory tables (always — this IS the synthetic env for a NiFi flow)
  const procTypes = processors.map(p=>p.type).filter((v,i,a)=>a.indexOf(v)===i);
  const procGroups = processors.map(p=>p.group).filter((v,i,a)=>a.indexOf(v)===i);
  const procStates = processors.map(p=>p.state).filter(Boolean).filter((v,i,a)=>a.indexOf(v)===i);

  tables.push({name:'nifi_processors', schema:'nifi_flow', row_count:processors.length, columns:[
    {name:'processor_name',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
    {name:'processor_type',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:procTypes.slice(0,50),max_length:200,precision:null,scale:null,default_value:null},
    {name:'process_group',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:procGroups,max_length:200,precision:null,scale:null,default_value:null},
    {name:'state',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:procStates,max_length:20,precision:null,scale:null,default_value:null},
    {name:'scheduling_strategy',data_type:'varchar',raw_type:'string',nullable:true,is_primary_key:false,is_unique:false,check_constraints:['TIMER_DRIVEN','CRON_DRIVEN','EVENT_DRIVEN'],max_length:30,precision:null,scale:null,default_value:null},
    {name:'scheduling_period',data_type:'varchar',raw_type:'string',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:50,precision:null,scale:null,default_value:null},
    {name:'property_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
  ], foreign_keys:[]});

  if (connections.length) {
    const relTypes = connections.flatMap(c=>c.relationships).filter((v,i,a)=>a.indexOf(v)===i);
    tables.push({name:'nifi_connections', schema:'nifi_flow', row_count:connections.length, columns:[
      {name:'connection_id',data_type:'int',raw_type:'int',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
      {name:'source_processor',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'destination_processor',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'relationship',data_type:'varchar',raw_type:'string',nullable:true,is_primary_key:false,is_unique:false,check_constraints:relTypes.slice(0,20),max_length:100,precision:null,scale:null,default_value:null},
      {name:'back_pressure_threshold',data_type:'int',raw_type:'int',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
    ], foreign_keys:[{fk_column:'source_processor',referenced_table:'nifi_processors',referenced_column:'processor_name'}]});
  }

  if (processGroups.length) {
    tables.push({name:'nifi_process_groups', schema:'nifi_flow', row_count:processGroups.length, columns:[
      {name:'group_name',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'parent_group',data_type:'varchar',raw_type:'string',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'processor_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null},
      {name:'connection_count',data_type:'int',raw_type:'int',nullable:false,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
    ], foreign_keys:[]});
  }

  if (controllerServices.length) {
    tables.push({name:'nifi_controller_services', schema:'nifi_flow', row_count:controllerServices.length, columns:[
      {name:'service_name',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'service_type',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:controllerServices.map(s=>s.type).filter((v,i,a)=>a.indexOf(v)===i),max_length:200,precision:null,scale:null,default_value:null},
      {name:'state',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:['ENABLED','DISABLED','ENABLING','DISABLING'],max_length:20,precision:null,scale:null,default_value:null},
      {name:'config_json',data_type:'text',raw_type:'text',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:null,precision:null,scale:null,default_value:null}
    ], foreign_keys:[]});
  }

  // If SQL references found, add a reference table
  if (sqlTables.size) {
    const refs = [...sqlTables];
    tables.push({name:'nifi_sql_table_refs', schema:'nifi_flow', row_count:refs.length, columns:[
      {name:'table_reference',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:true,is_unique:true,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null},
      {name:'reference_type',data_type:'varchar',raw_type:'string',nullable:false,is_primary_key:false,is_unique:false,check_constraints:['table','variable','external_table'],max_length:50,precision:null,scale:null,default_value:null},
      {name:'referenced_by_processor',data_type:'varchar',raw_type:'string',nullable:true,is_primary_key:false,is_unique:false,check_constraints:[],max_length:200,precision:null,scale:null,default_value:null}
    ], foreign_keys:[]});
  }

  const warnings = [];
  if (sqlTables.size) warnings.push(`Found ${sqlTables.size} SQL table references: ${[...sqlTables].slice(0,10).join(', ')}${sqlTables.size>10?'...':''}`);

  const result = {source_name:sourceName||'Apache NiFi Flow', source_type:'nifi', tables, input_format:'nifi_xml', parse_warnings:warnings};
  result._nifi = {processors, connections, controllerServices, processGroups, sqlTables:[...sqlTables]};
  return result;
}

// ================================================================
// RESOURCE MANIFEST — Identifies ALL resources needed by NiFi flow
// ================================================================
function buildResourceManifest(nifi) {
  const dirs = {}, files = {}, sqlTbls = {}, tokens = {}, signals = {};
  const httpEndpoints = [], kafkaTopics = [], dbConnections = [], scripts = [], parameters = [], counters = [];
  const connectedIds = new Set();
  const NIFI_EL_FUNCS = new Set(['now','nextInt','UUID','hostname','IP','literal','thread','format','toDate','substring','substringBefore','substringAfter','replace','replaceAll','replaceFirst','replaceEmpty','replaceNull','toUpper','toLower','trim','length','isEmpty','equals','equalsIgnoreCase','contains','startsWith','endsWith','append','prepend','plus','minus','multiply','divide','mod','gt','ge','lt','le','and','or','not','ifElse','toString','toNumber','math','getStateValue','count','padLeft','padRight','escapeJson','escapeXml','escapeCsv','unescapeJson','unescapeXml','urlEncode','urlDecode','base64Encode','base64Decode','toRadix','jsonPath','jsonPathDelete','jsonPathAdd','jsonPathSet','jsonPathPut']);

  function addDir(path, type, proc) {
    if (!path || path.includes('${')) return;
    if (!dirs[path]) dirs[path] = { type, processors: [] };
    dirs[path].processors.push(proc);
  }
  function addFile(path, role, proc, fmt) {
    if (!path) return;
    if (!files[path]) files[path] = { producers: [], consumers: [], format: fmt || 'unknown' };
    if (role === 'read') files[path].consumers.push(proc);
    else files[path].producers.push(proc);
  }
  function addSqlTable(name, role, proc) {
    if (!name || name === 'dual' || name.length < 2) return;
    const n = name.replace(/^["'`]+|["'`]+$/g, '').trim();
    if (!n || /^(waiting|because|account|log|Dates|LeadLag|startGrouping|grps|Temptation)$/i.test(n)) return;
    if (!sqlTbls[n]) sqlTbls[n] = { readers: [], writers: [] };
    if (role === 'read') sqlTbls[n].readers.push(proc);
    else sqlTbls[n].writers.push(proc);
  }
  function findUnresolvedEL(value, proc) {
    if (!value || typeof value !== 'string') return;
    const matches = value.match(/\$\{([^}]+)\}/g);
    if (!matches) return;
    matches.forEach(m => {
      const inner = m.slice(2, -1);
      const funcName = inner.split(':')[0].trim();
      if (!NIFI_EL_FUNCS.has(funcName) && !funcName.includes('.') && !/^(filename|path|absolute\.path|uuid|fileSize|file\.size|entryDate|lineageStartDate|flowfile)/.test(funcName)) {
        parameters.push({ expr: m, processor: proc, attrName: funcName, resolved: false });
      }
    });
  }

  // Scan connections for connected processor IDs
  (nifi.connections || []).forEach(c => {
    if (c.sourceType === 'PROCESSOR') connectedIds.add(c.sourceId || c.sourceName);
    if (c.destinationType === 'PROCESSOR') connectedIds.add(c.destinationId || c.destinationName);
    connectedIds.add(c.sourceName); connectedIds.add(c.destinationName);
  });

  // Scan each processor
  (nifi.processors || []).forEach(p => {
    const props = p.properties || {};
    const pName = p.name;
    const t = p.type;

    // Scan ALL properties for unresolved expressions
    Object.entries(props).forEach(([k, v]) => findUnresolvedEL(v, pName));

    // Per-type resource extraction
    if (t === 'GetFile') {
      const dir = props['Input Directory']; addDir(dir, 'input', pName);
      if (dir) addFile(dir + '/*.csv', 'read', pName, 'csv');
    } else if (t === 'ListFile') {
      const dir = props['Input Directory']; addDir(dir, 'input', pName);
    } else if (t === 'FetchFile') {
      const fp = props['File to Fetch'] || props['Filename']; addFile(fp || '(dynamic)', 'read', pName);
    } else if (t === 'PutFile') {
      const dir = props['Directory']; addDir(dir, 'output', pName);
    } else if (t === 'PutSFTP') {
      const host = props['Hostname'] || 'sftp-host';
      const rp = props['Remote Path'] || '/';
      addDir(`sftp://${host}${rp}`, 'output', pName);
      addFile(`sftp://${host}${rp}/(dynamic)`, 'write', pName);
    } else if (t === 'PutHDFS' || t === 'PutParquet') {
      const dir = props['Directory'] || props['directory']; addDir(dir, 'output', pName);
    } else if (t === 'ExecuteSQL' || t === 'ExecuteSQLRecord') {
      const sql = props['SQL select query'] || props['sql-select-query'] || '';
      const tblRefs = sql.match(/(?:FROM|JOIN)\s+([\w$.{}"]+)/gi);
      if (tblRefs) tblRefs.forEach(r => {
        const tn = r.replace(/^(FROM|JOIN)\s+/i, '').trim();
        addSqlTable(tn, 'read', pName);
      });
      const dbcp = props['Database Connection Pooling Service'] || props['dbcp-service'];
      if (dbcp) dbConnections.push({ name: dbcp, processor: pName, type: 'read' });
    } else if (t === 'PutDatabaseRecord' || t === 'PutSQL') {
      const tn = props['Table Name'] || props['table-name'] || props['put-db-record-table-name'];
      addSqlTable(tn, 'write', pName);
      const dbcp = props['Database Connection Pooling Service'] || props['dbcp-service'];
      if (dbcp) dbConnections.push({ name: dbcp, processor: pName, type: 'write' });
    } else if (t === 'ExecuteStreamCommand') {
      const cmd = props['Command'] || '';
      const args = props['Command Arguments'] || '';
      if (cmd) scripts.push({ path: cmd, args, processor: pName });
      // Check for hdfs/impala/kinit patterns in args
      if (/hdfs\s+dfs/.test(args)) {
        const hdfsMatch = args.match(/(?:-cp|-mv|-put|-get|-ls|-rm)\s+(\S+)/);
        if (hdfsMatch) addDir(hdfsMatch[1], args.includes('-ls') ? 'input' : 'output', pName);
      }
    } else if (t === 'InvokeHTTP') {
      const url = props['Remote URL'] || props['remote-url'] || '';
      const method = props['HTTP Method'] || props['http-method'] || 'GET';
      if (url) httpEndpoints.push({ url, method, processor: pName });
    } else if (t === 'ConsumeKafka_2_6' || t === 'ConsumeKafka' || t === 'ConsumeKafkaRecord_2_6') {
      const topic = props['Topic Name(s)'] || props['topic'] || '';
      const brokers = props['Kafka Brokers'] || props['bootstrap.servers'] || '';
      if (topic) kafkaTopics.push({ topic, brokers, processor: pName, direction: 'consume' });
    } else if (t === 'PublishKafka_2_6' || t === 'PublishKafka' || t === 'PublishKafkaRecord_2_6') {
      const topic = props['Topic Name(s)'] || props['topic'] || '';
      const brokers = props['Kafka Brokers'] || props['bootstrap.servers'] || '';
      if (topic) kafkaTopics.push({ topic, brokers, processor: pName, direction: 'produce' });
    } else if (t === 'Wait') {
      const sn = props['Signal Counter Name'] || '';
      const target = parseInt(props['Target Signal Count']) || 1;
      if (sn) { if (!signals[sn]) signals[sn] = { senders: [], waiters: [], target }; signals[sn].waiters.push(pName); }
    } else if (t === 'Notify') {
      const sn = props['Signal Counter Name'] || '';
      if (sn) { if (!signals[sn]) signals[sn] = { senders: [], waiters: [], target: 1 }; signals[sn].senders.push(pName); }
    } else if (t === 'ControlRate') {
      const tn = 'rate_' + pName.replace(/\s+/g, '_');
      tokens[tn] = { acquirers: [pName], releasers: [pName] };
    } else if (t === 'LogMessage') {
      counters.push({ name: 'log_' + pName, processor: pName });
    } else if (t === 'LookupAttribute' || t === 'LookupRecord') {
      addSqlTable('lookup_' + pName.replace(/\s+/g, '_').toLowerCase(), 'read', pName);
    }
  });

  // Scan controller services for DB connections
  (nifi.controllerServices || []).forEach(cs => {
    const props = cs.properties || {};
    const url = props['Database Connection URL'] || props['database-connection-url'] || '';
    if (url || cs.type.includes('DBCP') || cs.type.includes('ConnectionPool')) {
      dbConnections.push({ name: cs.name, url: url ? url.replace(/password=[^&;]+/gi, 'password=***') : '', processor: '(controller service)', type: 'service' });
    }
  });

  // Detect disconnected processors
  const disconnected = (nifi.processors || []).filter(p => !connectedIds.has(p.name) && !connectedIds.has(p.id));

  // Deduplicate parameters
  const uniqueParams = [];
  const seenParams = new Set();
  parameters.forEach(p => { const k = p.expr + '|' + p.processor; if (!seenParams.has(k)) { seenParams.add(k); uniqueParams.push(p); } });

  // Summary counts
  const totalResources = Object.keys(dirs).length + Object.keys(files).length + Object.keys(sqlTbls).length +
    Object.keys(tokens).length + Object.keys(signals).length + httpEndpoints.length + kafkaTopics.length +
    scripts.length + dbConnections.length + counters.length;

  return {
    directories: dirs, files, sqlTables: sqlTbls, tokens, signals,
    httpEndpoints, kafkaTopics, dbConnections, scripts,
    parameters: uniqueParams, counters, disconnected,
    totalResources,
    warnings: [
      ...disconnected.map(p => `Processor "${p.name}" (${p.type}) has no connections — may never execute`),
      ...uniqueParams.filter(p => !p.resolved).slice(0, 10).map(p => `Unresolved expression ${p.expr} in "${p.processor}"`),
      ...(dbConnections.filter(d => d.type !== 'service').length > 0 && dbConnections.filter(d => d.type === 'service').length === 0 ?
        ['Processors reference DB connections but no DBCP controller service found'] : [])
    ]
  };
}

function renderManifestHTML(manifest) {
  const m = manifest;
  const dirCount = Object.keys(m.directories).length;
  const fileCount = Object.keys(m.files).length;
  const sqlCount = Object.keys(m.sqlTables).length;
  const tokCount = Object.keys(m.tokens).length;
  const sigCount = Object.keys(m.signals).length;

  let h = '<div class="manifest-grid">';
  h += `<div class="manifest-stat"><div class="num">${dirCount}</div><div class="lbl">Directories</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${fileCount}</div><div class="lbl">Files</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${sqlCount}</div><div class="lbl">SQL Tables</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${tokCount}</div><div class="lbl">Tokens</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${sigCount}</div><div class="lbl">Signals</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${m.scripts.length}</div><div class="lbl">Scripts</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${m.httpEndpoints.length}</div><div class="lbl">HTTP APIs</div></div>`;
  h += `<div class="manifest-stat"><div class="num">${m.kafkaTopics.length}</div><div class="lbl">Kafka Topics</div></div>`;
  h += '</div>';

  // Directories
  if (dirCount) {
    const rows = Object.entries(m.directories).map(([p, d]) => [escapeHTML(p), d.type, d.processors.map(escapeHTML).join(', ')]);
    h += '<h4 style="margin:12px 0 4px">Directories</h4>' + tableHTML(['Path', 'Type', 'Processors'], rows);
  }
  // SQL Tables
  if (sqlCount) {
    const rows = Object.entries(m.sqlTables).map(([n, t]) => [
      escapeHTML(n),
      t.readers.length ? t.readers.map(escapeHTML).join(', ') : '<em>none</em>',
      t.writers.length ? t.writers.map(escapeHTML).join(', ') : '<em>none</em>'
    ]);
    h += '<h4 style="margin:12px 0 4px">SQL Tables</h4>' + tableHTML(['Table', 'Readers', 'Writers'], rows);
  }
  // Signals & Tokens
  if (sigCount || tokCount) {
    const rows = [];
    Object.entries(m.signals).forEach(([n, s]) => rows.push([escapeHTML(n), 'Signal', s.senders.map(escapeHTML).join(', '), s.waiters.map(escapeHTML).join(', '), s.target]));
    Object.entries(m.tokens).forEach(([n, t]) => rows.push([escapeHTML(n), 'Token', t.acquirers.map(escapeHTML).join(', '), t.releasers.map(escapeHTML).join(', '), '—']));
    h += '<h4 style="margin:12px 0 4px">Tokens &amp; Signals</h4>' + tableHTML(['Name', 'Type', 'Producers', 'Consumers', 'Target'], rows);
  }
  // Scripts
  if (m.scripts.length) {
    const rows = m.scripts.map(s => [escapeHTML(s.path), escapeHTML(s.args), escapeHTML(s.processor)]);
    h += '<h4 style="margin:12px 0 4px">Scripts</h4>' + tableHTML(['Path', 'Arguments', 'Processor'], rows);
  }
  // HTTP Endpoints
  if (m.httpEndpoints.length) {
    const rows = m.httpEndpoints.map(e => [escapeHTML(e.url), e.method, escapeHTML(e.processor)]);
    h += '<h4 style="margin:12px 0 4px">HTTP Endpoints</h4>' + tableHTML(['URL', 'Method', 'Processor'], rows);
  }
  // Kafka Topics
  if (m.kafkaTopics.length) {
    const rows = m.kafkaTopics.map(k => [escapeHTML(k.topic), k.direction, escapeHTML(k.brokers), escapeHTML(k.processor)]);
    h += '<h4 style="margin:12px 0 4px">Kafka Topics</h4>' + tableHTML(['Topic', 'Direction', 'Brokers', 'Processor'], rows);
  }
  // DB Connections
  if (m.dbConnections.length) {
    const rows = m.dbConnections.map(d => [escapeHTML(d.name), escapeHTML(d.url || '—'), escapeHTML(d.processor)]);
    h += '<h4 style="margin:12px 0 4px">Database Connections</h4>' + tableHTML(['Service', 'URL', 'Processor'], rows);
  }
  // Warnings
  if (m.warnings.length) {
    h += '<div style="margin-top:12px">' + m.warnings.map(w => `<div class="alert alert-warn" style="margin:4px 0;padding:6px 12px;font-size:0.82rem">${escapeHTML(w)}</div>`).join('') + '</div>';
  }
  // Disconnected processors
  if (m.disconnected.length) {
    const rows = m.disconnected.map(p => [escapeHTML(p.name), escapeHTML(p.type), escapeHTML(p.group || '—'), escapeHTML(p.state || '—')]);
    h += '<h4 style="margin:12px 0 4px;color:var(--red)">Disconnected Processors</h4>' + tableHTML(['Name', 'Type', 'Group', 'State'], rows);
  }
  return h;
}

// ================================================================
// SOURCE SYSTEM DETECTION
// ================================================================
function detectSourceSystem(content, fmt) {
  if (fmt==='dependency_json') return {name:'Dependency Graph',type:'ETL Session Lineage',color:'#8B5CF6'};
  if (fmt==='informatica_xml') return {name:'Informatica',type:'ETL & Integration',color:'#FF4A00'};
  if (fmt==='talend_xml') return {name:'Talend',type:'Data Integration',color:'#FF6D70'};
  if (fmt==='nifi_xml') return {name:'Apache NiFi',type:'Flow Definition',color:'#728E9B'};
  if (fmt==='pyspark') return {name:'PySpark / Databricks',type:'Spark Schema',color:'#E25A1C'};
  if (fmt==='scala') return {name:'Scala / Spark',type:'Case Classes',color:'#DC382D'};
  if (fmt==='dbt') return {name:'dbt',type:'Data Transformation',color:'#FF694B'};
  if (fmt==='avro') return {name:'Apache Avro',type:'Schema Registry',color:'#3ECF8E'};
  if (fmt==='protobuf') return {name:'Protobuf',type:'Schema Definition',color:'#3ECF8E'};
  if (fmt==='spark_schema') return {name:'Spark',type:'printSchema Output',color:'#E25A1C'};
  if (fmt==='yaml') return {name:'YAML Schema',type:'Universal',color:'#CB171E'};
  if (fmt==='json') return {name:'JSON Schema',type:'Universal',color:'#000000'};
  if (fmt==='csv') return {name:'CSV Mapping',type:'Universal',color:'#217346'};
  if (fmt==='xml') return {name:'XML Schema',type:'Universal',color:'#0060AC'};
  const c = content || '';
  if (/\bVARCHAR2\b|\bNUMBER\s*\(|\bCLOB\b|\bBINARY_FLOAT\b/i.test(c)) return {name:'Oracle',type:'Database',color:'#F80000'};
  if (/\[\w+\]|\bIDENTITY\s*\(|\bDATETIME2\b|\bUNIQUEIDENTIFIER\b|\bNVARCHAR\b/i.test(c)) return {name:'SQL Server',type:'Microsoft SQL',color:'#CC2927'};
  if (/\bDISTKEY\b|\bSORTKEY\b|\bENCODE\s+(lzo|zstd|raw|bytedict)\b/i.test(c)) return {name:'AWS Redshift',type:'Data Warehouse',color:'#FF9900'};
  if (/\bVARIANT\b|\bCLUSTER\s+BY\b|\bTRANSIENT\s+TABLE\b/i.test(c)) return {name:'Snowflake',type:'Data Cloud',color:'#29B5E8'};
  if (/\bMULTISET\b|\bBYTEINT\b|\bTITLE\s+'/i.test(c)) return {name:'Teradata',type:'Enterprise DW',color:'#F37440'};
  if (/\bCOLUMN\s+TABLE\b|\bCS_STRING\b|\bALPHANUM\b/i.test(c)) return {name:'SAP HANA',type:'ERP / BW',color:'#0FAAFF'};
  if (/\bINT64\b|\bFLOAT64\b|\bSTRUCT\s*</i.test(c)) return {name:'Google BigQuery',type:'Cloud Platform',color:'#4285F4'};
  if (/\bUSING\s+DELTA\b|\bTBLPROPERTIES\b|\bLOCATION\s+'/i.test(c)) return {name:'Databricks',type:'Unity Catalog',color:'#FF3621'};
  if (/\bDISTRIBUTION\s*=\s*(HASH|ROUND_ROBIN|REPLICATE)\b/i.test(c)) return {name:'Azure Synapse',type:'Analytics',color:'#0078D4'};
  if (/\bSERIAL\b|\bBYTEA\b|\bJSONB\b|\bINET\b|\bTSVECTOR\b/i.test(c)) return {name:'PostgreSQL',type:'Database',color:'#4169E1'};
  if (/\bAUTO_INCREMENT\b|\bENGINE\s*=\s*(InnoDB|MyISAM)/i.test(c)) return {name:'MySQL',type:'Database',color:'#4479A1'};
  if (/\bSTORED\s+AS\s+(ORC|PARQUET|TEXTFILE)\b|\bROW\s+FORMAT\b/i.test(c)) return {name:'Apache Hive',type:'Data Warehouse',color:'#FDEE21'};
  return {name:'SQL',type:'Standard DDL',color:'#808495'};
}

// ================================================================
// DEFAULT STATS
// ================================================================
function genStats(col, rowCount) {
  const dt = col.data_type.toLowerCase();
  const s = {null_ratio: col.nullable ? 0.05 : 0.0};
  if (col.check_constraints && col.check_constraints.length) {
    const n = col.check_constraints.length;
    s.top_values = col.check_constraints.map(v=>({value:v, frequency:Math.round(1/n*10000)/10000}));
    s.distinct_count = n; return s;
  }
  if (['int','integer','smallint','tinyint'].includes(dt)) {
    if (col.is_primary_key) Object.assign(s, {min:1,max:rowCount,mean:rowCount/2,stddev:rowCount/6,distinct_count:rowCount});
    else Object.assign(s, {min:1,max:1000,mean:500,stddev:300,distinct_count:Math.min(500,rowCount)});
  } else if (['bigint','long'].includes(dt)) Object.assign(s, {min:1,max:100000,mean:50000,stddev:30000,distinct_count:Math.min(10000,rowCount)});
  else if (['float','double'].includes(dt)) Object.assign(s, {min:0,max:10000,mean:100,stddev:50,distinct_count:rowCount});
  else if (['decimal','numeric'].includes(dt)) { const mx = Math.pow(10,(col.precision||10)-(col.scale||2))-1; Object.assign(s, {min:0,max:mx,mean:mx/10,stddev:mx/20,distinct_count:rowCount}); }
  else if (['varchar','char','text','string'].includes(dt)) Object.assign(s, {min_length:3,max_length:Math.min(col.max_length||50,100),distinct_count:rowCount});
  else if (dt==='date') Object.assign(s, {min:'2020-01-01',max:'2025-12-31',distinct_count:Math.min(rowCount,2000)});
  else if (['timestamp','datetime'].includes(dt)) Object.assign(s, {min:'2020-01-01',max:'2025-12-31',distinct_count:rowCount});
  else if (['boolean','bool'].includes(dt)) { s.top_values=[{value:true,frequency:0.5},{value:false,frequency:0.5}]; s.distinct_count=2; }
  else Object.assign(s, {min_length:5,max_length:20,distinct_count:rowCount});
  return s;
}

// ================================================================
// BLUEPRINT ASSEMBLER
// ================================================================
function assembleBlueprint_fn(parsed) {
  const bid = crypto.randomUUID ? crypto.randomUUID() : 'bp-'+Math.random().toString(36).substring(2,10);
  const tables = parsed.tables.map(pt => {
    const rc = pt.row_count || 1000; // Use actual row count from source parser
    const cols = pt.columns.map(c => ({name:c.name, data_type:c.data_type, nullable:c.nullable, is_primary_key:c.is_primary_key, stats:genStats(c, rc)}));
    const fks = pt.foreign_keys.map(fk => ({column:fk.fk_column, references_table:fk.referenced_table, references_column:fk.referenced_column}));
    return {name:pt.name, schema:pt.schema, row_count:rc, columns:cols, foreign_keys:fks};
  });
  const rels = [];
  parsed.tables.forEach(pt => pt.foreign_keys.forEach(fk => rels.push({from_table:`${pt.schema}.${pt.name}`,to_table:`${pt.schema}.${fk.referenced_table}`,relationship_type:'one_to_many',join_columns:[{from_column:fk.fk_column,to_column:fk.referenced_column}]})));
  return {blueprint_id:bid, source_system:{name:parsed.source_name,type:parsed.source_type}, tables, relationships:rels};
}

// ================================================================
// TIER DIAGRAM — Adaptive Environment Visualization
// ================================================================
const NIFI_ROLE_MAP = {
  // Sources (Tier 1)
  GetFile:'source',GetHTTP:'source',GetSFTP:'source',GetFTP:'source',ConsumeKafka:'source',
  ConsumeKafka_2_6:'source',ConsumeKafkaRecord_2_6:'source',ListenHTTP:'source',
  QueryDatabaseTable:'source',QueryDatabaseTableRecord:'source',GenerateFlowFile:'source',
  GetHDFS:'source',ListS3:'source',FetchS3Object:'source',GetS3Object:'source',
  ListFile:'source',FetchFile:'source',ConsumeJMS:'source',ListenTCP:'source',
  ListenUDP:'source',GetMongo:'source',GetElasticsearch:'source',TailFile:'source',
  // Routing (Tier 2)
  RouteOnAttribute:'route',RouteOnContent:'route',DistributeLoad:'route',ControlRate:'route',
  RouteText:'route',DetectDuplicate:'route',ValidateRecord:'route',
  // Transform (Tier 2)
  UpdateAttribute:'transform',JoltTransformJSON:'transform',ReplaceText:'transform',
  ConvertRecord:'transform',SplitRecord:'transform',MergeContent:'transform',MergeRecord:'transform',
  ExecuteScript:'transform',ExecuteStreamCommand:'transform',ConvertJSONToSQL:'transform',
  TransformXml:'transform',SplitJson:'transform',SplitXml:'transform',SplitText:'transform',SplitContent:'transform',
  EvaluateJsonPath:'transform',ExtractText:'transform',CompressContent:'transform',
  EncryptContent:'transform',HashContent:'transform',Base64EncodeContent:'transform',
  ConvertCharacterSet:'transform',FlattenJson:'transform',ConvertAvroToJSON:'transform',
  ConvertJSONToAvro:'transform',
  // Processing (Tier 3)
  ExecuteSQL:'process',ExecuteSQLRecord:'process',PutDatabaseRecord:'process',
  LookupAttribute:'process',LookupRecord:'process',InvokeHTTP:'process',
  ExecuteProcess:'process',HandleHttpRequest:'process',HandleHttpResponse:'process',
  // Sinks (Tier 4)
  PutFile:'sink',PutHDFS:'sink',PutS3Object:'sink',PutSQL:'sink',PutKafka:'sink',
  PutKafkaRecord:'sink',PutEmail:'sink',PutSFTP:'sink',PutFTP:'sink',PublishKafka:'sink',
  PublishKafka_2_6:'sink',PublishKafkaRecord_2_6:'sink',PutMongo:'sink',PutElasticsearch:'sink',
  PutDatabaseRecord:'sink',PutSyslog:'sink',PutTCP:'sink',
  // Utility
  LogMessage:'utility',LogAttribute:'utility',Wait:'utility',Notify:'utility',
  DebugFlow:'utility',CountText:'utility',AttributesToJSON:'utility',
};

function classifyNiFiProcessor(type) {
  return NIFI_ROLE_MAP[type] || (
    /^(Get|List|Consume|Listen|Fetch|Tail|Query)/i.test(type) ? 'source' :
    /^(Put|Publish|Send|Post)/i.test(type) ? 'sink' :
    /^(Route|Distribute|Control|Validate|Detect)/i.test(type) ? 'route' :
    /^(Convert|Split|Merge|Replace|Transform|Extract|Evaluate|Flatten|Compress|Encrypt|Hash)/i.test(type) ? 'transform' :
    /^(Execute|Invoke|Lookup|Handle)/i.test(type) ? 'process' :
    /^(Log|Debug|Count|Wait|Notify)/i.test(type) ? 'utility' :
    'process'
  );
}

// ── NiFi role-tier constants (shared by build + render) ──
const ROLE_TIER_ORDER = ['source', 'route', 'transform', 'process', 'sink', 'utility'];
const ROLE_TIER_COLORS = { source:'#3B82F6', route:'#EAB308', transform:'#A855F7', process:'#6366F1', sink:'#21C354', utility:'#808495' };
const ROLE_TIER_LABELS = {
  source:'SOURCES — Ingestion & Acquisition', route:'ROUTING — Distribution & Validation',
  transform:'TRANSFORMS — Conversion & Enrichment', process:'PROCESSING — Execution & Lookup',
  sink:'SINKS — Output & Delivery', utility:'UTILITY — Logging & Control'
};

// ── NiFi → Databricks processor mapping ──
const NIFI_DATABRICKS_MAP = {
  // SOURCES
  GetFile:{cat:'Auto Loader',tpl:'df_{v} = (spark.readStream\n  .format("cloudFiles")\n  .option("cloudFiles.format", "{format}")\n  .option("cloudFiles.schemaLocation", "/mnt/schema/{v}")\n  .load("/Volumes/{catalog}/{schema}/{path}"))',desc:'Auto Loader from Databricks Volumes',notes:'Configure volume mount path',imp:[],conf:0.85},
  GetHTTP:{cat:'Spark HTTP',tpl:'# Ingest from REST API via Spark\n_url = "{url}"\n_resp_rdd = spark.sparkContext.parallelize([_url])\ndf_{v} = spark.read.json(spark.sparkContext.wholeTextFiles(_url).values())',desc:'REST API ingestion via Spark',notes:'For paginated APIs use spark.read.format("json") with custom schema',imp:[],conf:0.65},
  ConsumeKafka:{cat:'Structured Streaming',tpl:'df_{v} = (spark.readStream\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("subscribe", "{topic}")\n  .load())',desc:'Kafka streaming source',notes:'Configure security protocol if needed',imp:[],conf:0.90},
  ConsumeKafka_2_6:{cat:'Structured Streaming',tpl:'df_{v} = (spark.readStream\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("subscribe", "{topic}")\n  .load())',desc:'Kafka streaming source',notes:'Same as ConsumeKafka',imp:[],conf:0.90},
  ConsumeKafkaRecord_2_6:{cat:'Structured Streaming',tpl:'df_{v} = (spark.readStream\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("subscribe", "{topic}")\n  .load()\n  .select(from_json(col("value").cast("string"), schema).alias("data"))\n  .select("data.*"))',desc:'Kafka record streaming',notes:'Define schema for deserialization',imp:[],conf:0.85},
  QueryDatabaseTable:{cat:'JDBC Source',tpl:'df_{v} = (spark.read\n  .format("jdbc")\n  .option("url", dbutils.secrets.get(scope="{scope}", key="jdbc-url"))\n  .option("dbtable", "{table}")\n  .option("driver", "{driver}")\n  .load())',desc:'JDBC database read',notes:'Store credentials in Databricks secret scope',imp:[],conf:0.90},
  QueryDatabaseTableRecord:{cat:'JDBC Source',tpl:'df_{v} = (spark.read\n  .format("jdbc")\n  .option("url", dbutils.secrets.get(scope="{scope}", key="jdbc-url"))\n  .option("dbtable", "{table}")\n  .load())',desc:'JDBC database read with record',notes:'Same as QueryDatabaseTable',imp:[],conf:0.90},
  ListenHTTP:{cat:'Manual',tpl:'# TODO: No direct equivalent for ListenHTTP in Databricks\n# Option 1: Databricks Model Serving endpoint\n# Option 2: External API gateway triggering a Databricks Job via REST API\n# Option 3: Use Delta Live Tables with webhook-triggered ingestion',desc:'HTTP listener endpoint',notes:'No native HTTP server in Databricks — use Model Serving or external trigger',imp:[],conf:0.10},
  GetSFTP:{cat:'External Storage',tpl:'# Stage from SFTP to Unity Catalog Volumes\ndbutils.fs.cp("sftp://{host}/{path}", "/Volumes/{catalog}/{schema}/landing/")\ndf_{v} = spark.read.format("{format}").load("/Volumes/{catalog}/{schema}/landing/")',desc:'SFTP file retrieval',notes:'Requires SFTP mount or external transfer utility',imp:[],conf:0.50},
  GetFTP:{cat:'External Storage',tpl:'# Stage from FTP to Unity Catalog Volumes (use external transfer)\ndf_{v} = spark.read.format("{format}").load("/Volumes/{catalog}/{schema}/landing/")',desc:'FTP file retrieval',notes:'No native FTP — use external transfer tool to stage to Volumes',imp:[],conf:0.40},
  GenerateFlowFile:{cat:'Test Data',tpl:'df_{v} = spark.range({count}).toDF("id")\n# Add test columns as needed',desc:'Test data generator',notes:'Replace with actual test data generation',imp:[],conf:0.60},
  ListS3:{cat:'Cloud Storage',tpl:'_files = dbutils.fs.ls("s3://{bucket}/{prefix}")\ndf_{v} = spark.createDataFrame(_files)',desc:'List S3 objects',notes:'Use Unity Catalog external locations',imp:[],conf:0.85},
  FetchS3Object:{cat:'Cloud Storage',tpl:'df_{v} = spark.read.format("{format}").load("s3://{bucket}/{key}")',desc:'Read S3 object',notes:'Configure external location in Unity Catalog',imp:[],conf:0.85},
  GetS3Object:{cat:'Cloud Storage',tpl:'df_{v} = spark.read.format("{format}").load("s3://{bucket}/{key}")',desc:'Read S3 object',notes:'Same as FetchS3Object',imp:[],conf:0.85},
  TailFile:{cat:'Auto Loader',tpl:'df_{v} = (spark.readStream\n  .format("cloudFiles")\n  .option("cloudFiles.format", "text")\n  .load("/Volumes/{catalog}/{schema}/{path}"))',desc:'File tail via Auto Loader',notes:'Streaming mode handles new files automatically',imp:[],conf:0.80},
  ListFile:{cat:'Cloud Storage',tpl:'_files = dbutils.fs.ls("/Volumes/{catalog}/{schema}/{path}")\ndf_{v} = spark.createDataFrame(_files)',desc:'List files in directory',notes:'Use Volumes or external location',imp:[],conf:0.80},
  GetMongo:{cat:'MongoDB Connector',tpl:'df_{v} = (spark.read\n  .format("mongodb")\n  .option("connection.uri", dbutils.secrets.get(scope="{scope}", key="mongo-uri"))\n  .option("database", "{database}")\n  .option("collection", "{collection}")\n  .load())',desc:'MongoDB read',notes:'Install mongodb-spark-connector library',imp:[],conf:0.75},
  GetElasticsearch:{cat:'ES Connector',tpl:'df_{v} = (spark.read\n  .format("org.elasticsearch.spark.sql")\n  .option("es.nodes", "{host}")\n  .option("es.resource", "{index}")\n  .load())',desc:'Elasticsearch read',notes:'Install elasticsearch-spark library',imp:[],conf:0.65},
  FetchFile:{cat:'Volumes Read',tpl:'# Fetch file content by path attribute\n_path = "/Volumes/{catalog}/{schema}/landing/{filename}"\ndf_{v} = spark.read.format("{format}").load(_path)',desc:'Read file by path from Unity Catalog Volumes',notes:'Map NiFi filename attribute to Volumes path',imp:[],conf:0.80},
  // TRANSFORMS
  ConvertRecord:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.selectExpr("*")  # Convert record format\n# Adjust column types/names as needed',desc:'Record format conversion',notes:'Spark handles format conversion natively',imp:[],conf:0.80},
  ConvertJSONToSQL:{cat:'Spark SQL',tpl:'df_{in}.createOrReplaceTempView("tmp_{v}")\ndf_{v} = spark.sql("SELECT * FROM tmp_{v}")',desc:'JSON to SQL conversion',notes:'Parse JSON and query with SQL',imp:[],conf:0.75},
  SplitRecord:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("item", explode(col("{array_field}")))\n  .select("item.*")',desc:'Split records by array field',notes:'Identify the array field to explode',imp:[],conf:0.75},
  MergeRecord:{cat:'DataFrame API',tpl:'df_{v} = df_{in1}.unionByName(df_{in2}, allowMissingColumns=True)',desc:'Merge/union records',notes:'Ensure compatible schemas',imp:[],conf:0.85},
  MergeContent:{cat:'DataFrame API',tpl:'df_{v} = df_{in1}.unionByName(df_{in2}, allowMissingColumns=True)',desc:'Merge content streams',notes:'Same as MergeRecord for DataFrames',imp:[],conf:0.80},
  ReplaceText:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("{col}", regexp_replace(col("{col}"), "{pattern}", "{replacement}"))',desc:'Regex text replacement',notes:'Apply to specific text columns',imp:[],conf:0.85},
  UpdateAttribute:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("{attr}", lit("{value}"))',desc:'Set/update attributes as columns',notes:'Map NiFi attributes to DataFrame columns',imp:[],conf:0.80},
  JoltTransformJSON:{cat:'JSON Processing',tpl:'# Define target schema for JSON transform\n_schema = "..."\ndf_{v} = df_{in}.withColumn("parsed", from_json(col("value"), _schema))\n  .select("parsed.*")',desc:'Complex JSON transformation',notes:'Jolt specs must be manually translated to Spark JSON ops',imp:[],conf:0.50},
  EvaluateJsonPath:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("{field}", get_json_object(col("value"), "$.{path}"))',desc:'Extract JSON paths',notes:'Map each JsonPath expression to get_json_object',imp:[],conf:0.80},
  ExtractText:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("{field}", regexp_extract(col("{col}"), "{pattern}", {group}))',desc:'Regex text extraction',notes:'Translate NiFi regex groups to Spark',imp:[],conf:0.80},
  SplitJson:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("items", explode(from_json(col("value"), ArrayType(StringType()))))',desc:'Split JSON array',notes:'Define element schema',imp:[],conf:0.75},
  SplitText:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("lines", explode(split(col("value"), "\\\\n")))',desc:'Split text by delimiter',notes:'Adjust delimiter as needed',imp:[],conf:0.80},
  SplitContent:{cat:'DataFrame API',tpl:'# Split content by byte boundary or delimiter\ndf_{v} = df_{in}.withColumn("parts", split(col("value"), "{byte_sequence}"))\ndf_{v} = df_{v}.withColumn("part", explode(col("parts"))).drop("parts")',desc:'Split content by delimiter/boundary',notes:'Adjust byte_sequence pattern for content splitting',imp:[],conf:0.75},
  CompressContent:{cat:'Native',tpl:'# Delta Lake handles compression natively (snappy/zstd)\n# No explicit compression step needed\ndf_{v} = df_{in}',desc:'Compression',notes:'Delta Lake auto-compresses',imp:[],conf:0.95},
  EncryptContent:{cat:'Security',tpl:'# Use Databricks column-level encryption or workspace-level encryption\n# See: docs.databricks.com/security/column-level-encryption\ndf_{v} = df_{in}  # TODO: Apply aes_encrypt() on sensitive columns',desc:'Encryption',notes:'Use workspace-level encryption or aes_encrypt()',imp:[],conf:0.40},
  HashContent:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.withColumn("{col}_hash", sha2(col("{col}").cast("string"), 256))',desc:'SHA-256 hashing',notes:'Apply to specific columns',imp:[],conf:0.90},
  TransformXml:{cat:'XML Processing',tpl:'# Use spark-xml library\ndf_{v} = spark.read.format("com.databricks.spark.xml").option("rowTag", "{tag}").load("{path}")',desc:'XML transformation',notes:'Install spark-xml; define row tag',imp:[],conf:0.60},
  ExecuteScript:{cat:'PySpark Cell',tpl:'# Custom script from NiFi ExecuteScript\n# Original engine: {engine}\n# TODO: Translate script logic to PySpark DataFrame operations\ndf_{v} = df_{in}',desc:'Custom script execution',notes:'Manual translation to PySpark required — review original script',imp:[],conf:0.30},
  ExecuteStreamCommand:{cat:'dbutils Shell',tpl:'# Execute shell command via %sh magic or dbutils\n# %sh {command}\n# Or use dbutils.notebook.run() to call a helper notebook\ndbutils.fs.put("/tmp/{v}_cmd.sh", "{command}", True)',desc:'External command via dbutils',notes:'Use %sh cell magic or dbutils.notebook.run()',imp:[],conf:0.40},
  ConvertAvroToJSON:{cat:'DataFrame API',tpl:'from pyspark.sql.avro.functions import from_avro\ndf_{v} = df_{in}.select(from_avro("value", _schema).alias("data")).select("data.*")',desc:'Avro to JSON',notes:'Spark handles Avro natively',imp:[],conf:0.85},
  AttributesToJSON:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.select(to_json(struct("*")).alias("json_value"))',desc:'Columns to JSON',notes:'Converts all columns to single JSON string',imp:[],conf:0.85},
  // ROUTES
  RouteOnAttribute:{cat:'DataFrame Filter',tpl:'# Route based on attribute conditions\ndf_{v}_matched = df_{in}.filter("{condition}")\ndf_{v}_unmatched = df_{in}.filter("NOT ({condition})")',desc:'Conditional routing',notes:'Map NiFi routing rules to filter conditions',imp:[],conf:0.80},
  RouteOnContent:{cat:'DataFrame Filter',tpl:'df_{v} = df_{in}.filter(col("value").rlike("{pattern}"))',desc:'Content-based routing',notes:'Translate content match patterns to regex',imp:[],conf:0.75},
  ValidateRecord:{cat:'DLT Expectations',tpl:'# Data quality validation using DLT expectations\n# @dlt.expect_or_drop("{rule}", "{expression}")\ndf_{v} = df_{in}.filter("{expression}")  # Drop invalid rows',desc:'Record validation',notes:'Best implemented as DLT expectations',imp:[],conf:0.85},
  DistributeLoad:{cat:'Spark Partitioning',tpl:'df_{v} = df_{in}.repartition({partitions})',desc:'Load distribution',notes:'Spark handles distribution automatically; repartition if needed',imp:[],conf:0.90},
  DetectDuplicate:{cat:'DataFrame API',tpl:'df_{v} = df_{in}.dropDuplicates(["{key}"])',desc:'Duplicate detection/removal',notes:'Specify dedup key columns',imp:[],conf:0.90},
  // PROCESSING
  ExecuteSQL:{cat:'Spark SQL',tpl:'df_{in}.createOrReplaceTempView("tmp_{v}")\ndf_{v} = spark.sql("""\n{sql}\n""")',desc:'SQL execution',notes:'Register input as temp view first',imp:[],conf:0.90},
  ExecuteSQLRecord:{cat:'Spark SQL',tpl:'df_{in}.createOrReplaceTempView("tmp_{v}")\ndf_{v} = spark.sql("""\n{sql}\n""")',desc:'SQL execution with records',notes:'Same as ExecuteSQL',imp:[],conf:0.90},
  LookupRecord:{cat:'DataFrame Join',tpl:'# Load lookup table from Unity Catalog\ndf_lookup = spark.table("{catalog}.{schema}.{lookup_table}")\ndf_{v} = df_{in}.join(df_lookup, on="{key}", how="left")',desc:'Record lookup via join',notes:'Ensure lookup table exists in Unity Catalog',imp:[],conf:0.85},
  InvokeHTTP:{cat:'Spark UDF',tpl:'# HTTP call via PySpark pandas UDF (Databricks-compatible)\nfrom pyspark.sql.functions import pandas_udf\nimport pandas as pd\n@pandas_udf("string")\ndef _call_api(urls: pd.Series) -> pd.Series:\n  import urllib.request, json\n  def _get(u):\n    with urllib.request.urlopen(u) as r: return r.read().decode()\n  return urls.apply(_get)\ndf_{v} = df_{in}.withColumn("api_response", _call_api(col("url")))',desc:'HTTP API call via PySpark UDF',notes:'Uses pandas UDF for distributed execution; add error handling',imp:[],conf:0.60},
  PutDatabaseRecord:{cat:'JDBC Write',tpl:'(df_{in}.write\n  .format("jdbc")\n  .option("url", dbutils.secrets.get(scope="{scope}", key="jdbc-url"))\n  .option("dbtable", "{table}")\n  .mode("append")\n  .save())',desc:'Database record write',notes:'Store JDBC credentials in secret scope',imp:[],conf:0.85},
  HandleHttpRequest:{cat:'Manual',tpl:'# TODO: No direct equivalent for HandleHttpRequest in Databricks\n# Option 1: Databricks Model Serving endpoint\n# Option 2: External API gateway triggering a Databricks Job via REST API',desc:'HTTP server endpoint',notes:'Databricks cannot host HTTP endpoints natively — use Model Serving',imp:[],conf:0.10},
  HandleHttpResponse:{cat:'Manual',tpl:'# TODO: No direct equivalent for HandleHttpResponse\n# Pair with HandleHttpRequest replacement',desc:'HTTP response handler',notes:'Use with HandleHttpRequest alternative',imp:[],conf:0.10},
  // SINKS
  PutFile:{cat:'Delta Lake Write',tpl:'(df_{in}.write\n  .format("delta")\n  .mode("append")\n  .saveAsTable("{catalog}.{schema}.{table}"))',desc:'Write to Delta Lake table',notes:'Uses Unity Catalog managed table',imp:[],conf:0.90},
  PutSQL:{cat:'JDBC Write',tpl:'(df_{in}.write\n  .format("jdbc")\n  .option("url", dbutils.secrets.get(scope="{scope}", key="jdbc-url"))\n  .option("dbtable", "{table}")\n  .mode("append")\n  .save())',desc:'SQL database write',notes:'Store credentials in secret scope',imp:[],conf:0.85},
  PutKafka:{cat:'Kafka Write',tpl:'(df_{in}\n  .selectExpr("to_json(struct(*)) AS value")\n  .write\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("topic", "{topic}")\n  .save())',desc:'Write to Kafka topic',notes:'Configure security protocol',imp:[],conf:0.85},
  PublishKafka:{cat:'Kafka Write',tpl:'(df_{in}\n  .selectExpr("to_json(struct(*)) AS value")\n  .write\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("topic", "{topic}")\n  .save())',desc:'Publish to Kafka',notes:'Same as PutKafka',imp:[],conf:0.85},
  PublishKafka_2_6:{cat:'Kafka Write',tpl:'(df_{in}\n  .selectExpr("to_json(struct(*)) AS value")\n  .write\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("topic", "{topic}")\n  .save())',desc:'Publish to Kafka 2.6',notes:'Same as PutKafka',imp:[],conf:0.85},
  PublishKafkaRecord_2_6:{cat:'Kafka Write',tpl:'(df_{in}\n  .selectExpr("to_json(struct(*)) AS value")\n  .write\n  .format("kafka")\n  .option("kafka.bootstrap.servers", "{brokers}")\n  .option("topic", "{topic}")\n  .save())',desc:'Publish Kafka records',notes:'Same as PutKafka',imp:[],conf:0.85},
  PutS3Object:{cat:'Cloud Storage Write',tpl:'(df_{in}.write\n  .format("delta")\n  .mode("append")\n  .save("s3a://{bucket}/{path}"))',desc:'Write to S3',notes:'Use external location in Unity Catalog',imp:[],conf:0.85},
  PutHDFS:{cat:'Cloud Storage Write',tpl:'(df_{in}.write\n  .format("delta")\n  .mode("append")\n  .save("{path}"))',desc:'Write to cloud storage',notes:'Map HDFS path to cloud storage / Volumes',imp:[],conf:0.80},
  PutSFTP:{cat:'External Storage Write',tpl:'# Write to SFTP via staging in Unity Catalog Volumes\n(df_{in}.write.format("{format}").mode("overwrite")\n  .save("/Volumes/{catalog}/{schema}/staging/{v}"))\n# Stage to Volumes then use external SFTP transfer\n# dbutils.fs.cp("/Volumes/.../staging/{v}", "sftp://{hostname}/{remote_path}")',desc:'SFTP file upload via staging',notes:'Stage to Volumes then transfer; or use external SFTP utility',imp:[],conf:0.70},
  PutEmail:{cat:'Workflow Notification',tpl:'# Use Databricks workflow email notifications\n# Configure in Job settings: email_notifications.on_success / on_failure\n# Or use dbutils.notebook.exit() with downstream webhook task\ndbutils.notebook.exit("NOTIFY: {subject}")',desc:'Email via workflow notification',notes:'Configure email notifications in Databricks Job settings',imp:[],conf:0.45},
  PutMongo:{cat:'MongoDB Connector',tpl:'(df_{in}.write\n  .format("mongodb")\n  .option("connection.uri", dbutils.secrets.get(scope="{scope}", key="mongo-uri"))\n  .option("database", "{database}")\n  .option("collection", "{collection}")\n  .mode("append")\n  .save())',desc:'MongoDB write',notes:'Install mongodb-spark-connector',imp:[],conf:0.75},
  PutElasticsearch:{cat:'ES Connector',tpl:'(df_{in}.write\n  .format("org.elasticsearch.spark.sql")\n  .option("es.nodes", "{host}")\n  .save("{index}"))',desc:'Elasticsearch write',notes:'Install elasticsearch-spark',imp:[],conf:0.65},
  PutDatabaseRecord:{cat:'JDBC Write',tpl:'(df_{in}.write\n  .format("jdbc")\n  .option("url", dbutils.secrets.get(scope="{scope}", key="jdbc-url"))\n  .option("dbtable", "{table}")\n  .mode("append")\n  .save())',desc:'Database record write',notes:'Store credentials in secret scope',imp:[],conf:0.85},
  // UTILITY
  LogMessage:{cat:'Spark Logging',tpl:'# Databricks notebook logging\nprint(f"[INFO] {v}: Processing complete")\nspark.sparkContext.setLocalProperty("callSite.short", "{v}")',desc:'Spark-native logging',notes:'Captured in Spark driver logs and notebook output',imp:[],conf:0.90},
  LogAttribute:{cat:'Spark Display',tpl:'# Inspect schema and sample data\ndisplay(df_{in})\ndf_{in}.printSchema()',desc:'Display attributes and preview',notes:'display() renders interactive table in Databricks',imp:[],conf:0.90},
  Wait:{cat:'Workflow Scheduling',tpl:'# Use Databricks workflow scheduling instead of sleep\n# Configure trigger interval or task dependencies in Job settings\n# If needed in-notebook: dbutils.notebook.run() with timeout\nprint("[WAIT] Scheduling delay — configure in workflow task settings")',desc:'Workflow-level scheduling',notes:'Use Job task dependencies or trigger intervals instead of sleep',imp:[],conf:0.70},
  Notify:{cat:'Workflow Signal',tpl:'dbutils.notebook.exit("SUCCESS")  # Signal to downstream workflow tasks',desc:'Signal/notify completion',notes:'Use workflow task dependencies',imp:[],conf:0.80},
  DebugFlow:{cat:'Spark Display',tpl:'display(df_{in})\ndf_{in}.printSchema()',desc:'Debug/inspect data',notes:'display() renders interactive table in Databricks',imp:[],conf:0.90},
  CountText:{cat:'DataFrame API',tpl:'_count = df_{in}.count()\ndisplayHTML(f"<h3>Row count: {_count}</h3>")',desc:'Count rows',notes:'displayHTML renders formatted output in Databricks',imp:[],conf:0.95},
  ControlRate:{cat:'Streaming Trigger',tpl:'# Rate control: use structured streaming trigger interval\n# .trigger(processingTime="{interval}")',desc:'Rate limiting',notes:'Use structured streaming trigger interval',imp:[],conf:0.70},
};

function sanitizeVarName(name) {
  return name.replace(/[^a-zA-Z0-9_]/g, '_').replace(/^(\d)/, '_$1').toLowerCase().substring(0, 40);
}

function mapNiFiToDatabricks(nifi) {
  const processors = nifi.processors || [];
  const conns = nifi.connections || [];
  const connGraph = {};
  conns.forEach(c => {
    if (!connGraph[c.destinationName]) connGraph[c.destinationName] = {inputs:[],outputs:[]};
    connGraph[c.destinationName].inputs.push(c.sourceName);
    if (!connGraph[c.sourceName]) connGraph[c.sourceName] = {inputs:[],outputs:[]};
    connGraph[c.sourceName].outputs.push(c.destinationName);
  });
  return processors.map(p => {
    const role = classifyNiFiProcessor(p.type);
    const mapEntry = NIFI_DATABRICKS_MAP[p.type];
    const varName = sanitizeVarName(p.name);
    const inputProcs = (connGraph[p.name] && connGraph[p.name].inputs) || [];
    const inputVar = inputProcs.length ? sanitizeVarName(inputProcs[0]) : 'input';
    if (mapEntry) {
      let code = mapEntry.tpl.replace(/\{v\}/g, varName).replace(/\{in\}/g, inputVar)
        .replace(/\{in1\}/g, inputVar).replace(/\{in2\}/g, inputProcs[1] ? sanitizeVarName(inputProcs[1]) : 'input2');
      const props = p.properties || {};
      // Generic property substitution
      Object.entries(props).forEach(([k, val]) => {
        const key = k.replace(/\s+/g, '_').toLowerCase();
        code = code.replace(new RegExp('\\{' + key + '\\}', 'gi'), val);
      });
      // ── Smart code generation for high-frequency processor types ──
      let conf = mapEntry.conf;
      if (p.type === 'RouteOnAttribute') {
        const routeEntries = Object.entries(props).filter(([k]) => k !== 'Routing Strategy');
        if (routeEntries.length) {
          const lines = ['# Route based on NiFi attribute conditions'];
          routeEntries.forEach(([routeName, expr]) => {
            const safe = routeName.replace(/[^a-zA-Z0-9_]/g, '_').toLowerCase();
            lines.push(`# Route "${routeName}": ${expr}`);
            lines.push(`df_${varName}_${safe} = df_${inputVar}.filter(col("${routeName}").isNotNull())  # Translate: ${expr}`);
          });
          lines.push(`df_${varName}_unmatched = df_${inputVar}  # Unmatched rows`);
          code = lines.join('\n');
          conf = 0.85;
        }
      }
      if (p.type === 'ExecuteStreamCommand') {
        const cmd = props['Command'] || props['command'] || '';
        const args = props['Command Arguments'] || props['command_arguments'] || '';
        const full = (cmd + ' ' + args).trim();
        if (/hdfs\s+dfs|hadoop\s+fs/i.test(full)) {
          const op = /-cp\b/.test(full)?'cp':/-mv\b/.test(full)?'mv':/-mkdir/.test(full)?'mkdirs':/-rm/.test(full)?'rm':/-ls/.test(full)?'ls':'head';
          code = `# HDFS operation → dbutils.fs.${op}()\n# Original: ${full.substring(0,120)}\ndbutils.fs.${op}("/Volumes/<catalog>/<schema>/<path>")`;
          conf = 0.80;
        } else if (/kinit/i.test(full)) {
          code = `# Kerberos kinit → Not needed in Databricks\n# Original: ${full.substring(0,120)}\n# Unity Catalog handles authentication natively\nprint("[INFO] Kerberos auth handled by Unity Catalog")`;
          conf = 0.95;
        } else if (/impala/i.test(full)) {
          const sq = full.match(/-q\s+["'](.+?)["']/i);
          code = `# Impala → Spark SQL\n# Original: ${full.substring(0,120)}\nspark.sql("${sq?sq[1].replace(/"/g,'\\"'):'REFRESH TABLE <table>'}")`;
          conf = 0.85;
        } else if (full) {
          code = `# Shell command → %sh magic cell\n# Original: ${full.substring(0,120)}\n# Use %sh in a separate cell or dbutils.notebook.run()\nprint("[CMD] ${full.replace(/"/g,'\\"').substring(0,80)}")`;
          conf = 0.50;
        }
      }
      if (p.type === 'UpdateAttribute') {
        const stdKeys = new Set(['Delete Attributes Expression','Store State','Stateful Variables Initial Value','canonical-value-lookup-cache-size']);
        const attrEntries = Object.entries(props).filter(([k]) => !stdKeys.has(k));
        if (attrEntries.length) {
          const lines = ['# Set DataFrame columns from NiFi attributes', `df_${varName} = df_${inputVar}`];
          attrEntries.forEach(([attr, expr]) => {
            const cn = attr.replace(/[^a-zA-Z0-9_]/g, '_').toLowerCase();
            lines.push(`  .withColumn("${cn}", lit("${expr.replace(/"/g,'\\"')}"))  # ${attr}`);
          });
          code = lines.join('\n');
          conf = 0.85;
        }
      }
      code = code.replace(/\{(\w+)\}/g, '<$1>');
      return { name: p.name, type: p.type, group: p.group, role, mapped: true,
        confidence: conf, category: mapEntry.cat, code, desc: mapEntry.desc,
        notes: mapEntry.notes, imports: mapEntry.imp || [], state: p.state };
    }
    return { name: p.name, type: p.type, group: p.group, role, mapped: false,
      confidence: 0, category: 'Unknown', code: `# TODO: No mapping for ${p.type}\n# Processor: ${p.name}\n# Review manually`,
      desc: 'No known Databricks equivalent', notes: 'Manual migration required',
      imports: [], state: p.state, gapReason: `Processor type "${p.type}" has no known Databricks equivalent` };
  });
}

function generateDatabricksNotebook(mappings, nifi, blueprint, cfg) {
  cfg = cfg || {};
  const catalogName = cfg.catalog || '';
  const schemaName = cfg.schema || 'nifi_migration';
  const qualifiedSchema = catalogName ? `${catalogName}.${schemaName}` : schemaName;
  const cells = [];
  const allImports = new Set(['from pyspark.sql.functions import *','from pyspark.sql.types import *']);
  mappings.forEach(m => (m.imports || []).forEach(i => allImports.add(i)));
  const flowName = (nifi.processGroups && nifi.processGroups[0] ? nifi.processGroups[0].name : 'NiFi Flow');
  const mapCount = mappings.filter(m=>m.mapped).length;
  const covPct = Math.round(mapCount/mappings.length*100);
  // Header (markdown — clean content, no # MAGIC)
  cells.push({type:'md',label:'Header',source:`# NiFi Migration: ${flowName}\nGenerated by SEG Demo | ${new Date().toISOString().split('T')[0]}\n\n**Processors:** ${mappings.length} | **Mapped:** ${mapCount} | **Coverage:** ${covPct}%\n\n**Target:** ${qualifiedSchema}`,role:'config'});
  // Imports
  let configCode = [...allImports].join('\n')+'\n\n# Databricks notebook configuration\nspark.conf.set("spark.sql.adaptive.enabled", "true")';
  if (catalogName) configCode += `\nspark.sql("USE CATALOG ${catalogName}")`;
  configCode += `\nspark.sql("USE SCHEMA ${schemaName}")`;
  if (cfg.secretScope) configCode += `\n\n# Secret scope for credentials\nSECRET_SCOPE = "${cfg.secretScope}"`;
  configCode += '\nprint(f"Notebook initialized — Spark version: {spark.version}")';
  cells.push({type:'code',label:'Imports & Config',source:configCode,role:'config'});
  // Unity Catalog DDL (SQL — clean content)
  const tables = (blueprint && blueprint.tables) || [];
  if (tables.length) {
    let ddl = '';
    if (catalogName) ddl += `CREATE CATALOG IF NOT EXISTS ${catalogName};\nUSE CATALOG ${catalogName};\n`;
    ddl += `CREATE SCHEMA IF NOT EXISTS ${schemaName};\nUSE SCHEMA ${schemaName};\n`;
    tables.forEach(t => {
      ddl += `\nCREATE TABLE IF NOT EXISTS ${qualifiedSchema}.${t.name} (\n`;
      ddl += t.columns.map(c => `  ${c.name} ${(c.data_type||c.type||'STRING').toUpperCase()}`).join(',\n');
      ddl += '\n) USING DELTA;';
    });
    cells.push({type:'sql',label:'Unity Catalog Setup',source:ddl,role:'config'});
  }
  // Group by process group, sorted by role
  const groups = {};
  mappings.forEach(m => { if (!groups[m.group]) groups[m.group] = []; groups[m.group].push(m); });
  const roleOrd = {source:0,route:1,transform:2,process:3,sink:4,utility:5};
  const sortedGroups = Object.entries(groups).sort((a,b) => {
    const aMin = Math.min(...a[1].map(m => roleOrd[m.role] || 3));
    const bMin = Math.min(...b[1].map(m => roleOrd[m.role] || 3));
    return aMin - bMin;
  });
  sortedGroups.forEach(([gName, procs]) => {
    const mapped = procs.filter(m=>m.mapped).length;
    cells.push({type:'md',label:gName,source:`## Process Group: ${gName}\n**${procs.length} processors** | ${mapped} mapped | ${procs.length-mapped} manual`,role:'config'});
    // Sort processors: sources first, then transforms, then sinks
    procs.sort((a,b) => (roleOrd[a.role]||3) - (roleOrd[b.role]||3));
    procs.forEach(m => {
      const lbl = `[${m.role.toUpperCase()}] ${m.name} → ${m.category}`;
      let cellCode = `# ${lbl}\n# ${m.desc}${m.notes ? '  |  ' + m.notes : ''}\n${m.code}`;
      // Wrap mapped processor code in try/except for resilience
      if (m.mapped && m.code && !m.code.startsWith('# TODO')) {
        const indent = m.code.split('\n').map(l => '    ' + l).join('\n');
        cellCode = `# ${lbl}\n# ${m.desc}${m.notes ? '  |  ' + m.notes : ''}\ntry:\n${indent}\n    print(f"[OK] ${m.name.replace(/"/g,'\\"')}")\nexcept Exception as _e:\n    print(f"[ERROR] ${m.name.replace(/"/g,'\\"')}: {_e}")\n    # Quarantine: log failed processor for manual review\n    spark.sql(f"""INSERT INTO ${qualifiedSchema}.__migration_errors VALUES ('${m.name.replace(/'/g,"''")}', '{m.type}', current_timestamp(), '{'{_e}'}')""")`;
      }
      cells.push({type:'code',label:lbl,source:cellCode,role:m.role,processor:m.name,procType:m.type,confidence:m.confidence,mapped:m.mapped});
    });
  });
  // Quarantine table DDL (before footer)
  cells.push({type:'sql',label:'Migration Error Table',source:`CREATE TABLE IF NOT EXISTS ${qualifiedSchema}.__migration_errors (\n  processor_name STRING,\n  processor_type STRING,\n  error_time TIMESTAMP,\n  error_message STRING\n) USING DELTA;`,role:'config'});
  // Footer
  cells.push({type:'code',label:'Pipeline Complete',source:`# Final status report\nerror_count = spark.sql("SELECT count(*) as cnt FROM ${qualifiedSchema}.__migration_errors").collect()[0].cnt\nif error_count > 0:\n    print(f"[WARN] Pipeline complete with {error_count} error(s) — review __migration_errors table")\nelse:\n    print("[SUCCESS] NiFi migration pipeline complete — all processors executed successfully")\ndbutils.notebook.exit(f"COMPLETE: {error_count} errors")`,role:'utility'});
  // Apply placeholder resolution to all code cells
  if (cfg.catalog) {
    cells.forEach(c => { c.source = resolveNotebookPlaceholders(c.source, cfg); });
  }
  return { cells, flowName, metadata: { processorCount: mappings.length, mappedCount: mapCount, generatedAt: new Date().toISOString(), config: { catalog: catalogName, schema: schemaName } }};
}

function generateWorkflowJSON(mappings, nifi, cfg) {
  cfg = cfg || {};
  const wsPath = cfg.workspacePath || '/Workspace/Migrations/NiFi';
  const sparkVer = cfg.sparkVersion || '14.3.x-scala2.12';
  const nodeType = cfg.nodeType || 'Standard_DS3_v2';
  const numWorkers = cfg.numWorkers || 2;
  const conns = nifi.connections || [];
  const procToGroup = {};
  (nifi.processors || []).forEach(p => { procToGroup[p.name] = p.group || '(root)'; });
  const groups = [...new Set(Object.values(procToGroup))];
  const groupDeps = {};
  groups.forEach(g => { groupDeps[g] = new Set(); });
  conns.forEach(c => {
    const sg = procToGroup[c.sourceName], dg = procToGroup[c.destinationName];
    if (sg && dg && sg !== dg) groupDeps[dg].add(sg);
  });
  const tasks = groups.map(g => ({
    task_key: sanitizeVarName(g),
    description: `Process group: ${g}`,
    notebook_task: { notebook_path: `${wsPath}/${sanitizeVarName(g)}_notebook`, source: 'WORKSPACE' },
    depends_on: [...groupDeps[g]].map(d => ({ task_key: sanitizeVarName(d) })),
    new_cluster: { spark_version: sparkVer, node_type_id: nodeType, num_workers: numWorkers }
  }));
  return { name: `NiFi_Migration_${sanitizeVarName(groups[0] || 'flow')}`, tasks, format: 'MULTI_TASK',
    tags: { source: 'nifi_migration', generated_by: 'seg_demo' } };
}

function generateMigrationReport(mappings, nifi) {
  const total = mappings.length, mapped = mappings.filter(m=>m.mapped).length;
  const byRole = {};
  ROLE_TIER_ORDER.forEach(r => { byRole[r] = { total:0, mapped:0, unmapped:0, procs:[] }; });
  mappings.forEach(m => {
    const r = byRole[m.role] || byRole.process;
    r.total++; if (m.mapped) r.mapped++; else r.unmapped++;
    r.procs.push(m);
  });
  const byGroup = {};
  mappings.forEach(m => {
    if (!byGroup[m.group]) byGroup[m.group] = { total:0, mapped:0, unmapped:0, procs:[] };
    byGroup[m.group].total++; if (m.mapped) byGroup[m.group].mapped++; else byGroup[m.group].unmapped++;
    byGroup[m.group].procs.push(m);
  });
  const gaps = mappings.filter(m => !m.mapped || m.confidence < 0.3).map(m => ({
    name: m.name, type: m.type, group: m.group, role: m.role,
    reason: m.gapReason || `Low confidence mapping (${Math.round(m.confidence*100)}%)`,
    recommendation: m.type.match(/^(Listen|Handle)/) ? 'Consider Databricks Model Serving or external API gateway'
      : m.type.match(/^Execute(Script|Stream)/) ? 'Manual translation required — review original script logic'
      : m.type.match(/^(Put|Send)(Email|TCP|Syslog)/) ? 'Use webhook notification service or Databricks workflow alerts'
      : 'Review processor documentation and implement custom PySpark logic'
  }));
  const recs = [];
  if (gaps.length > total * 0.2) recs.push('High gap rate — consider custom UDFs for unsupported processor types');
  if (mappings.some(m => m.type.match(/Listen|Handle/))) recs.push('HTTP endpoints detected — evaluate Databricks Model Serving for REST API replacement');
  if (mappings.some(m => m.type.match(/Consume.*Kafka|Subscribe/))) recs.push('Streaming sources present — use Structured Streaming with Auto Loader trigger intervals');
  if ((nifi.controllerServices||[]).length) recs.push(`${nifi.controllerServices.length} controller service(s) detected — map credentials to Databricks secret scopes`);
  if (mapped > total * 0.8) recs.push('High coverage — prioritize testing the mapped processors before addressing gaps');
  recs.push('Run the generated notebook in a Databricks workspace to validate each cell');
  const coveragePct = total ? Math.round(mapped / total * 100) : 0;
  const effort = coveragePct >= 85 ? 'Low' : coveragePct >= 60 ? 'Medium' : 'High';
  return { summary: { totalProcessors: total, mappedProcessors: mapped, unmappedProcessors: total - mapped, coveragePercent: coveragePct,
    totalProcessGroups: Object.keys(byGroup).length, totalConnections: (nifi.connections||[]).length, controllerServices: (nifi.controllerServices||[]).length },
    byRole, byGroup, gaps, recommendations: recs, effort };
}

// ================================================================
// STEP 8 — CROSS-COMPARISON LOGIC
// ================================================================
function computeComparison(mappings, nifi) {
  const total = mappings.length;
  // Exact match: high-confidence direct 1:1 mappings (conf >= 0.8)
  const exactCount = mappings.filter(m => m.mapped && m.confidence >= 0.8).length;
  // Functional match: any mapped processor (intent preserved regardless of confidence)
  const funcCount = mappings.filter(m => m.mapped).length;
  // Actions converted: connections where BOTH source and destination are mapped
  const conns = nifi.connections || [];
  const mappedNames = new Set(mappings.filter(m => m.mapped).map(m => m.name));
  const totalActions = conns.length;
  const convertedActions = conns.filter(c => mappedNames.has(c.sourceName) && mappedNames.has(c.destinationName)).length;
  // Build comparison rows
  const rows = mappings.map((m, i) => {
    let matchType;
    if (!m.mapped) matchType = 'gap';
    else if (m.confidence >= 0.8) matchType = 'exact';
    else matchType = 'functional';
    return { idx: i + 1, name: m.name, type: m.type, group: m.group || '—', role: m.role,
      equiv: m.mapped ? m.desc : '—', category: m.mapped ? m.category : '—',
      matchType, confidence: m.confidence, code: m.code };
  });
  return {
    exact: { count: exactCount, total, pct: total ? Math.round(exactCount / total * 100) : 0 },
    functional: { count: funcCount, total, pct: total ? Math.round(funcCount / total * 100) : 0 },
    actions: { count: convertedActions, total: totalActions, pct: totalActions ? Math.round(convertedActions / totalActions * 100) : 0 },
    rows
  };
}

function donutSVG(pct, label, sublabel) {
  const r = 54, circ = 2 * Math.PI * r;
  const filled = circ * pct / 100, gap = circ - filled;
  const color = pct >= 85 ? '#21C354' : pct >= 60 ? '#EAB308' : '#EF4444';
  const track = 'rgba(128,132,149,0.15)';
  return `<div class="donut-chart">
    <svg width="140" height="140" viewBox="0 0 140 140">
      <circle cx="70" cy="70" r="${r}" fill="none" stroke="${track}" stroke-width="12"/>
      <circle cx="70" cy="70" r="${r}" fill="none" stroke="${color}" stroke-width="12"
        stroke-dasharray="${filled} ${gap}" stroke-dashoffset="${circ * 0.25}"
        stroke-linecap="round" style="transition:stroke-dasharray 0.6s ease"/>
      <text x="70" y="66" text-anchor="middle" fill="${color}" font-size="28" font-weight="800">${pct}%</text>
      <text x="70" y="84" text-anchor="middle" fill="#9ca3af" font-size="11">${sublabel}</text>
    </svg>
    <div class="donut-label">${label}</div>
  </div>`;
}

// Tarjan's SCC algorithm — returns arrays of node groups forming cycles (size > 1 only)
function detectCyclesSCC(adjacencyMap) {
  let idx = 0; const stack = [], onStack = new Set(), indices = {}, lowlinks = {}, sccs = [];
  function sc(v) {
    indices[v] = lowlinks[v] = idx++;
    stack.push(v); onStack.add(v);
    for (const w of (adjacencyMap[v] || [])) {
      if (indices[w] === undefined) { sc(w); lowlinks[v] = Math.min(lowlinks[v], lowlinks[w]); }
      else if (onStack.has(w)) { lowlinks[v] = Math.min(lowlinks[v], indices[w]); }
    }
    if (lowlinks[v] === indices[v]) {
      const scc = []; let w;
      do { w = stack.pop(); onStack.delete(w); scc.push(w); } while (w !== v);
      if (scc.length > 1) sccs.push(scc);
    }
  }
  for (const v of Object.keys(adjacencyMap)) { if (indices[v] === undefined) sc(v); }
  return sccs;
}

function classifyGroupDominantRole(stats) {
  const counts = [['source',stats.sources],['route',stats.routes],['transform',stats.transforms],
    ['process',stats.processes],['sink',stats.sinks],['utility',stats.utilities]];
  counts.sort((a,b) => b[1] !== a[1] ? b[1] - a[1] : ROLE_TIER_ORDER.indexOf(a[0]) - ROLE_TIER_ORDER.indexOf(b[0]));
  return counts[0][1] > 0 ? counts[0][0] : 'process';
}

// BFS shortest path through directed connections array; returns {pathNodes, pathEdgeKeys, found}
function bfsShortestPath(connections, startId, endId) {
  const adj = {};
  connections.forEach(c => {
    if (!adj[c.from]) adj[c.from] = [];
    adj[c.from].push({ to: c.to, key: c.from + '|' + c.to });
  });
  const visited = new Set([startId]);
  const parent = {};
  const queue = [startId];
  while (queue.length) {
    const cur = queue.shift();
    if (cur === endId) {
      const pathNodes = [], pathEdgeKeys = [];
      let n = endId;
      while (n !== startId) { pathNodes.unshift(n); pathEdgeKeys.unshift(parent[n].key); n = parent[n].from; }
      pathNodes.unshift(startId);
      return { pathNodes, pathEdgeKeys, found: true };
    }
    for (const nb of (adj[cur] || [])) {
      if (!visited.has(nb.to)) { visited.add(nb.to); parent[nb.to] = { from: cur, key: nb.key }; queue.push(nb.to); }
    }
  }
  return { pathNodes: [], pathEdgeKeys: [], found: false };
}

function buildTierData(blueprint, parsed) {
  const fmt = parsed ? parsed.input_format : '';
  if (fmt === 'nifi_xml' && parsed._nifi) return buildNiFiTierData(parsed._nifi, blueprint);
  if (fmt === 'dependency_json' && parsed._dependency) return buildDependencyTierData(parsed._dependency, blueprint);
  if (blueprint.relationships && blueprint.relationships.length > 0) return buildSQLTierData(blueprint);
  return buildFlatTierData(blueprint);
}

function buildNiFiTierData(nifi, blueprint) {
  const nodes = [], connections = [];
  const tierLabels = {};
  const processors = nifi.processors || [];
  const conns = nifi.connections || [];
  const processGroups = nifi.processGroups || [];

  // ── Step 1: Build per-group stats ──
  const groupStats = {};  // groupName -> {sources, sinks, routes, transforms, processes, utilities, total, processors:[]}
  processors.forEach(p => {
    const g = p.group || '(root)';
    if (!groupStats[g]) groupStats[g] = { sources:0, sinks:0, routes:0, transforms:0, processes:0, utilities:0, total:0, processors:[], typeCount:{} };
    const role = classifyNiFiProcessor(p.type);
    groupStats[g][role + 's'] = (groupStats[g][role + 's'] || 0) + 1;
    groupStats[g].total++;
    groupStats[g].processors.push(p);
    groupStats[g].typeCount[p.type] = (groupStats[g].typeCount[p.type] || 0) + 1;
  });

  // ── Step 2: Build inter-group connections ──
  // Map processor name -> group
  const procToGroup = {};
  processors.forEach(p => { procToGroup[p.name] = p.group || '(root)'; });
  // Count inter-group connections
  const interGroupConns = {};  // "fromGroup|toGroup" -> count
  const intraGroupConns = {};  // groupName -> count
  conns.forEach(c => {
    const srcGroup = procToGroup[c.sourceName] || '(root)';
    const dstGroup = procToGroup[c.destinationName] || '(root)';
    if (srcGroup !== dstGroup) {
      const key = srcGroup + '|' + dstGroup;
      interGroupConns[key] = (interGroupConns[key] || 0) + 1;
    } else {
      intraGroupConns[srcGroup] = (intraGroupConns[srcGroup] || 0) + 1;
    }
  });

  // ── Step 3: Detect cycles + assign role-based tiers ──
  const groupNames = Object.keys(groupStats);
  const groupDownstream = {};
  Object.keys(interGroupConns).forEach(key => {
    const [from, to] = key.split('|');
    if (!groupDownstream[from]) groupDownstream[from] = new Set();
    groupDownstream[from].add(to);
  });
  groupNames.forEach(gn => { if (!groupDownstream[gn]) groupDownstream[gn] = new Set(); });

  const sccs = detectCyclesSCC(groupDownstream);
  const cycleGroups = new Set();
  const groupToSCC = {};
  sccs.forEach((scc, i) => { scc.forEach(gn => { cycleGroups.add(gn); groupToSCC[gn] = i; }); });

  // Assign dominant role per group
  const groupDominantRole = {};
  groupNames.forEach(gn => { groupDominantRole[gn] = classifyGroupDominantRole(groupStats[gn]); });

  // Group groups by dominant role
  const roleGroups = {};
  ROLE_TIER_ORDER.forEach(r => { roleGroups[r] = []; });
  groupNames.forEach(gn => { roleGroups[groupDominantRole[gn]].push(gn); });
  // Sort within each role: purity desc, then total desc
  ROLE_TIER_ORDER.forEach(role => {
    const key = role + 's';
    roleGroups[role].sort((a, b) => {
      const aFrac = (groupStats[a][key] || 0) / (groupStats[a].total || 1);
      const bFrac = (groupStats[b][key] || 0) / (groupStats[b].total || 1);
      if (bFrac !== aFrac) return bFrac - aFrac;
      return groupStats[b].total - groupStats[a].total;
    });
  });

  // ── Step 4: Build role-based tier layout ──
  let tierNum = 0;
  ROLE_TIER_ORDER.forEach(role => {
    const groups = roleGroups[role];
    if (!groups.length) return;
    tierNum++;
    const color = ROLE_TIER_COLORS[role];
    const rgb = color.replace('#','').match(/.{2}/g).map(h => parseInt(h, 16));
    tierLabels[tierNum] = { label: ROLE_TIER_LABELS[role], color, bg: `rgba(${rgb[0]},${rgb[1]},${rgb[2]},0.06)`, role };

    groups.forEach(gn => {
      const stats = groupStats[gn];
      const topTypes = Object.entries(stats.typeCount).sort((a, b) => b[1] - a[1]).slice(0, 3).map(([t, c]) => `${t}(${c})`).join(', ');
      const inCycle = cycleGroups.has(gn);
      const sccIdx = groupToSCC[gn];
      const sccMembers = inCycle ? sccs[sccIdx] : [];
      const cycleEdges = inCycle ? Object.entries(interGroupConns)
        .filter(([k]) => { const [f, t] = k.split('|'); return sccs[sccIdx].includes(f) && sccs[sccIdx].includes(t); })
        .map(([k, v]) => { const [f, t] = k.split('|'); return { from: f, to: t, count: v }; }) : [];

      nodes.push({
        id: 'pg_' + gn, name: gn, tier: tierNum,
        type: 'process_group', dominantRole: groupDominantRole[gn],
        subtype: groupDominantRole[gn] + 's',
        procCount: stats.total,
        srcCount: stats.sources, sinkCount: stats.sinks,
        routeCount: stats.routes, transformCount: stats.transforms,
        processCount: stats.processes, utilityCount: stats.utilities,
        intraConns: intraGroupConns[gn] || 0,
        topTypes, inCycle, sccMembers, cycleEdges, expandable: true,
        detail: { processors: stats.processors, typeCount: stats.typeCount, intraConns: intraGroupConns[gn] || 0 }
      });
    });
  });

  // ── Step 5: Build inter-group connections (red for cycle edges) ──
  Object.entries(interGroupConns).forEach(([key, count]) => {
    const [from, to] = key.split('|');
    const bothInCycle = cycleGroups.has(from) && cycleGroups.has(to) && groupToSCC[from] === groupToSCC[to];
    connections.push({
      from: 'pg_' + from, to: 'pg_' + to,
      label: count > 1 ? count + ' flows' : '1 flow',
      type: 'flow', color: bothInCycle ? '#EF4444' : '#4B5563',
      width: Math.min(1 + count * 0.3, 4), inCycle: bothInCycle
    });
  });

  // ── Step 6: Connection density sidebar ──
  const densityData = [];
  const globalTypeCount = {};
  processors.forEach(p => { globalTypeCount[p.type] = (globalTypeCount[p.type] || 0) + 1; });
  Object.entries(globalTypeCount).sort((a, b) => b[1] - a[1]).forEach(([type, count]) => {
    const role = classifyNiFiProcessor(type);
    densityData.push({ name: type, writers: count, readers: 0, lookups: 0, total: count, role });
  });

  // ── Step 7: Cycle summary ──
  const cycleData = sccs.map((scc, i) => ({
    id: i, groups: scc,
    edgeCount: Object.keys(interGroupConns).filter(k => { const [f, t] = k.split('|'); return scc.includes(f) && scc.includes(t); }).length
  }));

  return { nodes, connections, tierLabels, diagramType: 'nifi_flow', densityData, cycleData };
}

function buildSQLTierData(blueprint) {
  const nodes = [], connections = [];
  const tierLabels = {};
  // Compute dependency depth via topological sort
  const depthMap = {};
  const tableNames = blueprint.tables.map(t => t.name);
  const fkTargets = {};
  blueprint.tables.forEach(t => {
    t.foreign_keys.forEach(fk => {
      const ref = fk.references_table;
      if (!fkTargets[t.name]) fkTargets[t.name] = [];
      fkTargets[t.name].push(ref);
    });
  });
  function getDepth(tn, visited) {
    if (depthMap[tn] !== undefined) return depthMap[tn];
    if (visited.has(tn)) return 0; // cycle
    visited.add(tn);
    const deps = fkTargets[tn] || [];
    if (!deps.length) { depthMap[tn] = 0; return 0; }
    const maxDep = Math.max(...deps.map(d => getDepth(d, new Set(visited))));
    depthMap[tn] = maxDep + 1;
    return depthMap[tn];
  }
  tableNames.forEach(tn => getDepth(tn, new Set()));
  const maxDepth = Math.max(0, ...Object.values(depthMap));
  // Build tier labels
  for (let d = 0; d <= maxDepth; d++) {
    if (d === 0) tierLabels[1] = {label:'INDEPENDENT TABLES', color:'#3B82F6', bg:'rgba(59,130,246,0.06)'};
    else tierLabels[d+1] = {label:`DEPENDENCY LEVEL ${d}`, color: d===1?'#EAB308':d===2?'#A855F7':'#21C354', bg: d===1?'rgba(234,179,8,0.06)':d===2?'rgba(168,85,247,0.06)':'rgba(33,195,84,0.06)'};
  }
  // Build nodes
  blueprint.tables.forEach(t => {
    const depth = depthMap[t.name] || 0;
    const pkCols = t.columns.filter(c => c.is_primary_key);
    nodes.push({
      id: t.name,
      name: t.name,
      tier: depth + 1,
      type: 'table',
      meta: `${t.columns.length} cols${pkCols.length?' · PK: '+pkCols.map(c=>c.name).join(','):''}`,
      rows: t.row_count,
      fkCount: t.foreign_keys.length,
      detail: t
    });
  });
  // Build connections from relationships
  blueprint.relationships.forEach(r => {
    const fromName = r.from_table.split('.').pop();
    const toName = r.to_table.split('.').pop();
    const colLabel = r.join_columns.map(j => `${j.from_column}→${j.to_column}`).join(', ');
    connections.push({
      from: fromName, to: toName,
      label: colLabel,
      type: 'foreign_key', color: '#3B82F6', width: 2
    });
  });
  return {nodes, connections, tierLabels, diagramType: 'sql_tables'};
}

function buildFlatTierData(blueprint) {
  const nodes = [], connections = [];
  const tierLabels = {1:{label:'SCHEMA OBJECTS',color:'#3B82F6',bg:'rgba(59,130,246,0.06)'}};
  blueprint.tables.forEach(t => {
    nodes.push({
      id: t.name, name: t.name, tier: 1, type: 'table',
      meta: `${t.columns.length} cols`,
      rows: t.row_count, detail: t
    });
  });
  // Look for implicit connections: shared column names between tables
  const colToTables = {};
  blueprint.tables.forEach(t => {
    t.columns.forEach(c => {
      const cn = c.name.toLowerCase();
      if (!colToTables[cn]) colToTables[cn] = [];
      colToTables[cn].push(t.name);
    });
  });
  Object.entries(colToTables).forEach(([cn, tbls]) => {
    if (tbls.length === 2 && (cn.endsWith('_id') || cn === 'id')) {
      connections.push({from:tbls[0], to:tbls[1], label:cn, type:'implicit', color:'#4B5563', width:1, dash:true});
    }
  });
  return {nodes, connections, tierLabels, diagramType: 'flat'};
}

function buildDependencyTierData(dep, blueprint) {
  const nodes = [], connections = [];
  const tierLabels = {};
  const sessions = dep.sessions || [];
  const edges = dep.edges || [];
  const order = dep.order || [];
  const conflicts = dep.conflicts || [];
  const rawSessions = dep.rawSessions || {};
  const allTables = dep.allTables || {};

  // ── Step 1: Build session adjacency + topological depth ──
  const depthMap = {};
  const upstreamMap = {};   // session -> [upstream session names]
  const downstreamMap = {}; // session -> [downstream session names]
  const edgeVia = {};       // "up|down" -> via_table
  edges.forEach(e => {
    const up = e.upstream || e.upstream_session || e.from;
    const down = e.downstream || e.downstream_session || e.to;
    if (!upstreamMap[down]) upstreamMap[down] = [];
    upstreamMap[down].push(up);
    if (!downstreamMap[up]) downstreamMap[up] = [];
    downstreamMap[up].push(down);
    edgeVia[up + '|' + down] = e.shared_tables ? e.shared_tables.join(', ') : (e.via_table || '');
  });
  const sessionNames = sessions.map(s => s.name);
  function getDepth(sn, visited) {
    if (depthMap[sn] !== undefined) return depthMap[sn];
    if (visited.has(sn)) return 0;
    visited.add(sn);
    const ups = upstreamMap[sn] || [];
    if (!ups.length) { depthMap[sn] = 0; return 0; }
    const maxD = Math.max(...ups.map(u => getDepth(u, new Set(visited))));
    depthMap[sn] = maxD + 1;
    return depthMap[sn];
  }
  sessionNames.forEach(sn => getDepth(sn, new Set()));
  if (order.length && Math.max(0, ...Object.values(depthMap)) === 0) {
    order.forEach((sn, i) => { depthMap[sn] = i; });
  }
  const maxSessionDepth = Math.max(0, ...Object.values(depthMap));

  // ── Step 2: Build table index from raw session data ──
  const tableWriters = {};  // table -> [session names that write it]
  const tableReaders = {};  // table -> [session names that read it as source]
  const tableLookups = {};  // table -> [session names that use it as lookup]
  for (const [sName, sess] of Object.entries(rawSessions)) {
    (sess.target_tables || []).forEach(t => {
      if (!tableWriters[t.name]) tableWriters[t.name] = [];
      tableWriters[t.name].push(sName);
    });
    (sess.source_tables || []).forEach(t => {
      if (!tableReaders[t.name]) tableReaders[t.name] = [];
      tableReaders[t.name].push(sName);
    });
    (sess.lookup_tables || []).forEach(t => {
      if (!tableLookups[t.name]) tableLookups[t.name] = [];
      tableLookups[t.name].push(sName);
    });
  }

  // ── Step 3: Classify tables ──
  // Chain tables: written by one session, read/looked-up by different sessions
  // Independent: written but only read back by the same writer
  // Conflict: written by multiple sessions
  const chainTables = {};    // table -> {writers, readers, lookups, isConflict, isChain}
  const conflictMap = {};
  conflicts.forEach(c => {
    if (!conflictMap[c.table_name]) conflictMap[c.table_name] = [];
    conflictMap[c.table_name].push(c);
  });
  const allWrittenTables = Object.keys(tableWriters);
  allWrittenTables.forEach(tn => {
    const writers = tableWriters[tn] || [];
    const readers = (tableReaders[tn] || []).filter(r => !writers.includes(r));
    const lookups = (tableLookups[tn] || []).filter(l => !writers.includes(l));
    const isConflict = writers.length > 1 || !!(conflictMap[tn] && conflictMap[tn].length);
    const isChain = readers.length > 0 || lookups.length > 0;
    if (isConflict || isChain) {
      chainTables[tn] = { writers, readers, lookups, isConflict, isChain, conflicts: conflictMap[tn] || [] };
    }
  });

  // ── Step 4: Group sessions by depth (wave) ──
  const waves = {};
  sessionNames.forEach(sn => {
    const d = depthMap[sn] || 0;
    if (!waves[d]) waves[d] = [];
    waves[d].push(sn);
  });
  const sortedWaves = Object.keys(waves).map(Number).sort((a, b) => a - b);

  // ── Step 5: Build interleaved tiers (session → outputs → conflict gate → next session) ──
  let tierNum = 0;
  const sessionTier = {};    // session name -> tier number
  const tableTier = {};      // table name -> tier number (for output tables)
  const sessionSeqMap = {};  // session name -> execution order number
  order.forEach((sn, i) => { sessionSeqMap[sn] = i + 1; });
  // If no order, assign by depth then alphabetical
  if (!order.length) sessionNames.sort().forEach((sn, i) => { sessionSeqMap[sn] = i + 1; });

  const tierColorPool = ['#3B82F6','#EAB308','#A855F7','#21C354','#F97316','#EC4899','#06B6D4','#8B5CF6','#F43F5E','#10B981'];
  const tierBgPool = ['rgba(59,130,246,0.06)','rgba(234,179,8,0.06)','rgba(168,85,247,0.06)','rgba(33,195,84,0.06)','rgba(249,115,22,0.06)','rgba(236,72,153,0.06)','rgba(6,182,212,0.06)','rgba(139,92,246,0.06)','rgba(244,63,94,0.06)','rgba(16,185,129,0.06)'];
  function tierColor(n) { return tierColorPool[n % tierColorPool.length]; }
  function tierBg(n) { return tierBgPool[n % tierBgPool.length]; }

  // Pre-compute: for each multi-writer conflict table, find which wave contains its LAST writer
  const conflictLastWave = {};  // table name -> wave index of last writer
  allWrittenTables.forEach(tn => {
    const info = chainTables[tn];
    if (info && info.isConflict && info.writers.length > 1) {
      let maxWave = 0;
      info.writers.forEach(w => {
        const d = depthMap[w] || 0;
        if (d > maxWave) maxWave = d;
      });
      conflictLastWave[tn] = maxWave;
    }
  });
  const placedTables = new Set();  // Track globally placed table nodes

  sortedWaves.forEach((waveIdx, wi) => {
    const waveSessions = waves[waveIdx];

    // ── Session tier ──
    tierNum++;
    const sLabel = waveIdx === 0 ? 'INDEPENDENT PARALLEL EXECUTION'
      : (wi === sortedWaves.length - 1 && sortedWaves.length > 1) ? 'END OF PIPELINE'
      : `EXECUTION WAVE ${waveIdx}`;
    tierLabels[tierNum] = { label: `TIER ${wi + 1} — ${sLabel}`, color: tierColor(tierNum), bg: tierBg(tierNum) };

    waveSessions.forEach(sn => {
      sessionTier[sn] = tierNum;
      const sess = rawSessions[sn] || {};
      const srcCount = (sess.source_tables || []).length;
      const tgtCount = (sess.target_tables || []).length;
      const lkpCount = (sess.lookup_tables || []).length;
      const sConflicts = [];
      Object.values(conflictMap).forEach(cArr => cArr.forEach(c => {
        if ((c.writers || []).includes(sn)) sConflicts.push(c);
      }));
      nodes.push({
        id: sn, name: sn, tier: tierNum,
        type: 'session', subtype: waveIdx === 0 ? 'root' : 'dependent',
        seq: sessionSeqMap[sn] || 0,
        srcCount, tgtCount, lkpCount,
        hasConflict: sConflicts.length > 0,
        conflictDetails: sConflicts,
        detail: { sources: srcCount, targets: tgtCount, lookups: lkpCount,
          source_tables: sess.source_tables, target_tables: sess.target_tables, lookup_tables: sess.lookup_tables }
      });
    });

    // ── Collect output tables for this wave ──
    const waveOutputTables = [];
    const waveConflictTables = [];
    waveSessions.forEach(sn => {
      const sess = rawSessions[sn] || {};
      (sess.target_tables || []).forEach(t => {
        if (placedTables.has(t.name)) return;  // Already placed in an earlier tier
        const info = chainTables[t.name];
        if (info && info.isConflict && info.writers.length > 1) {
          // Multi-writer conflict — only place gate after the LAST writer's wave
          if (conflictLastWave[t.name] === waveIdx && !waveConflictTables.find(x => x.name === t.name)) {
            waveConflictTables.push({ name: t.name, info });
          }
        } else if (!info) {
          if (!waveOutputTables.find(x => x.name === t.name)) {
            waveOutputTables.push({ name: t.name, isChain: false, isConflict: false, writer: sn, loadType: t.load_type || '' });
          }
        } else {
          if (!waveOutputTables.find(x => x.name === t.name)) {
            waveOutputTables.push({ name: t.name, isChain: info.isChain, isConflict: info.isConflict, writer: sn, loadType: t.load_type || '' });
          }
        }
      });
    });

    // ── Output tables tier (if any) ──
    if (waveOutputTables.length) {
      tierNum++;
      tierLabels[tierNum] = { label: `TIER ${wi + 1} OUTPUTS${waveOutputTables.some(t=>t.isChain) ? ' & CHAIN TABLES' : ''}`, color: '#6366F1', bg: 'rgba(99,102,241,0.04)' };
      waveOutputTables.forEach(t => {
        placedTables.add(t.name);
        tableTier[t.name] = tierNum;
        const cls = t.isChain ? 'chain' : 'independent';
        nodes.push({
          id: 'tbl_' + t.name, name: t.name, tier: tierNum,
          type: 'table_output', subtype: cls,
          isConflict: t.isConflict, isChain: t.isChain,
          writer: t.writer, loadType: t.loadType,
          detail: { writers: tableWriters[t.name] || [], readers: tableReaders[t.name] || [], lookups: tableLookups[t.name] || [], conflicts: conflictMap[t.name] || [] }
        });
      });
    }

    // ── Conflict gate tier (for multi-writer tables whose last writer is in THIS wave) ──
    if (waveConflictTables.length) {
      tierNum++;
      const gateLabel = waveConflictTables.length === 1
        ? `CRITICAL GATE — ${waveConflictTables[0].name} CONFLICT`
        : `CRITICAL GATE — ${waveConflictTables.length} CONFLICT TABLES`;
      tierLabels[tierNum] = { label: gateLabel, color: '#EF4444', bg: 'rgba(239,68,68,0.06)' };
      waveConflictTables.forEach(t => {
        placedTables.add(t.name);
        tableTier[t.name] = tierNum;
        const info = t.info;
        nodes.push({
          id: 'gate_' + t.name, name: t.name, tier: tierNum,
          type: 'conflict_gate',
          writerCount: info.writers.length,
          readerCount: info.readers.length,
          lookupCount: info.lookups.length,
          conflictTypes: info.conflicts.map(c => c.conflict_type),
          detail: { writers: info.writers, readers: info.readers, lookups: info.lookups, conflicts: info.conflicts }
        });
      });
    }
  });

  // ── Final outputs tier — target tables from the terminal sessions ──
  const terminalWave = sortedWaves[sortedWaves.length - 1];
  const terminalSessions = waves[terminalWave] || [];
  const finalOutputs = [];
  terminalSessions.forEach(sn => {
    const sess = rawSessions[sn] || {};
    (sess.target_tables || []).forEach(t => {
      if (!placedTables.has(t.name) && !finalOutputs.find(x => x.name === t.name)) {
        const info = chainTables[t.name];
        finalOutputs.push({ name: t.name, isConflict: !!(info && info.isConflict), isChain: !!(info && info.isChain), writer: sn });
      }
    });
  });
  if (finalOutputs.length) {
    tierNum++;
    tierLabels[tierNum] = { label: 'FINAL OUTPUTS & CONFLICTS', color: '#EF4444', bg: 'rgba(239,68,68,0.04)' };
    finalOutputs.forEach(t => {
      tableTier[t.name] = tierNum;
      nodes.push({
        id: 'final_' + t.name, name: t.name, tier: tierNum,
        type: 'table_output', subtype: t.isChain ? 'chain' : 'independent',
        isConflict: t.isConflict, isChain: t.isChain, writer: t.writer,
        detail: { writers: tableWriters[t.name] || [], readers: tableReaders[t.name] || [], lookups: tableLookups[t.name] || [], conflicts: conflictMap[t.name] || [] }
      });
    });
  }

  // ── Step 6: Build connections ──
  // Session → its output tables
  for (const [sn, sess] of Object.entries(rawSessions)) {
    (sess.target_tables || []).forEach(t => {
      const tableId = nodes.find(n => (n.type === 'table_output' || n.type === 'conflict_gate') && n.name === t.name);
      if (tableId) {
        connections.push({ from: sn, to: tableId.id, label: '', type: 'produces', color: '#6366F1', width: 1.5 });
      }
    });
  }
  // Output/gate tables → downstream sessions that read them
  nodes.filter(n => n.type === 'table_output' || n.type === 'conflict_gate').forEach(tblNode => {
    const readers = (tableReaders[tblNode.name] || []).filter(r => !((tableWriters[tblNode.name] || []).includes(r)));
    const lookups = (tableLookups[tblNode.name] || []).filter(l => !((tableWriters[tblNode.name] || []).includes(l)));
    readers.forEach(r => {
      if (nodes.find(n => n.id === r)) {
        connections.push({ from: tblNode.id, to: r, label: 'reads', type: 'dependency', color: '#6366F1', width: 1.5 });
      }
    });
    lookups.forEach(l => {
      if (nodes.find(n => n.id === l)) {
        connections.push({ from: tblNode.id, to: l, label: 'lookup', type: 'lookup', color: '#F59E0B', width: 1, dash: true });
      }
    });
  });
  // Direct session → session edges where no intermediate table node exists
  edges.forEach(e => {
    const up = e.upstream || e.upstream_session || e.from;
    const down = e.downstream || e.downstream_session || e.to;
    const via = e.shared_tables ? e.shared_tables.join(', ') : (e.via_table || '');
    // Check if we already have session→table→session path for this edge
    const viaTableNode = via ? nodes.find(n => (n.type === 'table_output' || n.type === 'conflict_gate') && n.name === via) : null;
    if (!viaTableNode) {
      const isConflict = via ? !!(conflictMap[via] && conflictMap[via].length) : false;
      connections.push({
        from: up, to: down, label: via ? 'via ' + via : '',
        type: isConflict ? 'conflict' : 'dependency',
        color: isConflict ? '#EF4444' : '#6366F1', width: isConflict ? 2.5 : 1.5
      });
    }
  });

  // Deduplicate connections (same from→to→type)
  const connKeys = new Set();
  const dedupedConns = [];
  connections.forEach(c => {
    const key = `${c.from}|${c.to}|${c.type}`;
    if (!connKeys.has(key)) { connKeys.add(key); dedupedConns.push(c); }
  });
  connections.length = 0;
  connections.push(...dedupedConns);

  // ── Step 7: Connection density data for sidebar ──
  const densityData = [];
  Object.keys(tableWriters).forEach(tn => {
    const w = (tableWriters[tn] || []).length;
    const r = (tableReaders[tn] || []).filter(x => !(tableWriters[tn] || []).includes(x)).length;
    const l = (tableLookups[tn] || []).filter(x => !(tableWriters[tn] || []).includes(x)).length;
    const total = w + r + l;
    if (total > 0) densityData.push({ name: tn, writers: w, readers: r, lookups: l, total, isConflict: !!(conflictMap[tn] && conflictMap[tn].length) });
  });
  densityData.sort((a, b) => b.total - a.total);

  return { nodes, connections, tierLabels, diagramType: 'dependency_graph', densityData };
}

// ================================================================
// ENVIRONMENT SUMMARY — Source-specific dashboard
// ================================================================
function buildEnvironmentSummary(parsed, bp) {
  if (!parsed) return '';
  const fmt = parsed.input_format || '';
  let h = '<h3>Environment Overview</h3>';
  if (fmt === 'nifi_xml' && parsed._nifi) {
    const nf = parsed._nifi;
    // NiFi environment reconstruction
    const byRole = {};
    nf.processors.forEach(p => {
      const role = classifyNiFiProcessor(p.type);
      if (!byRole[role]) byRole[role] = [];
      byRole[role].push(p);
    });
    h += '<div class="alert alert-info"><strong>NiFi Flow Environment</strong> — reconstructed from template XML</div>';
    h += '<div class="row">';
    // Flow topology card
    h += '<div class="col-3">';
    h += metricsHTML([['Sources', (byRole.source||[]).length], ['Transforms', (byRole.transform||[]).length + (byRole.route||[]).length]]);
    h += '</div><div class="col-3">';
    h += metricsHTML([['Processors', (byRole.process||[]).length], ['Sinks', (byRole.sink||[]).length]]);
    h += '</div><div class="col-3">';
    // Scheduling profile
    const schedTypes = {};
    nf.processors.forEach(p => { const s = p.schedulingStrategy||'TIMER_DRIVEN'; schedTypes[s]=(schedTypes[s]||0)+1; });
    const schedInfo = Object.entries(schedTypes).map(([k,v])=>`${k}: ${v}`).join(', ');
    h += metricsHTML([['Scheduling', schedInfo], ['Controller Svc', nf.controllerServices.length]]);
    h += '</div></div>';
    // Data lineage
    if (nf.sqlTables && nf.sqlTables.length) {
      h += `<div class="alert alert-warn">SQL Lineage: ${nf.sqlTables.length} table references found across processors — ${nf.sqlTables.slice(0,5).join(', ')}${nf.sqlTables.length>5?'...':''}</div>`;
    }
  } else if (fmt === 'dependency_json' && parsed._dependency) {
    const dep = parsed._dependency;
    const allTableCount = Object.keys(dep.allTables || {}).length;
    const conflictCount = dep.conflicts.length;
    h += '<div class="alert alert-info"><strong>ETL Dependency Graph</strong> — session lineage with table-level dependencies</div>';
    h += '<div class="row">';
    h += '<div class="col-3">';
    h += metricsHTML([['Sessions', dep.sessions.length], ['Dep. Edges', dep.edges.length]]);
    h += '</div><div class="col-3">';
    h += metricsHTML([['Tables Referenced', allTableCount], ['Exec. Order Steps', dep.order.length]]);
    h += '</div><div class="col-3">';
    h += metricsHTML([['Conflicts', conflictCount], ['Types', [...new Set(dep.conflicts.map(c=>c.conflict_type))].length || 0]]);
    h += '</div></div>';
    if (conflictCount) {
      h += `<div class="alert alert-warn">${conflictCount} table conflict(s): ${dep.conflicts.slice(0,3).map(c=>c.table_name+' ('+c.conflict_type+')').join(', ')}${conflictCount>3?'...':''}</div>`;
    }
  } else {
    // Generic environment summary
    const totalCols = bp.tables.reduce((a,t)=>a+t.columns.length,0);
    const pkTables = bp.tables.filter(t => t.columns.some(c=>c.is_primary_key));
    const fkCount = bp.relationships.length;
    const types = {};
    bp.tables.forEach(t => t.columns.forEach(c => { types[c.data_type]=(types[c.data_type]||0)+1; }));
    const topTypes = Object.entries(types).sort((a,b)=>b[1]-a[1]).slice(0,5).map(([t,c])=>`${t}(${c})`).join(', ');
    h += `<div class="alert alert-info"><strong>${parsed.source_name||'Source'}</strong> — ${bp.tables.length} tables, ${totalCols} columns, ${fkCount} relationships</div>`;
    h += `<p style="font-size:0.85rem;color:var(--text2);margin:8px 0">Tables with PKs: ${pkTables.length}/${bp.tables.length} · Top types: ${topTypes}</p>`;
    if (fkCount === 0 && bp.tables.length > 1) {
      h += '<div class="alert alert-warn">No foreign key relationships detected — tables will be generated independently</div>';
    }
  }
  return h;
}

// ================================================================
// TIER DIAGRAM — SVG Rendering Engine
// ================================================================
function renderTierDiagram(tierData, containerId, detailId, legendId) {
  const container = document.getElementById(containerId);
  const detailEl = document.getElementById(detailId);
  const legendEl = document.getElementById(legendId);
  if (!container) return;
  container.innerHTML = '';
  container.style.minHeight = '200px';

  const {nodes, connections, tierLabels, diagramType, densityData} = tierData;
  if (!nodes.length) { container.innerHTML = '<p style="text-align:center;padding:20px;color:var(--text2)">No nodes to display</p>'; return; }

  // Multi-select state (closure-scoped)
  const _ms = { selected: [], pathNodes: new Set(), pathEdgeKeys: new Set(), active: false };

  // Group nodes by tier
  const tierGroups = {};
  nodes.forEach(n => {
    if (!tierGroups[n.tier]) tierGroups[n.tier] = [];
    tierGroups[n.tier].push(n);
  });

  // Render tier bands — supports up to 100 tiers, only renders used ones
  const sortedTiers = Object.keys(tierGroups).map(Number).sort((a,b)=>a-b);
  const nodeEls = {};

  sortedTiers.forEach(tier => {
    const config = tierLabels[tier] || {label:`TIER ${tier}`, color:'#808495', bg:'rgba(128,132,149,0.06)'};
    const band = document.createElement('div');
    band.className = 'tier-band';
    band.style.background = config.bg;
    band.style.borderLeft = `3px solid ${config.color}`;

    const label = document.createElement('div');
    label.className = 'tier-band-label';
    label.style.color = config.color;
    label.textContent = config.label;
    band.appendChild(label);

    const nodesDiv = document.createElement('div');
    nodesDiv.className = 'tier-nodes';

    tierGroups[tier].forEach(node => {
      const el = document.createElement('div');
      el.dataset.nodeId = node.id;

      // ── Dependency graph: session nodes ──
      if (node.type === 'session') {
        el.className = 'tier-node';
        if (node.hasConflict) { el.style.borderColor = '#EF4444'; el.style.borderTopColor = '#EF4444'; }
        else if (node.subtype === 'root') el.style.borderTopColor = '#3B82F6';
        else el.style.borderTopColor = '#6366F1';
        el.style.borderTopWidth = '3px';
        // Sequence number badge
        if (node.seq) {
          const seqEl = document.createElement('div');
          seqEl.className = 'node-seq';
          seqEl.textContent = node.seq;
          if (node.hasConflict) seqEl.style.background = '#EF4444';
          el.appendChild(seqEl);
        }
        // Name
        const nameEl = document.createElement('div');
        nameEl.className = 'node-name';
        const shortName = node.name.replace(/^s_m_(?:Load_|LOAD_)?/i, '');
        nameEl.textContent = shortName.length > 22 ? shortName.substring(0, 19) + '...' : shortName;
        nameEl.title = node.name;
        el.appendChild(nameEl);
        // Colored stat badges
        const statsDiv = document.createElement('div');
        statsDiv.className = 'node-stats';
        statsDiv.innerHTML = `<span class="ns ns-tx">${node.srcCount} tx</span><span class="ns ns-ext">${node.tgtCount} ext</span>` + (node.lkpCount ? `<span class="ns ns-lkp">${node.lkpCount} lkp</span>` : '');
        el.appendChild(statsDiv);
        // Conflict badge
        if (node.hasConflict) {
          const badge = document.createElement('div');
          badge.className = 'node-badge red';
          badge.textContent = '!';
          badge.title = node.conflictDetails.map(c => c.table_name + ': ' + c.conflict_type).join(', ');
          el.appendChild(badge);
        }
      }
      // ── Table output nodes ──
      else if (node.type === 'table_output') {
        el.className = 'tier-node table-output';
        if (node.isConflict) { el.style.borderColor = '#EF4444'; }
        else if (node.isChain) { el.style.borderColor = '#F59E0B'; }
        else el.style.borderColor = '#21C354';
        // Icon
        const icon = document.createElement('div');
        icon.style.cssText = 'font-size:0.8rem;margin-bottom:2px';
        icon.textContent = node.isConflict ? '\u26A0' : node.isChain ? '\u2161' : '\u2713';
        el.appendChild(icon);
        const nameEl = document.createElement('div');
        nameEl.className = 'node-name';
        nameEl.textContent = node.name.length > 20 ? node.name.substring(0, 17) + '...' : node.name;
        nameEl.title = node.name;
        el.appendChild(nameEl);
        const cls = document.createElement('div');
        cls.className = 'node-class';
        cls.style.color = node.isConflict ? '#FCA5A5' : node.isChain ? '#FDE68A' : '#86EFAC';
        cls.textContent = node.isConflict ? 'CONFLICT' : node.isChain ? 'CHAIN' : 'INDEPENDENT';
        el.appendChild(cls);
      }
      // ── Conflict gate nodes ──
      else if (node.type === 'conflict_gate') {
        el.className = 'tier-node conflict-gate';
        const icon = document.createElement('div');
        icon.style.cssText = 'font-size:1.2rem;margin-bottom:2px';
        icon.textContent = '\u26A0';
        el.appendChild(icon);
        const nameEl = document.createElement('div');
        nameEl.className = 'node-name';
        nameEl.textContent = node.name.length > 25 ? node.name.substring(0, 22) + '...' : node.name;
        nameEl.title = node.name;
        el.appendChild(nameEl);
        const metaEl = document.createElement('div');
        metaEl.className = 'node-meta';
        metaEl.textContent = `${node.writerCount}W / ${node.readerCount}R / ${node.lookupCount}L`;
        el.appendChild(metaEl);
        const clsEl = document.createElement('div');
        clsEl.className = 'node-class';
        clsEl.style.color = '#FCA5A5';
        clsEl.textContent = 'CONFLICT';
        el.appendChild(clsEl);
      }
      // ── Process group nodes (NiFi) ──
      else if (node.type === 'process_group') {
        el.className = 'tier-node expandable';
        if (node.inCycle) el.classList.add('in-cycle');
        const roleColor = ROLE_TIER_COLORS[node.dominantRole] || '#6366F1';
        el.style.borderTopColor = roleColor;
        el.style.borderTopWidth = '3px';
        el.style.minWidth = '160px';
        el.style.maxWidth = '240px';
        // Cycle badge
        if (node.inCycle) {
          const cyBadge = document.createElement('div');
          cyBadge.className = 'cycle-badge';
          cyBadge.textContent = '\u21BB';
          cyBadge.title = 'Cycle: ' + node.sccMembers.filter(g => g !== node.name).join(', ');
          el.appendChild(cyBadge);
        }
        // Name
        const nameEl = document.createElement('div');
        nameEl.className = 'node-name';
        nameEl.textContent = node.name.length > 28 ? node.name.substring(0, 25) + '...' : node.name;
        nameEl.title = node.name;
        el.appendChild(nameEl);
        // Processor count badge
        const badge = document.createElement('div');
        badge.className = 'node-badge';
        badge.textContent = node.procCount;
        badge.title = node.procCount + ' processors';
        el.appendChild(badge);
        // Colored stat badges
        const statsDiv = document.createElement('div');
        statsDiv.className = 'node-stats';
        if (node.srcCount) statsDiv.innerHTML += `<span class="ns ns-tx">${node.srcCount} src</span>`;
        if (node.transformCount + node.routeCount) statsDiv.innerHTML += `<span class="ns" style="background:#A855F7;color:white">${node.transformCount + node.routeCount} xfm</span>`;
        if (node.processCount) statsDiv.innerHTML += `<span class="ns ns-ext">${node.processCount} proc</span>`;
        if (node.sinkCount) statsDiv.innerHTML += `<span class="ns" style="background:#21C354;color:white">${node.sinkCount} sink</span>`;
        if (node.utilityCount) statsDiv.innerHTML += `<span class="ns" style="background:#808495;color:white">${node.utilityCount} util</span>`;
        el.appendChild(statsDiv);
        // Expand indicator
        const expandInd = document.createElement('div');
        expandInd.className = 'expand-indicator';
        expandInd.textContent = '\u25B6 expand';
        el.appendChild(expandInd);
      }
      // ── Generic nodes (NiFi processors, SQL, flat) ──
      else {
        el.className = 'tier-node';
        if (node.state === 'DISABLED' || node.state === 'STOPPED') el.style.opacity = '0.5';
        if (node.subtype === 'source') el.style.borderTopColor = '#3B82F6';
        else if (node.subtype === 'sink') el.style.borderTopColor = '#21C354';
        else if (node.subtype === 'route') el.style.borderTopColor = '#EAB308';
        else if (node.subtype === 'transform') el.style.borderTopColor = '#A855F7';
        else if (node.type === 'table') el.style.borderTopColor = '#3B82F6';
        el.style.borderTopWidth = '3px';
        const nameEl = document.createElement('div');
        nameEl.className = 'node-name';
        nameEl.textContent = node.name.length > 25 ? node.name.substring(0, 22) + '...' : node.name;
        nameEl.title = node.name;
        el.appendChild(nameEl);
        if (node.meta) {
          const metaEl = document.createElement('div');
          metaEl.className = 'node-meta';
          metaEl.textContent = node.meta;
          el.appendChild(metaEl);
        }
        if (node.rows) {
          const badge = document.createElement('div');
          badge.className = 'node-badge';
          badge.textContent = node.rows >= 1000 ? Math.round(node.rows / 1000) + 'K' : node.rows;
          el.appendChild(badge);
        }
      }

      // Hover: highlight connected (suppressed during multi-select)
      el.addEventListener('mouseenter', () => { if (!_ms.active) highlightConnected(node.id, nodes, connections, nodeEls, container); });
      el.addEventListener('mouseleave', () => { if (!_ms.active) clearHighlight(nodeEls, container); });
      // Click: route tracing + expand + detail
      el.addEventListener('click', (e) => {
        e.stopPropagation();
        if (_ms.active && !_ms.selected.includes(node.id)) {
          // Route tracing: add this node to the route
          addToRouteTrace(node.id, _ms, connections, nodeEls, container);
          showNodeDetail(node, detailEl, diagramType);
        } else if (_ms.active && _ms.selected.includes(node.id)) {
          // Clicking an already-selected node: expand it (if process group)
          if (node.type === 'process_group' && node.expandable) {
            toggleGroupExpand(node, el, band, tierData, nodeEls, container, detailEl, diagramType);
          }
          showNodeDetail(node, detailEl, diagramType);
        } else {
          // First click: start route trace + expand if process group
          startRouteTrace(node.id, _ms, connections, nodeEls, container);
          if (node.type === 'process_group' && node.expandable) {
            toggleGroupExpand(node, el, band, tierData, nodeEls, container, detailEl, diagramType);
          }
          showNodeDetail(node, detailEl, diagramType);
        }
      });

      nodesDiv.appendChild(el);
      nodeEls[node.id] = el;
    });

    band.appendChild(nodesDiv);
    container.appendChild(band);
  });

  // Render SVG connections after DOM is laid out
  requestAnimationFrame(() => {
    renderConnections(container, connections, nodeEls);
  });

  // Escape clears route trace; click empty space clears
  document.addEventListener('keydown', (e) => {
    if (e.key === 'Escape' && _ms.active) clearRouteTrace(_ms, nodeEls, container);
  });
  container.addEventListener('click', (e) => {
    if ((e.target === container || e.target.classList.contains('tier-band') || e.target.classList.contains('tier-band-label')) && _ms.active) {
      clearRouteTrace(_ms, nodeEls, container);
    }
  });

  // Connection density sidebar — now an active filter
  const sidebarEl = document.getElementById('tierDensitySidebar');
  const barsEl = document.getElementById('densityBars');
  const _sidebarFilter = { activeTypes: new Set() };
  if (sidebarEl && barsEl && densityData && densityData.length) {
    sidebarEl.classList.remove('hidden');
    const sidebarTitle = sidebarEl.querySelector('h4');
    if (sidebarTitle) sidebarTitle.textContent = diagramType === 'nifi_flow' ? 'Filter by Type' : 'Connection Density';
    barsEl.innerHTML = '';
    // Add hint for NiFi
    if (diagramType === 'nifi_flow') {
      const hint = document.createElement('div');
      hint.className = 'sidebar-filter-hint';
      hint.textContent = 'Click to filter diagram';
      barsEl.appendChild(hint);
    }
    const maxTotal = Math.max(...densityData.map(d => d.total));
    // Pre-build type→group mapping for NiFi filter
    const typeToGroups = {};
    if (diagramType === 'nifi_flow') {
      nodes.forEach(n => {
        if (n.type === 'process_group' && n.detail && n.detail.typeCount) {
          Object.keys(n.detail.typeCount).forEach(t => {
            if (!typeToGroups[t]) typeToGroups[t] = new Set();
            typeToGroups[t].add(n.id);
          });
        }
      });
    }
    densityData.forEach(d => {
      const row = document.createElement('div');
      row.className = 'density-row';
      row.dataset.typeName = d.name;
      if (d.role) {
        const roleColors = { source:'#3B82F6', sink:'#21C354', route:'#EAB308', transform:'#A855F7', process:'#6366F1', utility:'#808495' };
        const barW = Math.max(4, (d.total / maxTotal) * 80);
        row.innerHTML = `<span class="density-bar" style="width:${barW}px;background:${roleColors[d.role]||'#808495'}" title="${d.total}x"></span><span class="density-label" title="${d.name}">${d.name} (${d.total})</span>`;
      } else {
        const wPct = Math.max(2, (d.writers / maxTotal) * 60);
        const rPct = Math.max(0, (d.readers / maxTotal) * 60);
        const lPct = Math.max(0, (d.lookups / maxTotal) * 60);
        let barsHTML = `<span class="density-bar" style="width:${wPct}px;background:#EF4444" title="${d.writers} writer(s)"></span>`;
        if (d.readers) barsHTML += `<span class="density-bar" style="width:${rPct}px;background:#3B82F6" title="${d.readers} reader(s)"></span>`;
        if (d.lookups) barsHTML += `<span class="density-bar" style="width:${lPct}px;background:#F59E0B" title="${d.lookups} lookup(s)"></span>`;
        row.innerHTML = barsHTML + `<span class="density-label" title="${d.name}">${d.name}</span>`;
      }
      // Click handler for filter
      if (diagramType === 'nifi_flow') {
        row.addEventListener('click', () => {
          if (_ms.active) clearRouteTrace(_ms, nodeEls, container);
          const typeName = d.name;
          if (_sidebarFilter.activeTypes.has(typeName)) {
            _sidebarFilter.activeTypes.delete(typeName);
            row.classList.remove('filter-active');
          } else {
            _sidebarFilter.activeTypes.add(typeName);
            row.classList.add('filter-active');
          }
          applySidebarFilter(_sidebarFilter, typeToGroups, nodes, connections, nodeEls, container, barsEl);
        });
      }
      barsEl.appendChild(row);
    });
    // Clear filter button
    if (diagramType === 'nifi_flow') {
      const clearBtn = document.createElement('div');
      clearBtn.className = 'sidebar-clear-btn';
      clearBtn.id = 'sidebarClearBtn';
      clearBtn.textContent = '\u2715 Clear filter';
      clearBtn.addEventListener('click', () => {
        _sidebarFilter.activeTypes.clear();
        barsEl.querySelectorAll('.density-row').forEach(r => r.classList.remove('filter-active','filter-dimmed'));
        clearSidebarFilter(nodeEls, container);
        clearBtn.style.display = 'none';
      });
      barsEl.appendChild(clearBtn);
    }
  } else if (sidebarEl) {
    sidebarEl.classList.add('hidden');
  }

  // Legend
  if (legendEl) {
    legendEl.innerHTML = '';
    const sessionCount = nodes.filter(n => n.type === 'session').length;
    const tableCount = nodes.filter(n => n.type === 'table_output' || n.type === 'conflict_gate').length;
    if (diagramType === 'dependency_graph') {
      legendEl.innerHTML = [
        `<span>${sessionCount} Sessions</span>`,
        `<span>${tableCount} Tables</span>`,
        `<span style="color:#EF4444">${nodes.filter(n => n.hasConflict || n.type === 'conflict_gate').length} Conflicts</span>`,
        '<span><span class="leg-line" style="background:#6366F1"></span> Dependency</span>',
        '<span><span class="leg-line" style="background:#F59E0B;border-top:2px dashed #F59E0B"></span> Lookup</span>',
        '<span><span class="leg-line" style="background:#EF4444"></span> Conflict</span>',
        '<span><span class="leg-line" style="background:#21C354"></span> Independent</span>',
        '<span><span class="leg-line" style="background:#F59E0B"></span> Chain</span>',
      ].join('');
    } else if (diagramType === 'nifi_flow') {
      const pgCount = nodes.filter(n => n.type === 'process_group').length;
      const procCount = nodes.filter(n => n.type === 'processor').length;
      const cycleCount = tierData.cycleData ? tierData.cycleData.length : 0;
      legendEl.innerHTML = [
        `<span>${pgCount} Process Groups</span>`,
        procCount ? `<span>${procCount} Processors</span>` : '',
        `<span>${connections.length} Connections</span>`,
        cycleCount ? `<span style="color:#EF4444">${cycleCount} Cycle(s)</span>` : '',
        '<span><span class="leg-line" style="background:#3B82F6"></span> Source</span>',
        '<span><span class="leg-line" style="background:#EAB308"></span> Route</span>',
        '<span><span class="leg-line" style="background:#A855F7"></span> Transform</span>',
        '<span><span class="leg-line" style="background:#6366F1"></span> Process</span>',
        '<span><span class="leg-line" style="background:#21C354"></span> Sink</span>',
        '<span><span class="leg-line" style="background:#EF4444;border-top:2px dashed #EF4444"></span> Cycle Edge</span>',
        '<span style="color:var(--text2);font-size:0.7rem">Click nodes to trace route · Esc to clear</span>',
      ].join('');
    } else if (diagramType === 'sql_tables') {
      legendEl.innerHTML = [
        '<span><span class="leg-line" style="background:#3B82F6;border-top:2px solid #3B82F6"></span> Foreign Key</span>',
        `<span>${nodes.length} tables · ${connections.length} relationships</span>`,
      ].join('');
    } else {
      legendEl.innerHTML = [
        `<span>${nodes.length} objects</span>`,
        connections.length ? `<span><span class="leg-line" style="background:#4B5563;border-top:2px dashed #4B5563"></span> Shared columns</span>` : '',
      ].join('');
    }
  }

  document.getElementById('tierDiagramContainer').classList.remove('hidden');
}

function renderConnections(container, connections, nodeEls) {
  // Remove old SVG
  const oldSvg = container.querySelector('svg.tier-svg');
  if (oldSvg) oldSvg.remove();

  if (!connections.length) return;

  const svg = document.createElementNS('http://www.w3.org/2000/svg','svg');
  svg.classList.add('tier-svg');
  svg.style.position = 'absolute';
  svg.style.top = '0';
  svg.style.left = '0';
  svg.style.width = container.scrollWidth + 'px';
  svg.style.height = container.scrollHeight + 'px';
  svg.style.pointerEvents = 'none';
  svg.style.zIndex = '1';
  svg.setAttribute('viewBox', `0 0 ${container.scrollWidth} ${container.scrollHeight}`);

  // Defs: arrow markers (default + highlighted variants) and glow filter
  const defs = document.createElementNS('http://www.w3.org/2000/svg','defs');
  // Glow filter for highlighted paths
  const filter = document.createElementNS('http://www.w3.org/2000/svg','filter');
  filter.setAttribute('id','glow');
  filter.setAttribute('x','-50%'); filter.setAttribute('y','-50%');
  filter.setAttribute('width','200%'); filter.setAttribute('height','200%');
  const blur = document.createElementNS('http://www.w3.org/2000/svg','feGaussianBlur');
  blur.setAttribute('stdDeviation','3'); blur.setAttribute('result','blur');
  filter.appendChild(blur);
  const merge = document.createElementNS('http://www.w3.org/2000/svg','feMerge');
  const mn1 = document.createElementNS('http://www.w3.org/2000/svg','feMergeNode');
  mn1.setAttribute('in','blur');
  const mn2 = document.createElementNS('http://www.w3.org/2000/svg','feMergeNode');
  mn2.setAttribute('in','SourceGraphic');
  merge.appendChild(mn1); merge.appendChild(mn2);
  filter.appendChild(merge);
  defs.appendChild(filter);
  // Arrow markers for each color
  const arrowColors = {'default':'#4B5563','blue':'#3B82F6','purple':'#6366F1','red':'#EF4444','amber':'#F59E0B','green':'#21C354','white':'#FAFAFA'};
  Object.entries(arrowColors).forEach(([name, color]) => {
    const marker = document.createElementNS('http://www.w3.org/2000/svg','marker');
    marker.setAttribute('id', 'arrow-' + name);
    marker.setAttribute('viewBox','0 0 10 8');
    marker.setAttribute('refX','10'); marker.setAttribute('refY','4');
    marker.setAttribute('markerWidth','8'); marker.setAttribute('markerHeight','6');
    marker.setAttribute('orient','auto');
    const ap = document.createElementNS('http://www.w3.org/2000/svg','path');
    ap.setAttribute('d','M0,0 L10,4 L0,8 Z'); ap.setAttribute('fill', color);
    marker.appendChild(ap); defs.appendChild(marker);
  });
  svg.appendChild(defs);

  const cRect = container.getBoundingClientRect();

  connections.forEach(conn => {
    const fromEl = nodeEls[conn.from];
    const toEl = nodeEls[conn.to];
    if (!fromEl || !toEl) return;

    const fromRect = fromEl.getBoundingClientRect();
    const toRect = toEl.getBoundingClientRect();

    const fromX = fromRect.left + fromRect.width/2 - cRect.left + container.scrollLeft;
    const fromY = fromRect.top + fromRect.height - cRect.top + container.scrollTop;
    const toX = toRect.left + toRect.width/2 - cRect.left + container.scrollLeft;
    const toY = toRect.top - cRect.top + container.scrollTop;

    const dy = toY - fromY;
    const cp = Math.max(Math.abs(dy) * 0.35, 30);
    const cpx = (toX - fromX) * 0.15;

    const path = document.createElementNS('http://www.w3.org/2000/svg','path');
    path.setAttribute('d', `M${fromX},${fromY} C${fromX+cpx},${fromY+cp} ${toX-cpx},${toY-cp} ${toX},${toY}`);
    const strokeColor = conn.color || '#4B5563';
    path.setAttribute('stroke', strokeColor);
    path.setAttribute('stroke-width', String(conn.width || 1.5));
    path.setAttribute('fill', 'none');
    // Pick arrow marker by closest color
    const arrowId = strokeColor.includes('EF44') ? 'arrow-red' : strokeColor.includes('F59E') || strokeColor.includes('F5') ? 'arrow-amber' : strokeColor.includes('6366') ? 'arrow-purple' : strokeColor.includes('3B82') ? 'arrow-blue' : strokeColor.includes('21C3') ? 'arrow-green' : 'arrow-default';
    path.setAttribute('marker-end', `url(#${arrowId})`);
    path.setAttribute('opacity', '0.35');
    path.dataset.from = conn.from;
    path.dataset.to = conn.to;
    path.dataset.origColor = strokeColor;
    path.dataset.origWidth = String(conn.width || 1.5);
    if (conn.dash) path.setAttribute('stroke-dasharray', '6,4');
    if (conn.inCycle) path.setAttribute('stroke-dasharray', '8,4');
    svg.appendChild(path);
  });

  container.style.position = 'relative';
  container.insertBefore(svg, container.firstChild);
}

function highlightConnected(nodeId, nodes, connections, nodeEls, container) {
  // ── Trace the FULL path in both directions (upstream + downstream) ──
  const pathNodes = new Set([nodeId]);
  const pathEdges = new Set();  // "from|to" keys of edges in the path

  // BFS downstream: follow all connections FROM this node recursively
  function traceDown(id) {
    connections.forEach((c, i) => {
      const key = c.from + '|' + c.to;
      if (c.from === id && !pathEdges.has(key)) {
        pathEdges.add(key);
        pathNodes.add(c.to);
        traceDown(c.to);
      }
    });
  }
  // BFS upstream: follow all connections TO this node recursively
  function traceUp(id) {
    connections.forEach((c, i) => {
      const key = c.from + '|' + c.to;
      if (c.to === id && !pathEdges.has(key)) {
        pathEdges.add(key);
        pathNodes.add(c.from);
        traceUp(c.from);
      }
    });
  }
  traceDown(nodeId);
  traceUp(nodeId);

  // Dim all nodes, highlight path nodes
  Object.entries(nodeEls).forEach(([id, el]) => {
    if (pathNodes.has(id)) {
      el.classList.add('highlighted'); el.classList.remove('dimmed');
      if (id === nodeId) el.classList.add('selected');
    } else {
      el.classList.add('dimmed'); el.classList.remove('highlighted', 'selected');
    }
  });

  // Highlight SVG paths — glow effect on path edges, dim everything else
  const svg = container.querySelector('svg.tier-svg');
  if (svg) {
    svg.querySelectorAll('path[data-from]').forEach(p => {
      const edgeKey = p.dataset.from + '|' + p.dataset.to;
      if (pathEdges.has(edgeKey)) {
        // Full path highlight: bright, thick, glowing
        p.setAttribute('opacity', '1');
        p.setAttribute('stroke', '#FAFAFA');
        p.setAttribute('stroke-width', '3');
        p.setAttribute('filter', 'url(#glow)');
        p.setAttribute('marker-end', 'url(#arrow-white)');
        p.style.transition = 'all 0.2s ease';
      } else {
        p.setAttribute('opacity', '0.08');
        p.removeAttribute('filter');
      }
    });
  }
}

function clearHighlight(nodeEls, container) {
  Object.values(nodeEls).forEach(el => { el.classList.remove('highlighted', 'dimmed', 'selected'); });
  const svg = container.querySelector('svg.tier-svg');
  if (svg) {
    svg.querySelectorAll('path[data-from]').forEach(p => {
      p.setAttribute('opacity', '0.35');
      p.setAttribute('stroke', p.dataset.origColor || '#4B5563');
      p.setAttribute('stroke-width', p.dataset.origWidth || '1.5');
      p.removeAttribute('filter');
      // Restore original arrow marker
      const c = p.dataset.origColor || '';
      const arrowId = c.includes('EF44') ? 'arrow-red' : c.includes('F59E') || c.includes('F5') ? 'arrow-amber' : c.includes('6366') ? 'arrow-purple' : c.includes('3B82') ? 'arrow-blue' : c.includes('21C3') ? 'arrow-green' : 'arrow-default';
      p.setAttribute('marker-end', `url(#${arrowId})`);
      p.style.transition = '';
    });
  }
}

// ── Expand/collapse a process group ──
function toggleGroupExpand(node, el, parentBand, tierData, nodeEls, container, detailEl, diagramType) {
  const subBandId = 'sub_' + node.id;
  const existing = container.querySelector(`[data-sub-band="${subBandId}"]`);
  if (existing) {
    existing.remove();
    el.classList.remove('expanded');
    const ind = el.querySelector('.expand-indicator');
    if (ind) ind.textContent = '\u25B6 expand';
    Object.keys(nodeEls).forEach(k => { if (k.startsWith('proc_' + node.name + '|')) delete nodeEls[k]; });
    requestAnimationFrame(() => renderConnections(container, tierData.connections, nodeEls));
    return;
  }
  el.classList.add('expanded');
  const ind = el.querySelector('.expand-indicator');
  if (ind) ind.textContent = '\u25BC collapse';
  const processors = (node.detail && node.detail.processors) || [];
  const ROLE_ORDER = ['source','route','transform','process','sink','utility'];
  const ROLE_NAMES = {source:'Sources',route:'Routing',transform:'Transforms',process:'Processing',sink:'Sinks',utility:'Utility'};
  const subBand = document.createElement('div');
  subBand.className = 'tier-sub-band';
  subBand.dataset.subBand = subBandId;
  ROLE_ORDER.forEach(role => {
    const procs = processors.filter(p => classifyNiFiProcessor(p.type) === role);
    if (!procs.length) return;
    const roleLabel = document.createElement('div');
    roleLabel.className = 'tier-band-label';
    roleLabel.style.color = ROLE_TIER_COLORS[role] || '#808495';
    roleLabel.textContent = `${node.name} \u2192 ${ROLE_NAMES[role]} (${procs.length})`;
    subBand.appendChild(roleLabel);
    const nodesDiv = document.createElement('div');
    nodesDiv.className = 'tier-nodes';
    procs.forEach(p => {
      const procEl = document.createElement('div');
      procEl.className = 'tier-node';
      const procId = 'proc_' + node.name + '|' + p.name;
      procEl.dataset.nodeId = procId;
      if (p.state === 'DISABLED' || p.state === 'STOPPED') procEl.style.opacity = '0.5';
      procEl.style.borderTopColor = ROLE_TIER_COLORS[role] || '#808495';
      procEl.style.borderTopWidth = '3px';
      const nameEl = document.createElement('div');
      nameEl.className = 'node-name';
      nameEl.textContent = p.name.length > 20 ? p.name.substring(0, 17) + '...' : p.name;
      nameEl.title = p.name;
      procEl.appendChild(nameEl);
      const metaEl = document.createElement('div');
      metaEl.className = 'node-meta';
      metaEl.textContent = p.type;
      procEl.appendChild(metaEl);
      procEl.addEventListener('click', (e) => {
        e.stopPropagation();
        showNodeDetail({name:p.name, type:'processor', subtype:role, meta:p.type, group:node.name, state:p.state, propCount:Object.keys(p.properties||{}).length, detail:p}, detailEl, diagramType);
      });
      nodesDiv.appendChild(procEl);
      nodeEls[procId] = procEl;
    });
    subBand.appendChild(nodesDiv);
  });
  parentBand.after(subBand);
  requestAnimationFrame(() => renderConnections(container, tierData.connections, nodeEls));
}

// ── Progressive route tracing ──
// BFS all reachable nodes (both directions) from a starting node
function bfsReachable(nodeId, connections) {
  const reachNodes = new Set([nodeId]);
  const reachEdges = new Set();
  const queue = [nodeId];
  // Downstream
  const visited = new Set([nodeId]);
  while (queue.length) {
    const cur = queue.shift();
    connections.forEach(c => {
      if (c.from === cur && !visited.has(c.to)) {
        visited.add(c.to); reachNodes.add(c.to); reachEdges.add(c.from + '|' + c.to); queue.push(c.to);
      }
    });
  }
  // Upstream
  const queue2 = [nodeId];
  const visited2 = new Set([nodeId]);
  while (queue2.length) {
    const cur = queue2.shift();
    connections.forEach(c => {
      if (c.to === cur && !visited2.has(c.from)) {
        visited2.add(c.from); reachNodes.add(c.from); reachEdges.add(c.from + '|' + c.to); queue2.push(c.from);
      }
    });
  }
  return { reachNodes, reachEdges };
}

function startRouteTrace(nodeId, ms, connections, nodeEls, container) {
  ms.selected = [nodeId];
  ms.active = true;
  // First click: show all reachable from this node, dim everything else
  const { reachNodes, reachEdges } = bfsReachable(nodeId, connections);
  ms.pathNodes = reachNodes;
  ms.pathEdgeKeys = reachEdges;
  applyRouteVisuals(ms, nodeEls, container);
  showPathToast(ms);
}

function addToRouteTrace(nodeId, ms, connections, nodeEls, container) {
  if (ms.selected.includes(nodeId)) return;
  ms.selected.push(nodeId);
  if (ms.selected.length === 2) {
    // Two nodes: find the specific path between them
    const a = ms.selected[0], b = ms.selected[1];
    let result = bfsShortestPath(connections, a, b);
    if (!result.found) result = bfsShortestPath(connections, b, a);
    if (!result.found) {
      const bi = connections.flatMap(c => [c, {from:c.to,to:c.from,label:c.label,type:c.type,color:c.color,width:c.width}]);
      result = bfsShortestPath(bi, a, b);
    }
    if (result.found) {
      ms.pathNodes = new Set(result.pathNodes);
      ms.pathEdgeKeys = new Set(result.pathEdgeKeys);
    } else {
      // No path — keep both selected, show nothing between
      ms.pathNodes = new Set(ms.selected);
      ms.pathEdgeKeys = new Set();
      flashNoPath();
    }
  } else {
    // 3+ nodes: extend from last-but-one to new node via existing path
    const prev = ms.selected[ms.selected.length - 2];
    let result = bfsShortestPath(connections, prev, nodeId);
    if (!result.found) result = bfsShortestPath(connections, nodeId, prev);
    if (!result.found) {
      const bi = connections.flatMap(c => [c, {from:c.to,to:c.from,label:c.label,type:c.type,color:c.color,width:c.width}]);
      result = bfsShortestPath(bi, prev, nodeId);
    }
    if (result.found) {
      result.pathNodes.forEach(n => ms.pathNodes.add(n));
      result.pathEdgeKeys.forEach(k => ms.pathEdgeKeys.add(k));
    } else {
      ms.pathNodes.add(nodeId);
      flashNoPath();
    }
  }
  applyRouteVisuals(ms, nodeEls, container);
  showPathToast(ms);
}

function applyRouteVisuals(ms, nodeEls, container) {
  Object.entries(nodeEls).forEach(([id, el]) => {
    el.classList.remove('path-selected','path-member','path-dimmed','highlighted','dimmed','selected');
    if (ms.selected.includes(id)) el.classList.add('path-selected');
    else if (ms.pathNodes.has(id)) el.classList.add('path-member');
    else el.classList.add('path-dimmed');
  });
  const svg = container.querySelector('svg.tier-svg');
  if (svg) {
    svg.querySelectorAll('path[data-from]').forEach(p => {
      const fwd = p.dataset.from + '|' + p.dataset.to;
      const rev = p.dataset.to + '|' + p.dataset.from;
      if (ms.pathEdgeKeys.has(fwd) || ms.pathEdgeKeys.has(rev)) {
        p.setAttribute('opacity','1');
        p.setAttribute('stroke','#FACA15');
        p.setAttribute('stroke-width','3');
        p.setAttribute('filter','url(#glow)');
        p.setAttribute('marker-end','url(#arrow-white)');
        p.style.transition = 'all 0.2s ease';
      } else {
        p.setAttribute('opacity','0.04');
        p.removeAttribute('filter');
        p.style.transition = 'all 0.2s ease';
      }
    });
  }
}

function clearRouteTrace(ms, nodeEls, container) {
  ms.selected = [];
  ms.pathNodes = new Set();
  ms.pathEdgeKeys = new Set();
  ms.active = false;
  Object.values(nodeEls).forEach(el => { el.classList.remove('path-selected','path-member','path-dimmed'); });
  const svg = container.querySelector('svg.tier-svg');
  if (svg) {
    svg.querySelectorAll('path[data-from]').forEach(p => {
      p.setAttribute('opacity','0.35');
      p.setAttribute('stroke', p.dataset.origColor || '#4B5563');
      p.setAttribute('stroke-width', p.dataset.origWidth || '1.5');
      p.removeAttribute('filter');
      const c = p.dataset.origColor || '';
      const arrowId = c.includes('EF44') ? 'arrow-red' : c.includes('F59E')||c.includes('F5') ? 'arrow-amber' : c.includes('6366') ? 'arrow-purple' : c.includes('3B82') ? 'arrow-blue' : c.includes('21C3') ? 'arrow-green' : 'arrow-default';
      p.setAttribute('marker-end', `url(#${arrowId})`);
      p.style.transition = '';
    });
  }
  hidePathToast();
}

function showPathToast(ms) {
  let toast = document.getElementById('pathTraceToast');
  if (!toast) {
    toast = document.createElement('div');
    toast.id = 'pathTraceToast';
    toast.className = 'path-trace-toast';
    document.body.appendChild(toast);
  }
  const count = ms.selected.length;
  const pathLen = ms.pathNodes.size;
  let msg = count === 1 ? '1 node selected — click another to trace route'
    : `${count} nodes selected — ${pathLen} in path`;
  toast.innerHTML = `<span>${msg}</span>` +
    `<span class="toast-hint">Click nodes to build route</span>` +
    `<span class="toast-clear" id="pathTraceToastClear">\u2715 Clear</span>`;
  toast.style.display = 'flex';
  document.getElementById('pathTraceToastClear').onclick = () => { toast.style.display = 'none'; };
}

function hidePathToast() {
  const toast = document.getElementById('pathTraceToast');
  if (toast) toast.style.display = 'none';
}

function flashNoPath() {
  const toast = document.getElementById('pathTraceToast');
  if (toast) {
    const noPath = document.createElement('span');
    noPath.style.cssText = 'color:var(--red);margin-left:8px';
    noPath.textContent = 'No direct path';
    toast.appendChild(noPath);
    setTimeout(() => { if (noPath.parentNode) noPath.remove(); }, 2500);
  }
}

// ── Sidebar filter ──
function applySidebarFilter(sf, typeToGroups, nodes, connections, nodeEls, container, barsEl) {
  const clearBtn = document.getElementById('sidebarClearBtn');
  if (!sf.activeTypes.size) {
    clearSidebarFilter(nodeEls, container);
    barsEl.querySelectorAll('.density-row').forEach(r => r.classList.remove('filter-dimmed'));
    if (clearBtn) clearBtn.style.display = 'none';
    return;
  }
  if (clearBtn) clearBtn.style.display = 'block';
  // Find all groups that contain ANY of the selected types
  const matchingGroups = new Set();
  sf.activeTypes.forEach(t => {
    if (typeToGroups[t]) typeToGroups[t].forEach(g => matchingGroups.add(g));
  });
  // Find connections between matching groups
  const matchingEdges = new Set();
  connections.forEach(c => {
    if (matchingGroups.has(c.from) && matchingGroups.has(c.to)) {
      matchingEdges.add(c.from + '|' + c.to);
    }
  });
  // Apply visuals to nodes
  Object.entries(nodeEls).forEach(([id, el]) => {
    el.classList.remove('path-selected','path-member','path-dimmed','highlighted','dimmed','selected');
    if (matchingGroups.has(id)) {
      el.classList.add('path-member');
    } else {
      el.classList.add('path-dimmed');
    }
  });
  // Apply visuals to SVG edges
  const svg = container.querySelector('svg.tier-svg');
  if (svg) {
    svg.querySelectorAll('path[data-from]').forEach(p => {
      const fwd = p.dataset.from + '|' + p.dataset.to;
      if (matchingEdges.has(fwd)) {
        p.setAttribute('opacity','0.8');
        p.setAttribute('stroke', p.dataset.origColor || '#4B5563');
        p.setAttribute('stroke-width', p.dataset.origWidth || '1.5');
      } else {
        p.setAttribute('opacity','0.04');
      }
    });
  }
  // Dim non-active sidebar rows
  barsEl.querySelectorAll('.density-row').forEach(r => {
    if (sf.activeTypes.has(r.dataset.typeName)) r.classList.remove('filter-dimmed');
    else r.classList.add('filter-dimmed');
  });
}

function clearSidebarFilter(nodeEls, container) {
  Object.values(nodeEls).forEach(el => { el.classList.remove('path-selected','path-member','path-dimmed'); });
  const svg = container.querySelector('svg.tier-svg');
  if (svg) {
    svg.querySelectorAll('path[data-from]').forEach(p => {
      p.setAttribute('opacity','0.35');
      p.setAttribute('stroke', p.dataset.origColor || '#4B5563');
      p.setAttribute('stroke-width', p.dataset.origWidth || '1.5');
      p.removeAttribute('filter');
      const c = p.dataset.origColor || '';
      const arrowId = c.includes('EF44') ? 'arrow-red' : c.includes('F59E')||c.includes('F5') ? 'arrow-amber' : c.includes('6366') ? 'arrow-purple' : c.includes('3B82') ? 'arrow-blue' : c.includes('21C3') ? 'arrow-green' : 'arrow-default';
      p.setAttribute('marker-end', `url(#${arrowId})`);
      p.style.transition = '';
    });
  }
}

function showNodeDetail(node, detailEl, diagramType) {
  if (!detailEl) return;
  let h = '<div class="node-detail">';
  h += `<h4>${node.name}</h4>`;
  if (diagramType === 'nifi_flow' && node.type === 'process_group' && node.detail) {
    const d = node.detail;
    h += `<p><strong>Processors:</strong> ${node.procCount} · <strong>Internal Connections:</strong> ${d.intraConns || 0}</p>`;
    // Role breakdown
    h += '<div style="display:flex;gap:6px;flex-wrap:wrap;margin:8px 0">';
    if (node.srcCount) h += `<span class="ns ns-tx">${node.srcCount} sources</span>`;
    if (node.routeCount) h += `<span class="ns" style="background:#EAB308;color:#000">${node.routeCount} routes</span>`;
    if (node.transformCount) h += `<span class="ns" style="background:#A855F7;color:white">${node.transformCount} transforms</span>`;
    if (node.processCount) h += `<span class="ns ns-ext">${node.processCount} processors</span>`;
    if (node.sinkCount) h += `<span class="ns" style="background:#21C354;color:white">${node.sinkCount} sinks</span>`;
    if (node.utilityCount) h += `<span class="ns" style="background:#808495;color:white">${node.utilityCount} utility</span>`;
    h += '</div>';
    // Processor type breakdown
    if (d.typeCount) {
      const types = Object.entries(d.typeCount).sort((a, b) => b[1] - a[1]);
      h += '<table style="font-size:0.75rem"><thead><tr><th>Processor Type</th><th>Count</th></tr></thead><tbody>';
      types.slice(0, 15).forEach(([t, c]) => { h += `<tr><td>${t}</td><td>${c}</td></tr>`; });
      if (types.length > 15) h += `<tr><td colspan="2" style="color:var(--text2)">+${types.length - 15} more types</td></tr>`;
      h += '</tbody></table>';
    }
    // First few processor names
    if (d.processors && d.processors.length) {
      h += `<p style="margin-top:8px"><strong>Processors (first 10):</strong></p>`;
      h += '<ul style="font-size:0.75rem;margin:4px 0 4px 16px">';
      d.processors.slice(0, 10).forEach(p => { h += `<li>${p.name} <code style="font-size:0.65rem">${p.type}</code></li>`; });
      if (d.processors.length > 10) h += `<li style="color:var(--text2)">+${d.processors.length - 10} more</li>`;
      h += '</ul>';
    }
    // Cycle information
    if (node.inCycle && node.sccMembers) {
      h += '<div style="margin:8px 0;padding:8px 12px;border:1px solid #EF4444;border-radius:6px;background:rgba(239,68,68,0.08);font-size:0.8rem">';
      h += '<strong style="color:#EF4444">Circular Dependency Detected</strong><br>';
      h += 'Cycle with: ' + node.sccMembers.filter(g => g !== node.name).map(escapeHTML).join(', ');
      if (node.cycleEdges && node.cycleEdges.length) {
        h += '<br><br><strong>Cycle edges:</strong><br>';
        node.cycleEdges.forEach(ce => { h += `${escapeHTML(ce.from)} \u2192 ${escapeHTML(ce.to)} (${ce.count} flow${ce.count>1?'s':''})<br>`; });
      }
      h += '</div>';
    }
  } else if (diagramType === 'nifi_flow' && node.detail) {
    const p = node.detail;
    h += `<p><strong>Type:</strong> ${escapeHTML(p.type)} <code style="font-size:0.7rem">${escapeHTML(p.fullType||'')}</code></p>`;
    h += `<p><strong>Group:</strong> ${escapeHTML(p.group || '(root)')}</p>`;
    h += `<p><strong>State:</strong> ${escapeHTML(p.state || 'N/A')}</p>`;
    if (p.schedulingStrategy) h += `<p><strong>Scheduling:</strong> ${escapeHTML(p.schedulingStrategy)} / ${escapeHTML(p.schedulingPeriod)}</p>`;
    const propKeys = Object.keys(p.properties);
    const sensCount = propKeys.filter(k => isSensitiveProp(k)).length;
    if (propKeys.length) {
      h += `<p><strong>Properties (${propKeys.length}):</strong>${sensCount ? ` <span style="color:#EAB308;font-size:0.75rem">&#x26A0; ${sensCount} sensitive masked</span>` : ''}</p><pre style="max-height:200px;overflow:auto;font-size:0.75rem">`;
      propKeys.slice(0,20).forEach(k => { h += `${escapeHTML(k)}: ${escapeHTML(maskProperty(k, (p.properties[k]||'').substring(0,100)))}\n`; });
      if (propKeys.length > 20) h += `... +${propKeys.length-20} more\n`;
      h += '</pre>';
    }
  } else if (diagramType === 'dependency_graph' && node.type === 'session' && node.detail) {
    const s = node.detail;
    h += `<p><strong>Sources:</strong> ${s.sources} · <strong>Targets:</strong> ${s.targets} · <strong>Lookups:</strong> ${s.lookups}</p>`;
    if (node.seq) h += `<p><strong>Execution Order:</strong> #${node.seq}</p>`;
    if (s.source_tables && s.source_tables.length) {
      h += `<p style="margin-top:6px"><strong>Source Tables:</strong></p><ul style="font-size:0.8rem;margin:4px 0 4px 16px">`;
      s.source_tables.slice(0, 10).forEach(t => { h += `<li>${escapeHTML(t.name)}</li>`; });
      if (s.source_tables.length > 10) h += `<li style="color:var(--text2)">+${s.source_tables.length - 10} more</li>`;
      h += '</ul>';
    }
    if (s.target_tables && s.target_tables.length) {
      h += `<p><strong>Target Tables:</strong></p><ul style="font-size:0.8rem;margin:4px 0 4px 16px">`;
      s.target_tables.forEach(t => { h += `<li>${escapeHTML(t.name)}${t.load_type ? ' <code style="font-size:0.7rem">' + escapeHTML(t.load_type) + '</code>' : ''}</li>`; });
      h += '</ul>';
    }
    if (node.hasConflict && node.conflictDetails.length) {
      h += '<div class="alert alert-warn" style="margin:8px 0;padding:8px 12px;font-size:0.8rem"><strong>Conflicts:</strong><br>';
      node.conflictDetails.forEach(c => { h += `${escapeHTML(c.table_name)} — ${escapeHTML(c.conflict_type)}<br>`; });
      h += '</div>';
    }
  } else if (diagramType === 'dependency_graph' && (node.type === 'table_output' || node.type === 'conflict_gate') && node.detail) {
    const d = node.detail;
    if (d.writers.length) h += `<p><strong>Writers:</strong> ${d.writers.map(escapeHTML).join(', ')}</p>`;
    if (d.readers.length) h += `<p><strong>Readers:</strong> ${d.readers.map(escapeHTML).join(', ')}</p>`;
    if (d.lookups.length) h += `<p><strong>Lookup Readers:</strong> ${d.lookups.map(escapeHTML).join(', ')}</p>`;
    if (d.conflicts && d.conflicts.length) {
      h += '<div class="alert alert-warn" style="margin:8px 0;padding:8px 12px;font-size:0.8rem"><strong>Conflicts:</strong><br>';
      d.conflicts.forEach(c => { h += `${escapeHTML(c.conflict_type)}${c.writers ? ' — Writers: ' + c.writers.map(escapeHTML).join(', ') : ''}<br>`; });
      h += '</div>';
    }
  } else if (node.detail && node.detail.columns) {
    const t = node.detail;
    h += `<p><strong>Schema:</strong> ${escapeHTML(t.schema || 'dbo')} · <strong>Rows:</strong> ${t.row_count}</p>`;
    h += '<table style="font-size:0.75rem"><thead><tr><th>Column</th><th>Type</th><th>PK</th><th>Null</th></tr></thead><tbody>';
    t.columns.slice(0,15).forEach(c => {
      h += `<tr><td>${escapeHTML(c.name)}</td><td>${escapeHTML(c.data_type)}</td><td>${c.is_primary_key?'Y':''}</td><td>${c.nullable?'Y':'N'}</td></tr>`;
    });
    if (t.columns.length > 15) h += `<tr><td colspan="4" style="color:var(--text2)">+${t.columns.length-15} more columns</td></tr>`;
    h += '</tbody></table>';
    if (t.foreign_keys.length) {
      h += '<p style="margin-top:8px"><strong>Foreign Keys:</strong></p>';
      t.foreign_keys.forEach(fk => { h += `<p style="font-size:0.8rem"><code>${escapeHTML(fk.column||fk.fk_column)}</code> → <code>${escapeHTML(fk.references_table)}(${escapeHTML(fk.references_column)})</code></p>`; });
    }
  }
  h += '</div>';
  detailEl.innerHTML = h;
}

// ================================================================
// DATA GENERATOR (Box-Muller + seeded RNG)
// ================================================================
class SeededRNG {
  constructor(seed) { this.s = seed; }
  next() { this.s = (this.s * 16807 + 0) % 2147483647; return (this.s - 1) / 2147483646; }
  nextInt(min, max) { return Math.floor(this.next() * (max - min + 1)) + min; }
  normal(mean, std) {
    const u1 = this.next(), u2 = this.next();
    const z = Math.sqrt(-2*Math.log(u1||0.0001)) * Math.cos(2*Math.PI*u2);
    return mean + z * std;
  }
  choice(arr) { return arr[Math.floor(this.next()*arr.length)]; }
  shuffle(arr) { for (let i=arr.length-1;i>0;i--) { const j=Math.floor(this.next()*(i+1)); [arr[i],arr[j]]=[arr[j],arr[i]]; } return arr; }
  string(len) { const ch='abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'; return Array.from({length:len},()=>ch[Math.floor(this.next()*ch.length)]).join(''); }
}

function sampleColumn(rng, colSpec, rowCount) {
  const stats = colSpec.stats || {};
  const dt = (colSpec.data_type||'string').toLowerCase();
  const nr = stats.null_ratio || 0;
  const nn = Math.round(rowCount * (1-nr)), nc = rowCount - nn;
  let vals;
  if (['int','bigint','smallint','tinyint','integer','long'].includes(dt)) vals = sampleInt(rng, stats, nn);
  else if (['float','double','decimal','numeric'].includes(dt)) vals = sampleFloat(rng, stats, nn);
  else if (['string','varchar','char','text'].includes(dt)) vals = sampleStr(rng, stats, nn);
  else if (dt==='date') vals = sampleDate(rng, stats, nn);
  else if (['timestamp','datetime'].includes(dt)) vals = sampleTS(rng, stats, nn);
  else if (['boolean','bool'].includes(dt)) vals = sampleBool(rng, stats, nn);
  else vals = sampleStr(rng, stats, nn);
  const result = [...vals, ...Array(nc).fill(null)];
  return rng.shuffle(result);
}

function sampleInt(rng, s, n) {
  if (s.top_values && s.distinct_count <= 100) return sampleFreq(rng, s.top_values, n);
  const mn=s.min||0, mx=s.max||1000, mean=s.mean, std=s.stddev;
  if (mean!=null && std!=null && std>0) return Array.from({length:n},()=>Math.max(mn,Math.min(mx,Math.round(rng.normal(mean,std)))));
  return Array.from({length:n},()=>rng.nextInt(mn, mx));
}
function sampleFloat(rng, s, n) {
  const mean=s.mean||0, std=s.stddev||1, mn=s.min||-1e9, mx=s.max||1e9;
  return Array.from({length:n},()=>Math.round(Math.max(mn,Math.min(mx,rng.normal(mean,std)))*100)/100);
}
function sampleStr(rng, s, n) {
  if (s.top_values) return sampleFreq(rng, s.top_values, n);
  const mnl=s.min_length||5, mxl=s.max_length||20;
  return Array.from({length:n},()=>rng.string(rng.nextInt(mnl,mxl)));
}
function sampleDate(rng, s, n) {
  const mn=new Date(s.min||'2020-01-01').getTime(), mx=new Date(s.max||'2025-12-31').getTime();
  const range = mx-mn || 86400000*365;
  return Array.from({length:n},()=>new Date(mn+rng.next()*range).toISOString().split('T')[0]);
}
function sampleTS(rng, s, n) {
  return sampleDate(rng,s,n).map(d=>`${d}T${String(rng.nextInt(0,23)).padStart(2,'0')}:${String(rng.nextInt(0,59)).padStart(2,'0')}:${String(rng.nextInt(0,59)).padStart(2,'0')}`);
}
function sampleBool(rng, s, n) {
  let tr=0.5;
  (s.top_values||[]).forEach(t=>{if(String(t.value).toLowerCase()==='true')tr=t.frequency;});
  return Array.from({length:n},()=>rng.next()<tr);
}
function sampleFreq(rng, tv, n) {
  const vals=tv.map(t=>t.value), freqs=tv.map(t=>t.frequency||1/tv.length);
  const sum=freqs.reduce((a,b)=>a+b,0);
  const cum=freqs.reduce((a,f)=>{a.push((a.length?a[a.length-1]:0)+f/sum);return a;},[]);
  return Array.from({length:n},()=>{const r=rng.next();const i=cum.findIndex(c=>r<=c);return vals[Math.max(0,i)];});
}

function generateTables(bp, seed) {
  const rng = new SeededRNG(seed);
  const tMap = {}; bp.tables.forEach(t=>tMap[t.name]=t);
  // Topological sort
  const order = [], visited = new Set();
  function visit(tn) {
    if (visited.has(tn)) return; visited.add(tn);
    const ts = tMap[tn]; if (!ts) return;
    ts.foreign_keys.forEach(fk => visit(fk.references_table));
    order.push(tn);
  }
  Object.keys(tMap).forEach(visit);
  const pkPools = {}, results = {};
  for (const tn of order) {
    const ts = tMap[tn]; if (!ts) continue;
    const data = {}; const rc = ts.row_count;
    ts.columns.forEach(c => { data[c.name] = sampleColumn(rng, c, rc); });
    // Apply FK values
    ts.foreign_keys.forEach(fk => {
      const pool = (pkPools[fk.references_table]||{})[fk.references_column] || [];
      if (pool.length && data[fk.column]) { data[fk.column] = data[fk.column].map(()=>rng.choice(pool)); }
    });
    // Build PK pool
    pkPools[tn] = {};
    ts.columns.filter(c=>c.is_primary_key).forEach(c => {
      pkPools[tn][c.name] = data[c.name].filter(v=>v!=null);
    });
    results[tn] = data;
  }
  return results;
}

// ================================================================
// MEDALLION
// ================================================================
function runMedallion(tables, bp) {
  const tMap = {}; bp.tables.forEach(t=>tMap[t.name]=t);
  const bronze={}, silver={}, gold={}, rules=[], results_q=[];
  let totalDropped=0, totalNulls=0;
  for (const [tn, data] of Object.entries(tables)) {
    const ts = tMap[tn]; const cols = Object.keys(data); const rc = data[cols[0]]?data[cols[0]].length:0;
    // Bronze
    bronze[tn] = {data, rowCount:rc, columns:cols};
    // Silver: remove all-null rows, dedup PKs
    const keep = Array(rc).fill(true);
    for (let i=0;i<rc;i++) { if (cols.every(c=>data[c][i]==null)) { keep[i]=false; totalDropped++; } }
    const silverData = {}; cols.forEach(c => silverData[c] = data[c].filter((_,i)=>keep[i]));
    const src = silverData[cols[0]]?silverData[cols[0]].length:0;
    silver[tn] = {data:silverData, rowCount:src, columns:cols};
    // Gold: agg
    const agg = cols.map(c => {
      const vals = silverData[c].filter(v=>v!=null);
      const nums = vals.map(Number).filter(v=>!isNaN(v));
      const row = {column:c, non_null:vals.length, nulls:src-vals.length};
      if (nums.length > src*0.5) {
        row.min = Math.round(Math.min(...nums)*100)/100;
        row.max = Math.round(Math.max(...nums)*100)/100;
        row.mean = Math.round(nums.reduce((a,b)=>a+b,0)/nums.length*100)/100;
      } else {
        const freq = {}; vals.forEach(v=>{freq[v]=(freq[v]||0)+1;});
        row.distinct = Object.keys(freq).length;
        row.top = Object.entries(freq).sort((a,b)=>b[1]-a[1]).slice(0,3).map(([v,c])=>`${v}(${c})`).join(', ');
      }
      return row;
    });
    gold[tn] = agg;
    // Quality rules
    if (ts) ts.columns.forEach(cs => {
      const cn = cs.name;
      if (!cs.nullable) {
        rules.push({name:`${tn}_${cn}_not_null`, table:tn, expression:`${cn} IS NOT NULL`});
        const nc = silverData[cn]?silverData[cn].filter(v=>v==null).length:0;
        results_q.push({rule:`${tn}_${cn}_not_null`,table:tn,column:cn,passed:nc===0,violations:nc,total:src});
      }
      if (cs.is_primary_key) {
        rules.push({name:`${tn}_${cn}_unique`, table:tn, expression:`${cn} is unique`});
        const seen=new Set(); let dups=0; (silverData[cn]||[]).forEach(v=>{if(seen.has(v))dups++;seen.add(v);});
        results_q.push({rule:`${tn}_${cn}_unique`,table:tn,column:cn,passed:dups===0,violations:dups,total:src});
      }
    });
  }
  return {bronze,silver,gold,rules,results:results_q,stats:{rows_dropped:totalDropped,nulls_cleaned:totalNulls,tables_processed:Object.keys(tables).length}};
}

// ================================================================
// VALIDATION
// ================================================================
function runValidation_fn(bp, tables, qualResults) {
  const results = [];
  for (const ts of bp.tables) {
    const tn = ts.name, data = tables[tn];
    if (!data) { results.push({table:tn,schema_score:0,fidelity_score:0,quality_score:0,pipeline_score:0,overall_score:0,recs:['Table not generated']}); continue; }
    const cols = Object.keys(data); const rc = data[cols[0]]?data[cols[0]].length:0;
    // Schema
    const expected = ts.columns.map(c=>c.name);
    const missing = expected.filter(c=>!cols.includes(c));
    const matched = expected.filter(c=>cols.includes(c)).length;
    const ss = matched / Math.max(expected.length, 1);
    // Fidelity
    const rcMatch = Math.abs(rc - ts.row_count) / Math.max(ts.row_count, 1) <= 0.05;
    const fs = (rcMatch?1:0.5)*0.2 + 0.8*1.0;
    // Quality
    let qs = 1.0;
    if (qualResults) { const v = qualResults.filter(r=>r.table===tn&&!r.passed); if (v.length) qs = Math.max(0, 1-v.length*0.1); }
    const overall = ss*0.25 + fs*0.35 + qs*0.20 + 1.0*0.20;
    const recs = []; if (missing.length) recs.push('Missing columns: '+missing.join(', '));
    results.push({table:tn, schema_score:Math.round(ss*1000)/1000, fidelity_score:Math.round(fs*1000)/1000,
      quality_score:Math.round(qs*1000)/1000, pipeline_score:1.0, overall_score:Math.round(overall*1000)/1000, recs, missing});
  }
  return results;
}

// ================================================================
// UI HELPERS
// ================================================================
function html(tag, attrs, ...children) {
  const el = document.createElement(tag);
  if (attrs) Object.entries(attrs).forEach(([k,v]) => { if (k==='className') el.className=v; else if (k==='onclick') el.onclick=v; else el.setAttribute(k,v); });
  children.forEach(c => { if (typeof c === 'string') el.innerHTML += c; else if (c) el.appendChild(c); });
  return el;
}

// Security: HTML escape to prevent XSS from NiFi XML content
function escapeHTML(s) {
  if (s === null || s === undefined) return '';
  return String(s).replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;').replace(/"/g,'&quot;').replace(/'/g,'&#39;');
}

// Security: Mask sensitive NiFi properties
const SENSITIVE_PROP_RE = /password|secret|token|key|auth|credential|cert|private|keytab|passphrase/i;
function maskProperty(key, value) {
  if (SENSITIVE_PROP_RE.test(key)) return '********';
  return value;
}
function isSensitiveProp(key) { return SENSITIVE_PROP_RE.test(key); }

// Databricks configuration (persisted to localStorage)
const DBX_CONFIG_DEFAULTS = { catalog: '', schema: '', secretScope: '', cloudProvider: 'azure', sparkVersion: '14.3.x-scala2.12', nodeType: 'Standard_DS3_v2', numWorkers: 2, workspacePath: '/Workspace/Migrations/NiFi' };
function loadDbxConfig() {
  try { const s = localStorage.getItem('dbx_config'); return s ? { ...DBX_CONFIG_DEFAULTS, ...JSON.parse(s) } : { ...DBX_CONFIG_DEFAULTS }; } catch(e) { return { ...DBX_CONFIG_DEFAULTS }; }
}
function saveDbxConfig(cfg) {
  try { localStorage.setItem('dbx_config', JSON.stringify(cfg)); } catch(e) {}
}
function getDbxConfig() {
  return {
    catalog: document.getElementById('cfgCatalog')?.value || '',
    schema: document.getElementById('cfgSchema')?.value || '',
    secretScope: document.getElementById('cfgScope')?.value || '',
    cloudProvider: document.getElementById('cfgCloud')?.value || 'azure',
    sparkVersion: document.getElementById('cfgSparkVersion')?.value || '14.3.x-scala2.12',
    nodeType: document.getElementById('cfgNodeType')?.value || 'Standard_DS3_v2',
    numWorkers: parseInt(document.getElementById('cfgWorkers')?.value) || 2,
    workspacePath: document.getElementById('cfgWorkspacePath')?.value || '/Workspace/Migrations/NiFi'
  };
}
function resolveNotebookPlaceholders(code, cfg) {
  if (!cfg || !cfg.catalog) return code;
  return code
    .replace(/<catalog>|{catalog}/g, cfg.catalog)
    .replace(/<schema>|{schema}/g, cfg.schema || 'default')
    .replace(/<scope>|{scope}/g, cfg.secretScope || 'migration_secrets')
    .replace(/<workspace_path>/g, cfg.workspacePath || '/Workspace/Migrations/NiFi')
    .replace(/<spark_version>/g, cfg.sparkVersion || '14.3.x-scala2.12')
    .replace(/<node_type>/g, cfg.nodeType || 'Standard_DS3_v2');
}

function metricsHTML(items) {
  return '<div class="metrics">'+items.map(([l,v,d])=>`<div class="metric"><div class="label">${l}</div><div class="value">${v}</div>${d?`<div class="delta">${d}</div>`:''}</div>`).join('')+'</div>';
}

function tableHTML(headers, rows) {
  return `<div class="table-scroll"><table><thead><tr>${headers.map(h=>`<th>${h}</th>`).join('')}</tr></thead><tbody>${rows.map(r=>`<tr>${r.map(c=>`<td>${c??''}</td>`).join('')}</tr>`).join('')}</tbody></table></div>`;
}

function expanderHTML(title, content, open=false) {
  return `<div class="expander ${open?'open':''}"><div class="expander-header" onclick="this.parentElement.classList.toggle('open')"><span>${title}</span><span class="expander-arrow">▶</span></div><div class="expander-body">${content}</div></div>`;
}

function scoreBadge(score) {
  if (score >= 0.9) return `<span class="badge badge-green">🟢 GREEN ${Math.round(score*100)}%</span>`;
  if (score >= 0.7) return `<span class="badge badge-amber">🟡 AMBER ${Math.round(score*100)}%</span>`;
  return `<span class="badge badge-red">🔴 RED ${Math.round(score*100)}%</span>`;
}

function progressHTML(score, label) {
  const cls = score>=0.9?'green':score>=0.7?'amber':'red';
  return `<div style="margin:4px 0"><div style="display:flex;justify-content:space-between;font-size:0.85rem"><span>${label}</span><span>${Math.round(score*100)}%</span></div><div class="progress-bar"><div class="progress-fill ${cls}" style="width:${Math.round(score*100)}%"></div></div></div>`;
}

function dataPreviewHTML(data, maxRows=15) {
  const cols = Object.keys(data); if (!cols.length) return '';
  const rc = data[cols[0]]?data[cols[0]].length:0;
  const rows = []; for (let i=0;i<Math.min(rc,maxRows);i++) rows.push(cols.map(c=>{ const v=data[c][i]; return v==null?'<span style="color:var(--text2)">null</span>':String(v).substring(0,40); }));
  return tableHTML(cols, rows);
}

// ================================================================
// STEP HANDLERS
// ================================================================
function parseInput() {
  const content = uploadedContent || document.getElementById('pasteInput').value.trim();
  if (!content) { alert('Upload a file or paste text first.'); return; }
  setTabStatus('parse', 'processing');
  // Use smart parse cascade
  let parsed;
  try {
    parsed = smartParse(content, uploadedName || null);
  } catch(e) { setTabStatus('parse', 'ready'); alert('Parse error: '+e.message); return; }
  if (!parsed || !parsed.tables || !parsed.tables.length) {
    setTabStatus('parse', 'ready');
    const warnings = parsed && parsed.parse_warnings ? parsed.parse_warnings.join('\n') : '';
    alert('No tables found. Check your input format.' + (warnings ? '\n\n' + warnings : ''));
    return;
  }
  STATE.parsed = parsed; STATE.blueprint = STATE.tables = STATE.medallion = STATE.validation = STATE.notebook = STATE.migrationReport = STATE.comparison = STATE.simulation = STATE.finalReport = STATE.virtualEnv = null;
  // Lock steps 6+7+8+9+10 until validation completes
  setTabStatus('notebook', 'locked');
  setTabStatus('report', 'locked');
  setTabStatus('comparison', 'locked');
  setTabStatus('simulate', 'locked');
  setTabStatus('reportFinal', 'locked');
  document.getElementById('notebookNotReady').classList.remove('hidden');
  document.getElementById('notebookNotNifi').classList.add('hidden');
  document.getElementById('notebookReady').classList.add('hidden');
  document.getElementById('notebookResults').innerHTML = '';
  document.getElementById('reportNotReady').classList.remove('hidden');
  document.getElementById('reportReady').classList.add('hidden');
  document.getElementById('reportResults').innerHTML = '';
  document.getElementById('comparisonNotReady').classList.remove('hidden');
  document.getElementById('comparisonReady').classList.add('hidden');
  document.getElementById('comparisonResults').innerHTML = '';
  document.getElementById('simulateNotReady').classList.remove('hidden');
  document.getElementById('simulateReady').classList.add('hidden');
  document.getElementById('simulateResults').innerHTML = '';
  document.getElementById('reportFinalNotReady').classList.remove('hidden');
  document.getElementById('reportFinalReady').classList.add('hidden');
  document.getElementById('reportFinalResults').innerHTML = '';
  // Detect source system
  const fmt = parsed.detected_format || parsed.input_format || 'unknown';
  const src = detectSourceSystem(content, fmt);
  const tc = parsed.tables.reduce((a,t)=>a+t.columns.length,0);
  const tf = parsed.tables.reduce((a,t)=>a+t.foreign_keys.length,0);
  let h = '<hr class="divider">';
  h += `<div class="detected-source"><span class="dot"></span><strong>${src.name}</strong>&nbsp;—&nbsp;${src.type}<span style="margin-left:12px;color:var(--text2);font-size:0.85rem">(${fmt.replace(/_/g,' ')})</span></div>`;
  // Show parse quality info
  if (parsed.parse_attempts && parsed.parse_attempts > 1) h += `<div class="alert alert-info">Smart parser tried ${parsed.parse_attempts} format(s) before finding a match (confidence: ${Math.round((parsed.parse_confidence||0)*100)}%)</div>`;
  h += metricsHTML([['Tables',parsed.tables.length],['Columns',tc],['Foreign Keys',tf],['Source',src.name]]);
  // NiFi-specific details
  if (parsed._nifi) {
    const nf = parsed._nifi;
    h += metricsHTML([['Processors',nf.processors.length],['Connections',nf.connections.length],['Process Groups',nf.processGroups.length],['Controller Services',nf.controllerServices.length]]);
    if (nf.processGroups.length) {
      const pgRows = nf.processGroups.map(pg => {
        const pc = nf.processors.filter(p=>p.group===pg.name).length;
        return [pg.name, pg.parentGroup, pc];
      });
      h += expanderHTML(`<strong>Process Groups</strong> (${nf.processGroups.length})`, tableHTML(['Group Name','Parent','Processors'], pgRows));
    }
    if (nf.processors.length) {
      // Group by type for summary
      const byType = {}; nf.processors.forEach(p=>{ byType[p.type]=(byType[p.type]||0)+1; });
      const typeRows = Object.entries(byType).sort((a,b)=>b[1]-a[1]).map(([t,c])=>[t,c]);
      let procBody = '<h3 style="margin-top:0">By Type</h3>' + tableHTML(['Processor Type','Count'], typeRows);
      // Show first 30 processors
      const pRows = nf.processors.slice(0,30).map(p => [p.name, p.type, p.group, p.state||'', Object.keys(p.properties).length]);
      procBody += `<h3>Processors (first 30 of ${nf.processors.length})</h3>` + tableHTML(['Name','Type','Group','State','Props'], pRows);
      h += expanderHTML(`<strong>Processors</strong> (${nf.processors.length})`, procBody);
    }
    if (nf.connections.length) {
      const cRows = nf.connections.slice(0,30).map(c => [c.sourceName, c.destinationName, c.relationships.join(', ')]);
      h += expanderHTML(`<strong>Connections</strong> (${nf.connections.length})`, tableHTML(['Source','Destination','Relationships'], cRows) + (nf.connections.length>30?`<p style="color:var(--text2)">...and ${nf.connections.length-30} more</p>`:''));
    }
    if (nf.controllerServices.length) {
      const csRows = nf.controllerServices.map(s => [s.name, s.type, s.state||'', Object.keys(s.properties).length+' props']);
      h += expanderHTML(`<strong>Controller Services</strong> (${nf.controllerServices.length})`, tableHTML(['Service','Type','State','Properties'], csRows));
    }
    if (nf.sqlTables && nf.sqlTables.length) {
      const stRows = nf.sqlTables.map(t => [t, t.startsWith('$')?'variable':'table']);
      h += expanderHTML(`<strong>SQL Table References</strong> (${nf.sqlTables.length})`, tableHTML(['Table Reference','Type'], stRows));
    }
    // Build and display Resource Manifest
    const manifest = buildResourceManifest(nf);
    STATE.manifest = manifest;
    h += expanderHTML(`<strong>Resource Manifest</strong> (${manifest.totalResources} resources)`, renderManifestHTML(manifest), true);
  }
  // Dependency graph-specific details
  if (parsed._dependency) {
    const dep = parsed._dependency;
    const allTableCount = Object.keys(dep.allTables || {}).length;
    h += metricsHTML([['Sessions',dep.sessions.length],['Dependencies',dep.edges.length],['Unique Tables',allTableCount],['Conflicts',dep.conflicts.length]]);
    // Sessions summary
    if (dep.sessions.length) {
      const sRows = dep.sessions.map(s => [s.name, s.sources, s.targets, s.lookups]);
      h += expanderHTML(`<strong>ETL Sessions</strong> (${dep.sessions.length})`, tableHTML(['Session','Sources','Targets','Lookups'], sRows));
    }
    // Dependency edges
    if (dep.edges.length) {
      const eRows = dep.edges.map(e => {
        const up = e.upstream || e.upstream_session || e.from || '';
        const down = e.downstream || e.downstream_session || e.to || '';
        const via = e.shared_tables ? e.shared_tables.join(', ') : (e.via_table || '');
        return [up, down, via];
      });
      h += expanderHTML(`<strong>Dependency Edges</strong> (${dep.edges.length})`, tableHTML(['Upstream','Downstream','Shared Tables'], eRows));
    }
    // Recommended execution order
    if (dep.order.length) {
      const oRows = dep.order.map((s, i) => [i + 1, s]);
      h += expanderHTML(`<strong>Recommended Order</strong> (${dep.order.length})`, tableHTML(['Step','Session'], oRows));
    }
    // Conflicts
    if (dep.conflicts.length) {
      const cRows = dep.conflicts.map(c => [c.table_name, c.conflict_type, (c.writers||[]).join(', '), (c.readers||c.lookup_readers||[]).join(', ')]);
      h += expanderHTML(`<strong>Conflicts</strong> (${dep.conflicts.length})`, '<div class="alert alert-warn" style="margin:0 0 8px">These tables have multiple writers or timing issues</div>' + tableHTML(['Table','Conflict Type','Writers','Readers'], cRows));
    }
  }
  if (parsed.parse_warnings && parsed.parse_warnings.length) {
    h += '<div class="alert alert-warn">'+parsed.parse_warnings.join('<br>')+'</div>';
  }
  parsed.tables.forEach(t => {
    const rows = t.columns.map(c=>[c.name, c.data_type, c.raw_type||c.data_type, c.nullable?'Yes':'No', c.is_primary_key?'Y':'', (c.check_constraints||[]).join(', ')]);
    let body = tableHTML(['Column','Type','Raw Type','Nullable','PK','Check'], rows);
    if (t.foreign_keys.length) { body += '<p style="margin-top:8px"><strong>Foreign Keys:</strong></p>'+t.foreign_keys.map(fk=>`<p style="font-size:0.9rem">  <code>${fk.fk_column}</code> → <code>${fk.referenced_table}(${fk.referenced_column})</code></p>`).join(''); }
    h += expanderHTML(`Table: <strong>${t.name}</strong> (${t.columns.length} columns)`, body, true);
  });
  h += `<div class="alert alert-success">Parsed <strong>${parsed.tables.length} tables</strong> with <strong>${tc} columns</strong> from <strong>${src.name}</strong> — running full pipeline...</div>`;
  document.getElementById('parseResults').innerHTML = h;
  document.getElementById('blueprintNotReady').classList.add('hidden');
  document.getElementById('blueprintReady').classList.remove('hidden');
  setTabStatus('parse', 'done');
  unlockTab('blueprint');
  // Auto-run full pipeline
  runFullPipeline();
}

async function runFullPipeline() {
  const delay = ms => new Promise(r => setTimeout(r, ms));
  const steps = [
    { tab: 'blueprint', fn: () => assembleBlueprint() },
    { tab: 'generate', fn: () => generateData() },
    { tab: 'conform', fn: () => runConform() },
    { tab: 'validate', fn: () => runValidation() },
  ];
  // NiFi-only steps
  const isNifi = STATE.parsed && STATE.parsed._nifi;
  if (isNifi) {
    steps.push({ tab: 'notebook', fn: () => generateNotebook() });
    steps.push({ tab: 'report', fn: () => generateReport() });
    steps.push({ tab: 'comparison', fn: () => generateComparison() });
    steps.push({ tab: 'simulate', fn: async () => await runDualSimulation() });
    steps.push({ tab: 'reportFinal', fn: async () => await generateFinalReport() });
  }
  for (const step of steps) {
    switchTab(step.tab);
    await delay(100); // Allow UI to paint the tab switch
    try { await step.fn(); } catch(e) { console.warn(`Pipeline step ${step.tab} error:`, e); break; }
    await delay(50);
  }
}

function assembleBlueprint() {
  if (!STATE.parsed) return;
  setTabStatus('blueprint', 'processing');
  STATE.blueprint = assembleBlueprint_fn(STATE.parsed);
  STATE.tables = STATE.medallion = STATE.validation = null;
  const bp = STATE.blueprint;
  let h = '<hr class="divider">';
  h += metricsHTML([['Blueprint ID',bp.blueprint_id.substring(0,8)+'...'],['Tables',bp.tables.length],['Relationships',bp.relationships.length],['Source',bp.source_system.type]]);
  // Environment Summary
  h += buildEnvironmentSummary(STATE.parsed, bp);
  if (bp.relationships.length) {
    h += '<h3>Relationships</h3>';
    bp.relationships.forEach(r => { const ft=r.from_table.split('.').pop(), tt=r.to_table.split('.').pop(), j=r.join_columns[0]; h += `<p><code>${ft}</code>.${j.from_column} → <code>${tt}</code>.${j.to_column}</p>`; });
  }
  h += '<h3>Table Specifications</h3>';
  bp.tables.forEach(t => {
    const rows = t.columns.map(c=>[c.name, c.data_type, c.is_primary_key?'Y':'', Math.round((c.stats.null_ratio||0)*100)+'%', c.stats.min??'', c.stats.max??'', c.stats.distinct_count??'']);
    h += expanderHTML(`<strong>${t.name}</strong> — ${t.row_count} rows`, tableHTML(['Column','Type','PK','Null%','Min','Max','Distinct'], rows));
  });
  h += `<div style="margin-top:16px;display:flex;gap:8px;flex-wrap:wrap"><button class="btn btn-secondary" onclick="downloadJSON()">Download Blueprint JSON</button><button class="btn btn-secondary" onclick="downloadEnvironment()">Export Environment Model</button></div>`;
  h += `<div class="alert alert-success">Blueprint assembled — proceed to Step 3</div>`;
  document.getElementById('blueprintResults').innerHTML = h;
  document.getElementById('generateNotReady').classList.add('hidden');
  document.getElementById('generateReady').classList.remove('hidden');
  // Render adaptive tier diagram
  try {
    const tierData = buildTierData(bp, STATE.parsed);
    if (tierData && tierData.nodes.length) {
      renderTierDiagram(tierData, 'tierDiagram', 'tierNodeDetail', 'tierDiagramLegend');
    }
  } catch(e) { console.warn('Tier diagram error:', e); }
  setTabStatus('blueprint', 'done');
  unlockTab('generate');
}

function downloadJSON() {
  if (!STATE.blueprint) return;
  const blob = new Blob([JSON.stringify(STATE.blueprint,null,2)], {type:'application/json'});
  const a = document.createElement('a'); a.href = URL.createObjectURL(blob);
  a.download = `blueprint_${STATE.blueprint.blueprint_id.substring(0,8)}.json`; a.click();
}

function downloadEnvironment() {
  if (!STATE.parsed || !STATE.blueprint) return;
  const env = {
    source: {name: STATE.parsed.source_name, type: STATE.parsed.source_type, format: STATE.parsed.input_format},
    blueprint_id: STATE.blueprint.blueprint_id,
    tables: STATE.blueprint.tables.map(t => ({name:t.name, schema:t.schema, columns:t.columns.length, row_count:t.row_count, has_pk:t.columns.some(c=>c.is_primary_key), fk_count:t.foreign_keys.length})),
    relationships: STATE.blueprint.relationships,
    tier_structure: (function() {
      try { const td = buildTierData(STATE.blueprint, STATE.parsed); return {type:td.diagramType, tiers:Object.keys(td.tierLabels).length, nodes:td.nodes.length, connections:td.connections.length}; } catch(e) { return null; }
    })()
  };
  if (STATE.parsed._nifi) {
    const nf = STATE.parsed._nifi;
    env.nifi_environment = {
      processors: nf.processors.map(p => ({name:p.name, type:p.type, group:p.group, role:classifyNiFiProcessor(p.type), state:p.state})),
      connections: nf.connections.map(c => ({source:c.sourceName, dest:c.destinationName, relationships:c.relationships})),
      process_groups: nf.processGroups,
      controller_services: nf.controllerServices.map(s => ({name:s.name, type:s.type, state:s.state})),
      sql_table_refs: nf.sqlTables
    };
  }
  const blob = new Blob([JSON.stringify(env,null,2)], {type:'application/json'});
  const a = document.createElement('a'); a.href = URL.createObjectURL(blob);
  a.download = `environment_${STATE.blueprint.blueprint_id.substring(0,8)}.json`; a.click();
}

function generateData() {
  if (!STATE.blueprint) return;
  setTabStatus('generate', 'processing');
  const seed = parseInt(document.getElementById('seed').value)||42;
  const rowOverride = parseInt(document.getElementById('rowCount').value)||0;
  // Apply row override if specified
  if (rowOverride > 0) {
    STATE.blueprint.tables.forEach(t => { t.row_count = rowOverride; });
  }
  STATE.tables = generateTables(STATE.blueprint, seed);
  STATE.medallion = STATE.validation = STATE.virtualEnv = null;
  const tables = STATE.tables;
  // Build VirtualEnv if NiFi flow is loaded
  if (STATE.parsed && STATE.parsed._nifi) {
    const venvResult = buildInitialVirtualEnv(STATE.parsed._nifi, tables, STATE.manifest);
    // Clone for both engines
    const nifiEnv = venvResult.env;
    const dbxJson = JSON.stringify({ filesystem: nifiEnv.filesystem, sqlTables: nifiEnv.sqlTables, tokens: nifiEnv.tokens, signals: nifiEnv.signals, counters: nifiEnv.counters });
    const dbxEnv = new VirtualEnv();
    const dbxData = JSON.parse(dbxJson);
    dbxEnv.filesystem = dbxData.filesystem; dbxEnv.sqlTables = dbxData.sqlTables;
    dbxEnv.tokens = dbxData.tokens; dbxEnv.signals = dbxData.signals; dbxEnv.counters = dbxData.counters;
    STATE.virtualEnv = { nifi: nifiEnv, dbx: dbxEnv, seedStats: venvResult.seedStats };
  }
  const totalRows = Object.values(tables).reduce((a,d)=>a+(d[Object.keys(d)[0]]||[]).length,0);
  const totalCols = Object.values(tables).reduce((a,d)=>a+Object.keys(d).length,0);
  let h = '<hr class="divider">';
  h += metricsHTML([['Tables Generated',Object.keys(tables).length],['Total Rows',totalRows.toLocaleString()],['Total Columns',totalCols]]);
  for (const [name, data] of Object.entries(tables)) {
    const cols = Object.keys(data); const rc = data[cols[0]]?data[cols[0]].length:0;
    let body = '<strong>Preview</strong> (first 15 rows)' + dataPreviewHTML(data);
    // Stats
    body += '<h3 style="margin-top:16px">Column Statistics</h3>';
    const statRows = cols.map(c => {
      const vals = data[c].filter(v=>v!=null); const nums = vals.map(Number).filter(v=>!isNaN(v));
      if (nums.length > vals.length*0.5) {
        const mn = Math.min(...nums), mx = Math.max(...nums), mean = nums.reduce((a,b)=>a+b,0)/nums.length;
        return [c, vals.length, data[c].length-vals.length, Math.round(mn*100)/100, Math.round(mx*100)/100, Math.round(mean*100)/100];
      }
      const uniq = new Set(vals).size;
      return [c, vals.length, data[c].length-vals.length, '—','—', `${uniq} unique`];
    });
    body += tableHTML(['Column','Non-Null','Null','Min','Max','Mean/Distinct'], statRows);
    h += expanderHTML(`<strong>${name}</strong> — ${rc.toLocaleString()} rows, ${cols.length} columns`, body, true);
  }
  h += `<div style="margin-top:16px"><button class="btn btn-secondary" onclick="downloadCSV()">Download All (CSV ZIP)</button></div>`;
  // VirtualEnv summary
  if (STATE.virtualEnv) {
    const ss = STATE.virtualEnv.seedStats;
    const nEnv = STATE.virtualEnv.nifi;
    h += '<hr class="divider"><h3>Virtual Environment</h3>';
    h += '<div class="venv-summary">';
    h += `<div class="venv-stat"><div class="venv-stat-num">${ss.files}</div><div class="venv-stat-label">Files Seeded</div></div>`;
    h += `<div class="venv-stat"><div class="venv-stat-num">${ss.sqlTables}</div><div class="venv-stat-label">SQL Tables</div></div>`;
    h += `<div class="venv-stat"><div class="venv-stat-num">${ss.tokens}</div><div class="venv-stat-label">Tokens</div></div>`;
    h += `<div class="venv-stat"><div class="venv-stat-num">${ss.signals}</div><div class="venv-stat-label">Signals</div></div>`;
    if (ss.scripts) h += `<div class="venv-stat"><div class="venv-stat-num">${ss.scripts}</div><div class="venv-stat-label">Scripts</div></div>`;
    if (ss.httpEndpoints) h += `<div class="venv-stat"><div class="venv-stat-num">${ss.httpEndpoints}</div><div class="venv-stat-label">HTTP APIs</div></div>`;
    if (ss.kafkaTopics) h += `<div class="venv-stat"><div class="venv-stat-num">${ss.kafkaTopics}</div><div class="venv-stat-label">Kafka Topics</div></div>`;
    h += '</div>';
    if (ss.manifestTotal) h += `<div style="font-size:0.82rem;color:var(--text2);margin:4px 0">Manifest coverage: <strong>${ss.manifestSeeded}</strong> resources seeded of <strong>${ss.manifestTotal}</strong> identified</div>`;
    h += expanderHTML('<strong>Virtual Environment Resources</strong> (files, tables, tokens, signals)', renderVenvTree(nEnv), false);
  }
  h += `<div class="alert alert-success">Generated <strong>${totalRows.toLocaleString()} rows</strong> across <strong>${Object.keys(tables).length} tables</strong>${STATE.virtualEnv ? ` + <strong>${STATE.virtualEnv.seedStats.files} files</strong>, <strong>${STATE.virtualEnv.seedStats.sqlTables} SQL tables</strong>, <strong>${STATE.virtualEnv.seedStats.tokens} tokens</strong> in VirtualEnv` : ''} — proceed to Step 4</div>`;
  document.getElementById('generateResults').innerHTML = h;
  document.getElementById('conformNotReady').classList.add('hidden');
  document.getElementById('conformReady').classList.remove('hidden');
  // Update tier diagram with row count badges
  try { updateTierDiagramBadges(tables); } catch(e) { console.warn('Badge update error:', e); }
  setTabStatus('generate', 'done');
  unlockTab('conform');
}

function downloadCSV() {
  if (!STATE.tables) return;
  // Simple CSV generation (no zip library needed — download individual files)
  for (const [name, data] of Object.entries(STATE.tables)) {
    const cols = Object.keys(data); const rc = data[cols[0]]?data[cols[0]].length:0;
    let csv = cols.join(',')+'\n';
    for (let i=0;i<rc;i++) csv += cols.map(c=>data[c][i]??'').join(',')+'\n';
    const blob = new Blob([csv], {type:'text/csv'});
    const a = document.createElement('a'); a.href=URL.createObjectURL(blob); a.download=`${name}.csv`; a.click();
  }
}

function runConform() {
  if (!STATE.tables || !STATE.blueprint) return;
  setTabStatus('conform', 'processing');
  STATE.medallion = runMedallion(STATE.tables, STATE.blueprint);
  STATE.validation = null;
  const med = STATE.medallion;
  let h = '<hr class="divider">';
  h += metricsHTML([['Tables Processed',med.stats.tables_processed],['Rows Dropped',med.stats.rows_dropped],['Nulls Cleaned',med.stats.nulls_cleaned]]);
  h += '<h3>Medallion Layers</h3>';
  for (const tn of Object.keys(med.bronze)) {
    h += `<h3 style="margin-top:20px">Table: <code>${tn}</code></h3><div class="row">`;
    // Bronze
    h += `<div class="col-3"><h3>Bronze (Raw)</h3>`;
    h += metricsHTML([['Rows',med.bronze[tn].rowCount]]);
    h += dataPreviewHTML(med.bronze[tn].data, 8) + '</div>';
    // Silver
    const dropped = med.bronze[tn].rowCount - med.silver[tn].rowCount;
    h += `<div class="col-3"><h3>Silver (Cleaned)</h3>`;
    h += metricsHTML([['Rows', med.silver[tn].rowCount, dropped?`-${dropped}`:'']]);
    h += dataPreviewHTML(med.silver[tn].data, 8) + '</div>';
    // Gold
    h += `<div class="col-3"><h3>Gold (Aggregated)</h3>`;
    h += metricsHTML([['Columns Profiled', med.gold[tn].length]]);
    const goldRows = med.gold[tn].map(r=>[r.column, r.non_null, r.nulls, r.min??'—', r.max??'—', r.mean??r.top??'—', r.distinct??'—']);
    h += tableHTML(['Column','Non-Null','Nulls','Min','Max','Mean/Top','Distinct'], goldRows) + '</div></div>';
  }
  h += '<hr class="divider"><h3>Quality Rules</h3>';
  if (med.rules.length) {
    h += '<p><strong>DLT Expectations:</strong></p><pre>';
    med.rules.forEach(r => h += `  CONSTRAINT ${r.name} EXPECT (${r.expression})\n`);
    h += '</pre>';
    h += '<p><strong>Quality Check Results:</strong></p>';
    const qRows = med.results.map(r=>[r.passed?'<span class="badge badge-green">PASS</span>':'<span class="badge badge-red">FAIL</span>', r.rule, r.table, r.violations, r.total]);
    h += tableHTML(['Status','Rule','Table','Violations','Total'], qRows);
    const pc = med.results.filter(r=>r.passed).length;
    h += metricsHTML([['Pass Rate',`${pc}/${med.results.length} (${Math.round(pc/Math.max(med.results.length,1)*100)}%)`]]);
  } else h += '<div class="alert alert-info">No quality rules for this schema.</div>';
  // Action Conformance check (VirtualEnv)
  if (STATE.virtualEnv && STATE.parsed && STATE.parsed._nifi) {
    h += '<hr class="divider"><h3>Action Conformance</h3>';
    h += '<p style="font-size:0.82rem;color:var(--text2)">Verifying VirtualEnv has required resources for each processor type:</p>';
    const nifi = STATE.parsed._nifi;
    const env = STATE.virtualEnv.nifi;
    const checks = [];
    const typeCount = {};
    nifi.processors.forEach(p => { typeCount[p.type] = (typeCount[p.type] || 0) + 1; });
    // Check source processors have input files
    const sources = nifi.processors.filter(p => p.type === 'GetFile' || p.type === 'FetchFile');
    const srcDirs = new Set();
    sources.forEach(p => {
      const dir = p.properties['Input Directory'] || `/data/input/${(p.group||'default').replace(/\\s+/g,'_').toLowerCase()}`;
      srcDirs.add(dir);
    });
    const srcFiles = Object.keys(env.filesystem).filter(f => ![...srcDirs].every(d => !f.startsWith(d)) && !f.endsWith('/.marker'));
    checks.push({ label: `Source processors (GetFile/FetchFile: ${sources.length}) have input files`, pass: sources.length === 0 || srcFiles.length > 0, detail: `${srcFiles.length} files available` });
    // Check SQL processors have tables
    const sqlProcs = nifi.processors.filter(p => /^Execute(SQL|SQLRecord)/.test(p.type));
    const sqlTablesAvailable = Object.keys(env.sqlTables).length;
    checks.push({ label: `SQL processors (ExecuteSQL: ${sqlProcs.length}) have source tables`, pass: sqlProcs.length === 0 || sqlTablesAvailable > 0, detail: `${sqlTablesAvailable} tables seeded` });
    // Check PutDatabaseRecord has target tables
    const putDbProcs = nifi.processors.filter(p => p.type === 'PutDatabaseRecord');
    checks.push({ label: `Database sink processors (PutDatabaseRecord: ${putDbProcs.length}) have target tables`, pass: putDbProcs.length === 0 || sqlTablesAvailable > 0, detail: `${sqlTablesAvailable} tables available` });
    // Check Wait/Notify have matching signals
    const waitProcs = nifi.processors.filter(p => p.type === 'Wait');
    const signalsAvailable = Object.keys(env.signals).length;
    checks.push({ label: `Wait processors (${waitProcs.length}) have signal definitions`, pass: waitProcs.length === 0 || signalsAvailable > 0, detail: `${signalsAvailable} signals configured` });
    // Check shell commands have scripts
    const shellProcs = nifi.processors.filter(p => p.type === 'ExecuteStreamCommand');
    const scriptFiles = Object.keys(env.filesystem).filter(f => env.filesystem[f].format === 'script');
    checks.push({ label: `Shell processors (ExecuteStreamCommand: ${shellProcs.length}) have scripts`, pass: shellProcs.length === 0 || scriptFiles.length > 0, detail: `${scriptFiles.length} scripts seeded` });
    // Check HTTP processors have cached responses
    const httpProcs = nifi.processors.filter(p => p.type === 'InvokeHTTP');
    const httpFiles = Object.keys(env.filesystem).filter(f => f.startsWith('/tmp/http_responses/'));
    checks.push({ label: `HTTP processors (InvokeHTTP: ${httpProcs.length}) have cached responses`, pass: httpProcs.length === 0 || httpFiles.length > 0, detail: `${httpFiles.length} responses cached` });
    const passCount = checks.filter(c => c.pass).length;
    checks.forEach(c => {
      const icon = c.pass ? '<span class="check-icon" style="color:#21C354">&#10003;</span>' : '<span class="check-icon" style="color:#EF4444">&#10007;</span>';
      h += `<div class="conform-check">${icon} ${c.label} <span style="color:var(--text2);font-size:0.75rem">(${c.detail})</span></div>`;
    });
    h += metricsHTML([['Checks Passed', `${passCount}/${checks.length}`], ['Coverage', `${Math.round(passCount/checks.length*100)}%`]]);
  }
  h += '<div class="alert alert-success">Medallion pipeline complete — proceed to Step 5</div>';
  document.getElementById('conformResults').innerHTML = h;
  document.getElementById('validateNotReady').classList.add('hidden');
  document.getElementById('validateReady').classList.remove('hidden');
  // Add medallion tiers to diagram
  try { addMedallionTiers(); } catch(e) { console.warn('Medallion tier error:', e); }
  setTabStatus('conform', 'done');
  unlockTab('validate');
}

function runValidation() {
  if (!STATE.tables || !STATE.blueprint) return;
  setTabStatus('validate', 'processing');
  const qr = STATE.medallion ? STATE.medallion.results : null;
  STATE.validation = runValidation_fn(STATE.blueprint, STATE.tables, qr);
  const val = STATE.validation;
  const avg = val.reduce((a,v)=>a+v.overall_score,0)/val.length;
  const gc = val.filter(v=>v.overall_score>=0.9).length;
  const ac = val.filter(v=>v.overall_score>=0.7&&v.overall_score<0.9).length;
  const rc = val.filter(v=>v.overall_score<0.7).length;
  const icon = avg>=0.9?'🟢':avg>=0.7?'🟡':'🔴';
  const lvl = avg>=0.9?'GREEN':avg>=0.7?'AMBER':'RED';
  let h = '<hr class="divider">';
  h += `<div class="score-big">${icon} ${lvl} — ${Math.round(avg*100)}%</div>`;
  h += `<p style="text-align:center;font-size:1.1rem"><strong>${val.length} tables:</strong> ${gc} green, ${ac} amber, ${rc} red</p>`;
  // Dimension averages
  const avgS = val.reduce((a,v)=>a+v.schema_score,0)/val.length;
  const avgF = val.reduce((a,v)=>a+v.fidelity_score,0)/val.length;
  const avgQ = val.reduce((a,v)=>a+v.quality_score,0)/val.length;
  const avgP = val.reduce((a,v)=>a+v.pipeline_score,0)/val.length;
  h += metricsHTML([['Schema (25%)',Math.round(avgS*100)+'%'],['Fidelity (35%)',Math.round(avgF*100)+'%'],['Quality (20%)',Math.round(avgQ*100)+'%'],['Pipeline (20%)',Math.round(avgP*100)+'%']]);
  h += '<hr class="divider"><h3>Per-Table Results</h3>';
  val.forEach(v => {
    const ic = v.overall_score>=0.9?'🟢':v.overall_score>=0.7?'🟡':'🔴';
    let body = metricsHTML([['Schema',Math.round(v.schema_score*100)+'%'],['Fidelity',Math.round(v.fidelity_score*100)+'%'],['Quality',Math.round(v.quality_score*100)+'%'],['Pipeline',Math.round(v.pipeline_score*100)+'%']]);
    body += progressHTML(v.schema_score, 'Schema Parity');
    body += progressHTML(v.fidelity_score, 'Data Fidelity');
    body += progressHTML(v.quality_score, 'Quality Compliance');
    body += progressHTML(v.pipeline_score, 'Pipeline Integrity');
    if (v.recs&&v.recs.length) body += '<p style="margin-top:12px"><strong>Recommendations:</strong></p><ul>'+v.recs.map(r=>`<li>${r}</li>`).join('')+'</ul>';
    h += expanderHTML(`${ic} <strong>${escapeHTML(v.table)}</strong> — ${Math.round(v.overall_score*100)}%`, body, v.overall_score<0.9);
  });
  h += '<hr class="divider"><h3>Scoring Methodology</h3>';
  h += tableHTML(['Dimension','Weight','Description'],[['Schema Parity','25%','Columns and types match blueprint'],['Data Fidelity','35%','Distributions, null ratios match'],['Quality Compliance','20%','DLT expectations pass rate'],['Pipeline Integrity','20%','Medallion pipeline success']]);
  h += tableHTML(['Level','Threshold','Meaning'],[['🟢 Green','≥ 90%','Ready for production cutover'],['🟡 Amber','≥ 70%','Needs attention'],['🔴 Red','< 70%','Not ready']]);
  // Resource Validation (VirtualEnv)
  if (STATE.virtualEnv) {
    h += '<hr class="divider"><h3>Resource Validation</h3>';
    h += '<p style="font-size:0.82rem;color:var(--text2)">Validating VirtualEnv resources for simulation readiness:</p>';
    const env = STATE.virtualEnv.nifi;
    const resChecks = [];
    // Validate file contents are parseable
    let parseableFiles = 0, totalFiles = 0;
    Object.entries(env.filesystem).forEach(([path, entry]) => {
      if (entry.format === 'raw' || path.endsWith('/.marker')) return;
      totalFiles++;
      try {
        if (entry.format === 'json') { JSON.parse(entry.content); parseableFiles++; }
        else if (entry.format === 'csv') { const lines = entry.content.split('\\n').filter(l => l.trim()); if (lines.length > 0) parseableFiles++; }
        else if (entry.format === 'script') parseableFiles++;
        else parseableFiles++;
      } catch(e) {}
    });
    resChecks.push({ label: 'File contents parseable', pass: totalFiles === 0 || parseableFiles === totalFiles, detail: `${parseableFiles}/${totalFiles} files` });
    // Validate SQL table schemas have rows
    let tablesWithData = 0;
    Object.values(env.sqlTables).forEach(t => { if (t.rowCount > 0) tablesWithData++; });
    resChecks.push({ label: 'SQL tables have data', pass: Object.keys(env.sqlTables).length === 0 || tablesWithData === Object.keys(env.sqlTables).length, detail: `${tablesWithData}/${Object.keys(env.sqlTables).length} tables populated` });
    // Validate token availability
    const availableTokens = Object.values(env.tokens).filter(t => t.released).length;
    resChecks.push({ label: 'Tokens available for acquisition', pass: Object.keys(env.tokens).length === 0 || availableTokens > 0, detail: `${availableTokens}/${Object.keys(env.tokens).length} available` });
    // Validate signal targets are reachable
    const reachableSignals = Object.values(env.signals).filter(s => s.target > 0).length;
    resChecks.push({ label: 'Signal targets defined', pass: Object.keys(env.signals).length === 0 || reachableSignals > 0, detail: `${reachableSignals}/${Object.keys(env.signals).length} configured` });
    const rPass = resChecks.filter(c => c.pass).length;
    resChecks.forEach(c => {
      const icon = c.pass ? '<span style="color:#21C354;margin-right:6px">&#10003;</span>' : '<span style="color:#EF4444;margin-right:6px">&#10007;</span>';
      h += `<div class="conform-check">${icon} ${c.label} <span style="color:var(--text2);font-size:0.75rem">(${c.detail})</span></div>`;
    });
    h += metricsHTML([['Resource Checks', `${rPass}/${resChecks.length}`], ['Readiness', `${Math.round(rPass/resChecks.length*100)}%`]]);
  }
  h += '<div class="alert alert-success">Validation complete! Your synthetic environment is ready.</div>';
  document.getElementById('validateResults').innerHTML = h;
  // Add validation scoring to diagram
  try { addValidationTier(val, avg); } catch(e) { console.warn('Validation tier error:', e); }
  setTabStatus('validate', 'done');
  // Unlock Step 6 for NiFi flows
  if (STATE.parsed && STATE.parsed._nifi) {
    document.getElementById('notebookNotReady').classList.add('hidden');
    document.getElementById('notebookNotNifi').classList.add('hidden');
    document.getElementById('notebookReady').classList.remove('hidden');
    unlockTab('notebook');
  } else {
    document.getElementById('notebookNotReady').classList.add('hidden');
    document.getElementById('notebookNotNifi').classList.remove('hidden');
    document.getElementById('notebookReady').classList.add('hidden');
  }
}

// ================================================================
// STEP 6 — GENERATE NOTEBOOK
// ================================================================
function generateNotebook() {
  if (!STATE.parsed || !STATE.parsed._nifi) return;
  setTabStatus('notebook', 'processing');
  const nifi = STATE.parsed._nifi;
  const cfg = getDbxConfig();
  const mappings = mapNiFiToDatabricks(nifi);
  const nbResult = generateDatabricksNotebook(mappings, nifi, STATE.blueprint, cfg);
  const cells = nbResult.cells;
  const workflow = generateWorkflowJSON(mappings, nifi, cfg);
  STATE.notebook = { mappings, cells, workflow, config: cfg };

  let h = '<hr class="divider">';

  // --- Mapping Summary Table ---
  h += '<h3>Processor Mapping</h3>';
  const mapRows = mappings.map(m => [
    escapeHTML(m.name),
    `<span style="color:${ROLE_TIER_COLORS[m.role]||'#808495'}">${escapeHTML(m.role)}</span>`,
    escapeHTML(m.group || '—'),
    m.mapped ? escapeHTML(m.desc) : '<em style="color:var(--text2)">No equivalent</em>',
    m.mapped ? `<span class="conf-badge ${m.confidence>=0.8?'conf-high':m.confidence>=0.5?'conf-med':'conf-low'}">${Math.round(m.confidence*100)}%</span>`
             : '<span class="conf-badge conf-none">—</span>'
  ]);
  h += `<div class="table-scroll"><table class="mapping-table"><thead><tr><th>NiFi Processor</th><th>Role</th><th>Group</th><th>Databricks Equivalent</th><th>Confidence</th></tr></thead><tbody>${mapRows.map(r=>`<tr>${r.map(c=>`<td>${c}</td>`).join('')}</tr>`).join('')}</tbody></table></div>`;

  // --- Notebook Preview ---
  h += '<hr class="divider"><h3>Generated Notebook</h3>';
  h += '<div class="notebook-preview">';
  cells.forEach((cell, i) => {
    const lbl = cell.label || (cell.type === 'md' ? 'markdown' : 'code');
    const lblClass = cell.role ? 'lb-' + cell.role : 'lb-config';
    const typeTag = cell.type === 'md' ? ' <span style="opacity:0.5">[md]</span>' : cell.type === 'sql' ? ' <span style="opacity:0.5">[sql]</span>' : '';
    const code = cell.source.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');
    h += `<div class="notebook-cell"><div class="cell-label ${lblClass}">[${i+1}] ${lbl}${typeTag}</div><pre>${code}</pre></div>`;
  });
  h += '</div>';

  // --- Unity Catalog DDL ---
  const ddlCells = cells.filter(c => c.label && c.label.includes('Unity Catalog'));
  if (ddlCells.length) {
    h += '<hr class="divider"><h3>Unity Catalog DDL</h3>';
    ddlCells.forEach(c => {
      const code = c.source.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');
      h += `<div class="notebook-preview"><div class="notebook-cell"><div class="cell-label lb-config">SQL</div><pre>${code}</pre></div></div>`;
    });
  }

  // --- Workflow JSON ---
  h += '<hr class="divider"><h3>Databricks Workflow (Jobs API)</h3>';
  const wfJson = JSON.stringify(workflow, null, 2).replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');
  h += `<div class="notebook-preview"><div class="notebook-cell"><div class="cell-label lb-config">JSON</div><pre>${wfJson}</pre></div></div>`;

  // --- Download buttons ---
  h += '<hr class="divider"><div style="display:flex;gap:8px;flex-wrap:wrap">';
  h += `<button class="btn" onclick="downloadNotebook()">Download .py Notebook</button>`;
  h += `<button class="btn" onclick="downloadWorkflow()">Download Workflow JSON</button>`;
  h += '</div>';

  document.getElementById('notebookResults').innerHTML = h;
  setTabStatus('notebook', 'done');

  // Unlock Step 7
  document.getElementById('reportNotReady').classList.add('hidden');
  document.getElementById('reportReady').classList.remove('hidden');
  unlockTab('report');
}

function downloadNotebook() {
  if (!STATE.notebook) return;
  // Convert clean cell content to Databricks .py notebook format
  const pyCells = STATE.notebook.cells.map(c => {
    if (c.type === 'md') {
      return c.source.split('\n').map(l => '# MAGIC %md' === l ? '# MAGIC %md' : '# MAGIC ' + l).join('\n');
    }
    if (c.type === 'sql') {
      return '# MAGIC %sql\n' + c.source.split('\n').map(l => '# MAGIC ' + l).join('\n');
    }
    return c.source;
  });
  const nb = '# Databricks notebook source\n\n' + pyCells.join('\n\n# COMMAND ----------\n\n');
  const blob = new Blob([nb], {type:'text/plain'});
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob);
  a.download = 'nifi_migration_notebook.py';
  a.click(); URL.revokeObjectURL(a.href);
}

function downloadWorkflow() {
  if (!STATE.notebook) return;
  const blob = new Blob([JSON.stringify(STATE.notebook.workflow, null, 2)], {type:'application/json'});
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob);
  a.download = 'databricks_workflow.json';
  a.click(); URL.revokeObjectURL(a.href);
}

// ================================================================
// STEP 7 — MIGRATION REPORT
// ================================================================
function generateReport() {
  if (!STATE.notebook || !STATE.parsed || !STATE.parsed._nifi) return;
  setTabStatus('report', 'processing');
  const nifi = STATE.parsed._nifi;
  const report = generateMigrationReport(STATE.notebook.mappings, nifi);
  STATE.migrationReport = report;
  const s = report.summary;

  let h = '<hr class="divider">';

  // --- Coverage Score ---
  const pct = s.coveragePercent;
  const cls = pct >= 85 ? 'green' : pct >= 60 ? 'amber' : 'red';
  const icon = pct >= 85 ? '🟢' : pct >= 60 ? '🟡' : '🔴';
  const lvl = pct >= 85 ? 'HIGH COVERAGE' : pct >= 60 ? 'PARTIAL COVERAGE' : 'LOW COVERAGE';
  h += `<div class="score-big">${icon} ${lvl} — ${pct}%</div>`;
  h += metricsHTML([
    ['Total Processors', s.totalProcessors],
    ['Mapped', s.mappedProcessors],
    ['Unmapped', s.unmappedProcessors],
    ['Process Groups', s.totalProcessGroups],
    ['Connections', s.totalConnections],
    ['Effort', `<span class="badge badge-${report.effort==='Low'?'green':report.effort==='Medium'?'amber':'red'}">${report.effort}</span>`]
  ]);

  // --- By Role Breakdown ---
  h += '<hr class="divider"><h3>Coverage by Role</h3>';
  const roleOrder = ['source','route','transform','process','sink','utility'];
  roleOrder.forEach(role => {
    const rd = report.byRole[role];
    if (!rd) return;
    const rpct = rd.total ? Math.round(rd.mapped / rd.total * 100) : 0;
    const rcls = rpct >= 85 ? 'green' : rpct >= 60 ? 'amber' : 'red';
    const color = ROLE_TIER_COLORS[role] || '#808495';
    h += `<div style="margin:8px 0">`;
    h += `<div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:2px">`;
    h += `<span style="font-weight:600;color:${color};text-transform:uppercase;font-size:0.85rem">${role}</span>`;
    h += `<span style="font-size:0.85rem;color:var(--text2)">${rd.mapped}/${rd.total} (${rpct}%)</span>`;
    h += `</div>`;
    h += `<div class="progress-bar"><div class="progress-fill ${rcls}" style="width:${rpct}%"></div></div>`;
    if (rd.procs && rd.procs.length) {
      h += `<div style="font-size:0.8rem;color:var(--text2);margin-top:2px">${rd.procs.map(p=>p.name).join(', ')}</div>`;
    }
    h += `</div>`;
  });

  // --- By Group Breakdown ---
  h += '<hr class="divider"><h3>Coverage by Process Group</h3>';
  Object.entries(report.byGroup).sort((a,b)=>a[0].localeCompare(b[0])).forEach(([gname, gd]) => {
    const gpct = gd.total ? Math.round(gd.mapped / gd.total * 100) : 0;
    const gcls = gpct >= 85 ? 'green' : gpct >= 60 ? 'amber' : 'red';
    let body = `<div class="progress-bar" style="margin-bottom:8px"><div class="progress-fill ${gcls}" style="width:${gpct}%"></div></div>`;
    body += `<div style="font-size:0.85rem;color:var(--text2)">Mapped: ${gd.mapped} / ${gd.total}</div>`;
    if (gd.procs && gd.procs.length) {
      body += '<div style="margin-top:6px">';
      gd.procs.forEach(p => {
        const picon = p.mapped ? '✅' : '❌';
        body += `<div style="font-size:0.85rem;padding:2px 0">${picon} <strong>${p.name}</strong> (${p.type}) → ${p.mapped ? p.desc : '<em>unmapped</em>'}</div>`;
      });
      body += '</div>';
    }
    h += expanderHTML(`<span style="color:${gcls==='green'?'var(--green)':gcls==='amber'?'var(--amber)':'var(--red)'}">${gpct}%</span> ${gname} (${gd.mapped}/${gd.total})`, body, gpct < 85);
  });

  // --- Gap Analysis ---
  if (report.gaps.length) {
    h += '<hr class="divider"><h3>Gap Analysis — Unmapped Processors</h3>';
    report.gaps.forEach(g => {
      h += `<div class="gap-card">`;
      h += `<div class="gap-title">${g.name} <span class="gap-meta">${g.type} &middot; ${g.group || 'ungrouped'}</span></div>`;
      h += `<div class="gap-rec">${g.recommendation || 'Manual implementation required'}</div>`;
      h += `</div>`;
    });
  }

  // --- Recommendations ---
  if (report.recommendations.length) {
    h += '<hr class="divider"><h3>Recommendations</h3>';
    h += '<ul style="margin:0;padding-left:20px">';
    report.recommendations.forEach(r => { h += `<li style="margin:4px 0">${r}</li>`; });
    h += '</ul>';
  }

  // --- Download ---
  h += '<hr class="divider"><div style="display:flex;gap:8px;flex-wrap:wrap">';
  h += `<button class="btn" onclick="downloadReport()">Download Report (Markdown)</button>`;
  h += '</div>';

  document.getElementById('reportResults').innerHTML = h;
  setTabStatus('report', 'done');
  // Unlock Step 8
  document.getElementById('comparisonNotReady').classList.add('hidden');
  document.getElementById('comparisonReady').classList.remove('hidden');
  unlockTab('comparison');
}

function downloadReport() {
  if (!STATE.migrationReport) return;
  const r = STATE.migrationReport;
  const s = r.summary;
  let md = `# NiFi → Databricks Migration Report\n\n`;
  md += `## Summary\n| Metric | Value |\n|--------|-------|\n`;
  md += `| Total Processors | ${s.totalProcessors} |\n| Mapped | ${s.mappedProcessors} |\n| Unmapped | ${s.unmappedProcessors} |\n`;
  md += `| Coverage | ${s.coveragePercent}% |\n| Process Groups | ${s.totalProcessGroups} |\n| Effort | ${r.effort} |\n\n`;
  md += `## By Role\n| Role | Mapped | Total | % |\n|------|--------|-------|---|\n`;
  Object.entries(r.byRole).forEach(([role, rd]) => {
    md += `| ${role} | ${rd.mapped} | ${rd.total} | ${rd.total?Math.round(rd.mapped/rd.total*100):0}% |\n`;
  });
  md += `\n## By Group\n| Group | Mapped | Total | % |\n|-------|--------|-------|---|\n`;
  Object.entries(r.byGroup).forEach(([g, gd]) => {
    md += `| ${g} | ${gd.mapped} | ${gd.total} | ${gd.total?Math.round(gd.mapped/gd.total*100):0}% |\n`;
  });
  if (r.gaps.length) {
    md += `\n## Gaps\n| Processor | Type | Group | Recommendation |\n|-----------|------|-------|----------------|\n`;
    r.gaps.forEach(g => { md += `| ${g.processor} | ${g.type} | ${g.group||'—'} | ${g.recommendation||'Manual'} |\n`; });
  }
  if (r.recommendations.length) {
    md += `\n## Recommendations\n`;
    r.recommendations.forEach(rec => { md += `- ${rec}\n`; });
  }
  const blob = new Blob([md], {type:'text/markdown'});
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob);
  a.download = 'migration_report.md';
  a.click(); URL.revokeObjectURL(a.href);
}

// ================================================================
// STEP 8 — CROSS-COMPARISON DASHBOARD
// ================================================================
function generateComparison() {
  if (!STATE.notebook || !STATE.parsed || !STATE.parsed._nifi) return;
  setTabStatus('comparison', 'processing');
  const cmp = computeComparison(STATE.notebook.mappings, STATE.parsed._nifi);
  STATE.comparison = cmp;

  let h = '<hr class="divider">';

  // --- Three Donut Charts ---
  h += '<div class="comparison-donuts">';
  h += donutSVG(cmp.exact.pct, 'Exact Match', `${cmp.exact.count} / ${cmp.exact.total}`);
  h += donutSVG(cmp.functional.pct, 'Functional Match', `${cmp.functional.count} / ${cmp.functional.total}`);
  h += donutSVG(cmp.actions.pct, 'Actions Converted', `${cmp.actions.count} / ${cmp.actions.total}`);
  h += '</div>';

  // --- Summary Metrics ---
  const gaps = cmp.exact.total - cmp.functional.count;
  h += metricsHTML([
    ['Total Processors', cmp.exact.total],
    ['Exact Matches', `<span style="color:#21C354">${cmp.exact.count}</span>`],
    ['Functional Matches', `<span style="color:#EAB308">${cmp.functional.count}</span>`],
    ['Gaps', `<span style="color:#EF4444">${gaps}</span>`],
    ['Pipeline Actions', `${cmp.actions.count} / ${cmp.actions.total}`]
  ]);

  // --- Legend ---
  h += '<div style="margin:16px 0;font-size:0.85rem;color:var(--text2)">';
  h += '<strong>Exact Match</strong> = direct 1:1 code equivalent (confidence &ge; 80%) &nbsp;|&nbsp; ';
  h += '<strong>Functional</strong> = intent preserved (any confidence) &nbsp;|&nbsp; ';
  h += '<strong>Actions</strong> = pipeline connections where both ends are mapped';
  h += '</div>';

  // --- Line-by-Line Comparison Table (inside details) ---
  h += '<hr class="divider">';
  h += `<details class="comparison-detail"><summary>Line-by-Line Comparison (${cmp.rows.length} processors)</summary>`;
  h += '<div class="table-scroll"><table><thead><tr>';
  h += '<th>#</th><th>NiFi Processor</th><th>Type</th><th>Group</th><th></th><th>Databricks Equivalent</th><th>Category</th><th>Match</th><th>Confidence</th>';
  h += '</tr></thead><tbody>';
  cmp.rows.forEach(r => {
    const badgeCls = r.matchType === 'exact' ? 'match-exact' : r.matchType === 'functional' ? 'match-functional' : 'match-gap';
    const badgeLabel = r.matchType === 'exact' ? 'Exact' : r.matchType === 'functional' ? 'Functional' : 'Gap';
    const confStr = r.matchType === 'gap' ? '—' : Math.round(r.confidence * 100) + '%';
    h += `<tr>`;
    h += `<td>${r.idx}</td>`;
    h += `<td><strong>${r.name}</strong></td>`;
    h += `<td style="color:var(--text2)">${r.type}</td>`;
    h += `<td style="color:var(--text2)">${r.group}</td>`;
    h += `<td style="text-align:center;color:var(--text2)">&rarr;</td>`;
    h += `<td>${r.equiv}</td>`;
    h += `<td style="color:var(--text2)">${r.category}</td>`;
    h += `<td><span class="match-badge ${badgeCls}">${badgeLabel}</span></td>`;
    h += `<td style="text-align:center">${confStr}</td>`;
    h += `</tr>`;
  });
  h += '</tbody></table></div></details>';

  document.getElementById('comparisonResults').innerHTML = h;
  setTabStatus('comparison', 'done');
  // Unlock Step 9
  document.getElementById('simulateNotReady').classList.add('hidden');
  document.getElementById('simulateReady').classList.remove('hidden');
  unlockTab('simulate');
}

// ================================================================
// STEP 9 — DUAL EXECUTION SIMULATION
// ================================================================

function topoSortProcessors(processors, connections) {
  // Index-based topological sort using NiFi IDs for connection resolution
  const n = processors.length;
  const idToIdx = {}; // NiFi _id → array index
  processors.forEach((p, i) => { if (p._id) idToIdx[p._id] = i; });
  // Also build name→[indices] for name-based fallback
  const nameToIdxs = {};
  processors.forEach((p, i) => {
    if (!nameToIdxs[p.name]) nameToIdxs[p.name] = [];
    nameToIdxs[p.name].push(i);
  });
  const inDeg = new Array(n).fill(0);
  const adj = Array.from({length:n}, () => []);
  const nameUseCount = {}; // track round-robin for name-based resolution
  connections.forEach(c => {
    // Try to resolve by NiFi ID first
    let srcIdx = idToIdx[c.sourceId];
    let dstIdx = idToIdx[c.destinationId];
    // Fallback: resolve by name (round-robin for duplicates)
    if (srcIdx === undefined && c.sourceName) {
      const idxs = nameToIdxs[c.sourceName];
      if (idxs && idxs.length) {
        const k = 'src_' + c.sourceName;
        nameUseCount[k] = ((nameUseCount[k] || 0)) % idxs.length;
        srcIdx = idxs[nameUseCount[k]++];
      }
    }
    if (dstIdx === undefined && c.destinationName) {
      const idxs = nameToIdxs[c.destinationName];
      if (idxs && idxs.length) {
        const k = 'dst_' + c.destinationName;
        nameUseCount[k] = ((nameUseCount[k] || 0)) % idxs.length;
        dstIdx = idxs[nameUseCount[k]++];
      }
    }
    if (srcIdx !== undefined && dstIdx !== undefined && srcIdx !== dstIdx) {
      adj[srcIdx].push(dstIdx);
      inDeg[dstIdx]++;
    }
  });
  const queue = [];
  for (let i = 0; i < n; i++) { if (inDeg[i] === 0) queue.push(i); }
  const order = [];
  while (queue.length) {
    const v = queue.shift(); order.push(v);
    for (const nb of adj[v]) { inDeg[nb]--; if (inDeg[nb] === 0) queue.push(nb); }
  }
  // Append any remaining (cycles or disconnected)
  for (let i = 0; i < n; i++) { if (!order.includes(i)) order.push(i); }
  return { order, adj };
}

function deepCopyColumnar(data) {
  if (!data) return {};
  const r = {}; Object.keys(data).forEach(c => { r[c] = [...data[c]]; }); return r;
}

function simHash(str) {
  let h = 0;
  for (let i = 0; i < str.length; i++) h = ((h << 5) - h + str.charCodeAt(i)) | 0;
  return 'h_' + Math.abs(h).toString(16).padStart(8, '0');
}

// ================================================================
// VIRTUALENV — In-memory operating system for simulation
// ================================================================
class VirtualEnv {
  constructor() {
    this.filesystem = {};   // path -> { content, size, modified, format }
    this.sqlTables = {};    // "schema.table" -> { columns: {col:[vals]}, rowCount }
    this.tokens = {};       // name -> { owner, acquired, released }
    this.signals = {};      // id -> { count, target, released }
    this.counters = {};     // name -> value
    this.flowfileQueues = {}; // connId -> [{attributes:{}, content:""}]
    this.log = [];          // [{tick, processor, action, target, before, after}]
    this.tick = 0;
  }
  _log(proc, action, target, before, after) {
    this.log.push({ tick: this.tick++, processor: proc, action, target, before, after });
  }
  // Filesystem
  writeFile(proc, path, content, format) {
    const before = this.filesystem[path] ? { ...this.filesystem[path], content: this.filesystem[path].content.substring(0, 100) } : null;
    this.filesystem[path] = { content, size: content.length, modified: this.tick, format: format || 'raw' };
    this._log(proc, 'FILE_WRITE', path, before, { size: content.length, format: format || 'raw' });
  }
  readFile(proc, path) {
    const entry = this.filesystem[path];
    this._log(proc, 'FILE_READ', path, null, entry ? { size: entry.size, format: entry.format } : null);
    return entry ? entry.content : null;
  }
  moveFile(proc, from, to) {
    const entry = this.filesystem[from];
    if (entry) {
      this.filesystem[to] = { ...entry, modified: this.tick };
      delete this.filesystem[from];
      this._log(proc, 'FILE_MOVE', `${from} -> ${to}`, { path: from }, { path: to, size: entry.size });
    }
  }
  deleteFile(proc, path) {
    const before = this.filesystem[path] ? { size: this.filesystem[path].size } : null;
    delete this.filesystem[path];
    this._log(proc, 'FILE_DELETE', path, before, null);
  }
  listFiles(proc, dir) {
    const files = Object.keys(this.filesystem).filter(p => p.startsWith(dir));
    this._log(proc, 'FILE_LIST', dir, null, { count: files.length });
    return files;
  }
  fileExists(path) { return !!this.filesystem[path]; }
  // SQL
  createTable(proc, table, schema) {
    const columns = {};
    Object.keys(schema).forEach(c => { columns[c] = []; });
    this.sqlTables[table] = { columns, rowCount: 0 };
    this._log(proc, 'SQL_CREATE', table, null, { columns: Object.keys(schema) });
  }
  insertRows(proc, table, data) {
    if (!this.sqlTables[table]) {
      const columns = {};
      Object.keys(data).forEach(c => { columns[c] = []; });
      this.sqlTables[table] = { columns, rowCount: 0 };
    }
    const t = this.sqlTables[table];
    const beforeRC = t.rowCount;
    Object.keys(data).forEach(c => {
      if (!t.columns[c]) t.columns[c] = Array(t.rowCount).fill(null);
      t.columns[c] = t.columns[c].concat(data[c]);
    });
    const newRows = data[Object.keys(data)[0]] ? data[Object.keys(data)[0]].length : 0;
    t.rowCount += newRows;
    this._log(proc, 'SQL_INSERT', table, { rowCount: beforeRC }, { rowCount: t.rowCount, added: newRows });
  }
  queryTable(proc, table, filter) {
    const t = this.sqlTables[table];
    this._log(proc, 'SQL_QUERY', table, null, t ? { rowCount: t.rowCount, cols: Object.keys(t.columns).length } : null);
    return t ? deepCopyColumnar(t.columns) : null;
  }
  updateRows(proc, table, setObj, where) {
    const t = this.sqlTables[table];
    if (!t) return;
    const beforeRC = t.rowCount;
    Object.entries(setObj).forEach(([col, val]) => {
      if (!t.columns[col]) t.columns[col] = Array(t.rowCount).fill(null);
      for (let i = 0; i < t.rowCount; i++) t.columns[col][i] = val;
    });
    this._log(proc, 'SQL_UPDATE', table, { rowCount: beforeRC }, { rowCount: t.rowCount, set: Object.keys(setObj) });
  }
  // Tokens
  acquireToken(proc, name) {
    if (!this.tokens[name]) this.tokens[name] = { owner: null, acquired: false, released: true };
    const before = { ...this.tokens[name] };
    this.tokens[name] = { owner: proc, acquired: true, released: false };
    this._log(proc, 'TOKEN_ACQUIRE', name, before, { ...this.tokens[name] });
  }
  releaseToken(proc, name) {
    if (!this.tokens[name]) this.tokens[name] = { owner: null, acquired: false, released: true };
    const before = { ...this.tokens[name] };
    this.tokens[name] = { owner: null, acquired: false, released: true };
    this._log(proc, 'TOKEN_RELEASE', name, before, { ...this.tokens[name] });
  }
  // Signals
  sendSignal(proc, id, count) {
    if (!this.signals[id]) this.signals[id] = { count: 0, target: 1, released: false };
    const before = { ...this.signals[id] };
    this.signals[id].count += (count || 1);
    if (this.signals[id].count >= this.signals[id].target) this.signals[id].released = true;
    this._log(proc, 'SIGNAL_SEND', id, before, { ...this.signals[id] });
  }
  waitSignal(proc, id, target) {
    if (!this.signals[id]) this.signals[id] = { count: 0, target: target || 1, released: false };
    const before = { ...this.signals[id] };
    const ready = this.signals[id].released || this.signals[id].count >= (target || this.signals[id].target);
    this._log(proc, 'SIGNAL_WAIT', id, before, { ready, ...this.signals[id] });
    return ready;
  }
  // Counters
  incrementCounter(proc, name, delta) {
    if (!this.counters[name]) this.counters[name] = 0;
    const before = this.counters[name];
    this.counters[name] += (delta || 1);
    this._log(proc, 'COUNTER_INC', name, { value: before }, { value: this.counters[name] });
  }
  // FlowFile queues
  enqueue(proc, connId, flowfile) {
    if (!this.flowfileQueues[connId]) this.flowfileQueues[connId] = [];
    this.flowfileQueues[connId].push(flowfile);
    this._log(proc, 'QUEUE_ENQUEUE', connId, null, { queueSize: this.flowfileQueues[connId].length });
  }
  dequeue(proc, connId) {
    if (!this.flowfileQueues[connId] || !this.flowfileQueues[connId].length) return null;
    const ff = this.flowfileQueues[connId].shift();
    this._log(proc, 'QUEUE_DEQUEUE', connId, { queueSize: this.flowfileQueues[connId].length + 1 }, { queueSize: this.flowfileQueues[connId].length });
    return ff;
  }
  queueSize(connId) { return this.flowfileQueues[connId] ? this.flowfileQueues[connId].length : 0; }
  // Snapshots
  snapshot() {
    return {
      filesystem: Object.fromEntries(Object.entries(this.filesystem).map(([k, v]) => [k, { size: v.size, format: v.format, modified: v.modified }])),
      sqlTables: Object.fromEntries(Object.entries(this.sqlTables).map(([k, v]) => [k, { rowCount: v.rowCount, cols: Object.keys(v.columns) }])),
      tokens: JSON.parse(JSON.stringify(this.tokens)),
      signals: JSON.parse(JSON.stringify(this.signals)),
      counters: { ...this.counters },
      tick: this.tick
    };
  }
  diffSnapshots(before, after) {
    const diffs = [];
    // Filesystem diffs
    const allPaths = new Set([...Object.keys(before.filesystem), ...Object.keys(after.filesystem)]);
    allPaths.forEach(p => {
      const b = before.filesystem[p], a = after.filesystem[p];
      if (!b && a) diffs.push({ type: 'FILE', action: 'CREATED', target: p, after: a });
      else if (b && !a) diffs.push({ type: 'FILE', action: 'DELETED', target: p, before: b });
      else if (b && a && (b.size !== a.size || b.modified !== a.modified)) diffs.push({ type: 'FILE', action: 'MODIFIED', target: p, before: b, after: a });
    });
    // SQL diffs
    const allTables = new Set([...Object.keys(before.sqlTables), ...Object.keys(after.sqlTables)]);
    allTables.forEach(t => {
      const b = before.sqlTables[t], a = after.sqlTables[t];
      if (!b && a) diffs.push({ type: 'SQL', action: 'CREATED', target: t, after: a });
      else if (b && !a) diffs.push({ type: 'SQL', action: 'DELETED', target: t, before: b });
      else if (b && a && b.rowCount !== a.rowCount) diffs.push({ type: 'SQL', action: 'MODIFIED', target: t, before: b, after: a });
    });
    // Token diffs
    const allTokens = new Set([...Object.keys(before.tokens), ...Object.keys(after.tokens)]);
    allTokens.forEach(t => {
      const b = before.tokens[t], a = after.tokens[t];
      if (JSON.stringify(b) !== JSON.stringify(a)) diffs.push({ type: 'TOKEN', action: 'CHANGED', target: t, before: b, after: a });
    });
    // Signal diffs
    const allSignals = new Set([...Object.keys(before.signals), ...Object.keys(after.signals)]);
    allSignals.forEach(s => {
      const b = before.signals[s], a = after.signals[s];
      if (JSON.stringify(b) !== JSON.stringify(a)) diffs.push({ type: 'SIGNAL', action: 'CHANGED', target: s, before: b, after: a });
    });
    return diffs;
  }
  getProcessorActions(procName) {
    return this.log.filter(e => e.processor === procName);
  }
  getSummary() {
    return {
      files: Object.keys(this.filesystem).length,
      totalFileSize: Object.values(this.filesystem).reduce((s, f) => s + f.size, 0),
      sqlTables: Object.keys(this.sqlTables).length,
      totalSqlRows: Object.values(this.sqlTables).reduce((s, t) => s + t.rowCount, 0),
      tokens: Object.keys(this.tokens).length,
      signals: Object.keys(this.signals).length,
      counters: Object.keys(this.counters).length,
      totalActions: this.log.length
    };
  }
}

// Generate synthetic data pool for a process group
function generateGroupDataPool(groupName, processors, tables) {
  // Try to find a matching table from Step 3
  const tNames = Object.keys(tables);
  for (const tn of tNames) {
    const data = tables[tn];
    if (data && Object.keys(data).length && data[Object.keys(data)[0]].length) return deepCopyColumnar(data);
  }
  // Build synthetic data based on group context
  const rowCount = 10 + Math.abs(simHash(groupName).charCodeAt(3) % 20);
  const pool = {
    record_id: Array.from({length:rowCount}, (_,i) => i + 1),
    group_name: Array(rowCount).fill(groupName),
    file_name: Array.from({length:rowCount}, (_,i) => `${groupName.replace(/\s+/g,'_').toLowerCase()}_${i}.dat`),
    load_date: Array.from({length:rowCount}, (_,i) => `2026-01-${String((i%28)+1).padStart(2,'0')}`),
    status: Array.from({length:rowCount}, (_,i) => ['PENDING','RUNNING','COMPLETE','ERROR'][i%4]),
    record_count: Array.from({length:rowCount}, (_,i) => 100 + (i * 37) % 500),
    payload: Array.from({length:rowCount}, (_,i) => `data_chunk_${groupName.substring(0,8)}_${i}`)
  };
  // Add SQL-referenced column names if processors reference them
  const sqlCols = new Set();
  processors.forEach(p => {
    Object.values(p.properties || {}).forEach(v => {
      if (typeof v !== 'string') return;
      const colRefs = v.match(/\$\{([a-zA-Z_]\w*)\}/g);
      if (colRefs) colRefs.forEach(r => { const cn = r.replace(/\$\{|\}/g,'').toLowerCase(); if (cn.length > 2 && cn.length < 30) sqlCols.add(cn); });
    });
  });
  sqlCols.forEach(cn => { if (!pool[cn]) pool[cn] = Array.from({length:rowCount}, (_,i) => `${cn}_val_${i}`); });
  return pool;
}

// ================================================================
// VIRTUALENV SEED BUILDER
// ================================================================
function inferColumnType(name) {
  const n = name.toLowerCase();
  if (/^(id|_id|record_id|pk)$/.test(n) || n.endsWith('_id')) return 'int';
  if (/date|time|timestamp|created|modified|updated/.test(n)) return 'date';
  if (/count|num|qty|quantity|amount|total|size|length/.test(n)) return 'int';
  if (/price|cost|rate|pct|percent|ratio|score|weight/.test(n)) return 'float';
  if (/flag|is_|has_|enabled|active|deleted|bool/.test(n)) return 'bool';
  return 'string';
}

function generateSyntheticValue(colName, rowIdx, colType) {
  switch (colType) {
    case 'int': return rowIdx + 1;
    case 'float': return Math.round((rowIdx * 1.73 + 0.5) * 100) / 100;
    case 'date': return `2026-01-${String((rowIdx % 28) + 1).padStart(2, '0')}`;
    case 'bool': return rowIdx % 3 !== 0;
    default: return `${colName}_val_${rowIdx}`;
  }
}

function generateSyntheticFileContent(columns, rowCount, format) {
  const rows = [];
  for (let i = 0; i < rowCount; i++) {
    const row = {};
    columns.forEach(col => {
      row[col] = generateSyntheticValue(col, i, inferColumnType(col));
    });
    rows.push(row);
  }
  if (format === 'json') return JSON.stringify(rows, null, 2);
  if (format === 'xml') {
    let xml = '<?xml version="1.0"?>\n<records>\n';
    rows.forEach(r => { xml += '  <record>\n'; Object.entries(r).forEach(([k, v]) => { xml += `    <${k}>${v}</${k}>\n`; }); xml += '  </record>\n'; });
    return xml + '</records>';
  }
  // Default: CSV
  const header = columns.join(',');
  const lines = rows.map(r => columns.map(c => r[c]).join(','));
  return header + '\n' + lines.join('\n');
}

function buildInitialVirtualEnv(nifiData, tables, manifest) {
  const env = new VirtualEnv();
  const procs = nifiData.processors;
  const conns = nifiData.connections;
  // Discover columns from existing tables
  const allCols = new Set();
  if (tables) Object.values(tables).forEach(t => Object.keys(t).forEach(c => allCols.add(c)));
  const defaultCols = allCols.size > 0 ? [...allCols].slice(0, 8) : ['record_id', 'file_name', 'load_date', 'status', 'value', 'record_count'];

  // 1. Filesystem seeding from processor properties
  procs.forEach(p => {
    const props = p.properties || {};
    const grp = (p.group || 'default').replace(/\s+/g, '_').toLowerCase();
    if (p.type === 'GetFile') {
      const dir = props['Input Directory'] || props['input-directory'] || `/data/input/${grp}`;
      const fmt = (props['File Filter'] || '').includes('.json') ? 'json' : 'csv';
      const cols = defaultCols.length > 0 ? defaultCols : ['id', 'value', 'timestamp'];
      for (let i = 0; i < 3; i++) {
        const fname = `${grp}_${p.name.replace(/\s+/g,'_').toLowerCase()}_${i}.${fmt}`;
        const content = generateSyntheticFileContent(cols, 10 + i * 5, fmt);
        env.writeFile('SEED', `${dir}/${fname}`, content, fmt);
        // Also seed Volumes path for DBX engine
        env.writeFile('SEED', `/Volumes/input/${grp}/${fname}`, content, fmt);
      }
    }
    if (p.type === 'FetchFile') {
      const fname = props['filename'] || props['File to Fetch'] || `${grp}_fetch_data.csv`;
      const dir = props['Input Directory'] || `/data/fetch/${grp}`;
      const content = generateSyntheticFileContent(defaultCols, 15, 'csv');
      env.writeFile('SEED', `${dir}/${fname}`, content, 'csv');
      // Also seed Volumes path for DBX engine
      env.writeFile('SEED', `/Volumes/fetch/${grp}/${fname}`, content, 'csv');
    }
    if (p.type === 'ListFile') {
      const dir = props['Input Directory'] || props['input-directory'] || `/data/list/${grp}`;
      const fmt = (props['File Filter'] || '').includes('.json') ? 'json' : 'csv';
      for (let i = 0; i < 4; i++) {
        const fname = `${grp}_${p.name.replace(/\s+/g,'_').toLowerCase()}_${i}.${fmt}`;
        env.writeFile('SEED', `${dir}/${fname}`, generateSyntheticFileContent(defaultCols, 8 + i * 3, fmt), fmt);
      }
      // Also seed Volumes path for DBX engine
      for (let i = 0; i < 4; i++) {
        const fname = `${grp}_${p.name.replace(/\s+/g,'_').toLowerCase()}_${i}.${fmt}`;
        env.writeFile('SEED', `/Volumes/list/${grp}/${fname}`, generateSyntheticFileContent(defaultCols, 8 + i * 3, fmt), fmt);
      }
    }
    if (p.type === 'PutFile' || p.type === 'PutSFTP' || p.type === 'PutHDFS') {
      const dir = props['Directory'] || props['Remote Path'] || props['Hostname'] || `/data/output/${grp}`;
      env.writeFile('SEED', `${dir}/.marker`, '', 'raw');
      // Also seed Volumes target dirs for DBX engine
      if (p.type === 'PutFile') env.writeFile('SEED', `/Volumes/output/${grp}/.marker`, '', 'raw');
      else if (p.type === 'PutSFTP') {
        const host = props['Hostname'] || props['hostname'] || 'sftp.example.com';
        const remotePath = props['Remote Path'] || 'upload';
        env.writeFile('SEED', `/Volumes/sftp/${host}/${remotePath}/.marker`, '', 'raw');
      }
      else if (p.type === 'PutHDFS') env.writeFile('SEED', `/Volumes/hdfs/${grp}/.marker`, '', 'raw');
    }
    if (p.type === 'ExecuteStreamCommand') {
      const cmd = props['Command'] || props['command'] || '';
      const args = props['Command Arguments'] || props['command-arguments'] || '';
      if (cmd) {
        const scriptContent = `#!/bin/bash\n# Synthetic script for ${p.name}\n# Original: ${cmd} ${args}\necho "Execution complete"\nexit 0`;
        env.writeFile('SEED', cmd.startsWith('/') ? cmd : `/usr/local/bin/${cmd}`, scriptContent, 'script');
      }
      // Detect HDFS operations
      if (cmd === 'hdfs' || args.includes('dfs ')) {
        const pathMatch = args.match(/\/([\w/._-]+)/g);
        if (pathMatch) pathMatch.forEach(path => {
          if (!env.fileExists(path)) {
            env.writeFile('SEED', path, generateSyntheticFileContent(defaultCols, 8, 'csv'), 'csv');
          }
        });
      }
    }
    if (p.type === 'GenerateFlowFile') {
      const customText = props['Custom Text'] || props['custom-text'] || '';
      if (customText) {
        env.writeFile('SEED', `/data/generated/${p.name.replace(/\s+/g,'_')}.dat`, customText, 'raw');
      }
    }
    if (p.type === 'InvokeHTTP') {
      const url = props['Remote URL'] || props['HTTP URL'] || 'http://api.example.com/data';
      const response = JSON.stringify({ status: 'ok', data: Array.from({length: 5}, (_, i) => ({ id: i + 1, value: `response_${i}` })) });
      env.writeFile('SEED', `/tmp/http_responses/${p.name.replace(/\s+/g,'_')}.json`, response, 'json');
    }
  });

  // 2. SQL table seeding
  procs.forEach(p => {
    const props = p.properties || {};
    if (p.type === 'ExecuteSQL' || p.type === 'ExecuteSQLRecord') {
      let sql = props['SQL select query'] || props['sql-select-query'] || props['SQL Pre-Query'] || '';
      // Resolve parameterized table references
      sql = sql.replace(/\$\{(\w+)\}/g, (m, name) => {
        const defaults = { external_table: 'ext_data', staging_table: 'stg_data', prod_table: 'prod_data' };
        return defaults[name] || name;
      });
      const tableMatch = sql.match(/(?:FROM|JOIN)\s+([a-zA-Z_][\w.]*)/gi);
      if (tableMatch) {
        tableMatch.forEach(m => {
          let tName = m.replace(/^(FROM|JOIN)\s+/i, '').trim();
          if (tName.toLowerCase() === 'dual') return; // Skip Oracle dual
          if (!env.sqlTables[tName]) {
            const cols = {};
            defaultCols.forEach(c => {
              cols[c] = Array.from({length: 20}, (_, i) => generateSyntheticValue(c, i, inferColumnType(c)));
            });
            env.insertRows('SEED', tName, cols);
          }
        });
      }
    }
    if (p.type === 'PutDatabaseRecord') {
      const tName = props['Table Name'] || props['table-name'] || `${(p.group || 'default').replace(/\s+/g,'_').toLowerCase()}_target`;
      if (!env.sqlTables[tName]) {
        env.createTable('SEED', tName, Object.fromEntries(defaultCols.map(c => [c, inferColumnType(c)])));
      }
    }
    if (p.type === 'LookupRecord' || p.type === 'LookupAttribute') {
      const lookupTable = props['lookup-table'] || props['Lookup Table'] || `lookup_${p.name.replace(/\s+/g,'_').toLowerCase()}`;
      if (!env.sqlTables[lookupTable]) {
        const cols = { lookup_key: Array.from({length: 10}, (_, i) => `key_${i}`), lookup_value: Array.from({length: 10}, (_, i) => `val_${i}`) };
        env.insertRows('SEED', lookupTable, cols);
      }
    }
  });
  // Also seed from STATE.tables
  if (tables) {
    Object.entries(tables).forEach(([tName, data]) => {
      if (!env.sqlTables[tName] && data && Object.keys(data).length) {
        env.insertRows('SEED', tName, deepCopyColumnar(data));
      }
    });
  }

  // 3. Token seeding (Wait/ControlRate)
  procs.forEach(p => {
    const props = p.properties || {};
    if (p.type === 'Wait') {
      const sigName = props['Signal Counter Name'] || props['Release Signal Identifier'] || `wait_${p.name.replace(/\s+/g,'_').toLowerCase()}`;
      const target = parseInt(props['Target Signal Count']) || 1;
      env.signals[sigName] = { count: 0, target, released: false };
      const tokenName = props['Distributed Cache Service'] || sigName + '_token';
      env.tokens[tokenName] = { owner: null, acquired: false, released: true };
    }
    if (p.type === 'Notify') {
      const sigName = props['Signal Counter Name'] || props['Release Signal Identifier'] || `notify_${p.name.replace(/\s+/g,'_').toLowerCase()}`;
      if (!env.signals[sigName]) env.signals[sigName] = { count: 0, target: 1, released: false };
    }
    if (p.type === 'ControlRate') {
      const tokenName = `rate_${p.name.replace(/\s+/g,'_').toLowerCase()}`;
      env.tokens[tokenName] = { owner: null, acquired: false, released: true };
    }
  });

  // Manifest-based seeding: fill any gaps the per-processor scan missed
  if (manifest) {
    // Seed directories from manifest that weren't already created
    Object.entries(manifest.directories).forEach(([dir, info]) => {
      if (info.type === 'input' && !Object.keys(env.filesystem).some(f => f.startsWith(dir))) {
        const content = generateSyntheticFileContent(defaultCols, 10, 'csv');
        for (let i = 1; i <= 3; i++) env.writeFile('SEED', `${dir}/data_${String(i).padStart(3,'0')}.csv`, content, 'csv');
      }
    });
    // Seed SQL tables from manifest not yet in env
    Object.keys(manifest.sqlTables).forEach(tn => {
      if (!env.sqlTables[tn]) {
        const cols = {}; defaultCols.forEach(c => { cols[c] = []; for (let i=0;i<15;i++) cols[c].push(generateSyntheticValue(c,i,'string')); });
        env.createTable('SEED', tn, Object.fromEntries(defaultCols.map(c=>[c, typeof cols[c][0] === 'number' ? 'int' : 'string'])));
        env.insertRows('SEED', tn, cols);
      }
    });
    // Seed scripts from manifest
    manifest.scripts.forEach(s => {
      if (s.path && !env.fileExists(s.path)) {
        env.writeFile('SEED', s.path, `#!/bin/bash\n# Synthetic script: ${s.path}\necho "Executing ${s.processor}"\n${s.args || ''}`, 'script');
      }
    });
    // Seed HTTP response caches from manifest
    manifest.httpEndpoints.forEach(ep => {
      const path = `/tmp/http_responses/${ep.processor.replace(/\s+/g,'_')}.json`;
      if (!env.fileExists(path)) {
        env.writeFile('SEED', path, JSON.stringify({status:200,body:{result:'ok',endpoint:ep.url},timestamp:new Date().toISOString()}), 'json');
      }
    });
    // Seed Kafka topic queues
    manifest.kafkaTopics.forEach(kt => {
      if (kt.direction === 'consume') {
        const queueId = `kafka_${kt.topic.replace(/[^a-zA-Z0-9]/g,'_')}`;
        for (let i = 0; i < 5; i++) {
          env.enqueue('SEED', queueId, { attributes: { 'kafka.topic': kt.topic, 'kafka.partition': '0', 'kafka.offset': String(i) }, content: JSON.stringify({ event_id: i, timestamp: new Date().toISOString(), data: 'synthetic_' + i }) });
        }
      }
    });
  }

  // Clear SEED entries from log (they're infrastructure, not simulation)
  const seedLogCount = env.log.length;
  env.log = [];
  env.tick = 0;

  const manifestTotal = manifest ? manifest.totalResources : 0;
  const manifestSeeded = Object.keys(env.filesystem).length + Object.keys(env.sqlTables).length + Object.keys(env.tokens).length + Object.keys(env.signals).length;
  return { env, seedStats: { files: Object.keys(env.filesystem).length, sqlTables: Object.keys(env.sqlTables).length, tokens: Object.keys(env.tokens).length, signals: Object.keys(env.signals).length, seedActions: seedLogCount, scripts: manifest ? manifest.scripts.length : 0, httpEndpoints: manifest ? manifest.httpEndpoints.length : 0, kafkaTopics: manifest ? manifest.kafkaTopics.length : 0, directories: Object.keys(manifest ? manifest.directories : {}).length, manifestTotal, manifestSeeded } };
}

function renderVenvTree(env) {
  let h = '<div class="venv-tree">';
  // Files
  const paths = Object.keys(env.filesystem).sort();
  const dirs = new Set();
  paths.forEach(p => { const parts = p.split('/'); for (let i = 1; i < parts.length; i++) dirs.add(parts.slice(0, i).join('/')); });
  const sortedDirs = [...dirs].sort();
  sortedDirs.forEach(d => {
    const depth = d.split('/').length - 1;
    const dirFiles = paths.filter(p => p.startsWith(d + '/') && p.split('/').length === d.split('/').length + 1);
    if (dirFiles.length) {
      h += `<div style="padding-left:${depth * 16}px"><span class="dir">${d.split('/').pop()}/</span> <span class="venv-badge">${dirFiles.length} files</span></div>`;
      dirFiles.forEach(f => {
        const entry = env.filesystem[f];
        h += `<div style="padding-left:${(depth + 1) * 16}px"><span class="file">${f.split('/').pop()}</span> <span class="venv-badge">${entry.size}B ${entry.format}</span></div>`;
      });
    }
  });
  // SQL tables
  if (Object.keys(env.sqlTables).length) {
    h += '<div style="margin-top:8px"><span class="dir">SQL Tables</span></div>';
    Object.entries(env.sqlTables).forEach(([name, t]) => {
      h += `<div style="padding-left:16px"><span class="file">${name}</span> <span class="venv-badge">${t.rowCount} rows, ${Object.keys(t.columns).length} cols</span></div>`;
    });
  }
  // Tokens & Signals
  if (Object.keys(env.tokens).length) {
    h += '<div style="margin-top:8px"><span class="dir">Tokens</span></div>';
    Object.entries(env.tokens).forEach(([name, t]) => {
      h += `<div style="padding-left:16px"><span class="file">${name}</span> <span class="venv-badge">${t.released ? 'available' : 'held'}</span></div>`;
    });
  }
  if (Object.keys(env.signals).length) {
    h += '<div style="margin-top:8px"><span class="dir">Signals</span></div>';
    Object.entries(env.signals).forEach(([name, s]) => {
      h += `<div style="padding-left:16px"><span class="file">${name}</span> <span class="venv-badge">${s.count}/${s.target} ${s.released ? 'released' : 'waiting'}</span></div>`;
    });
  }
  h += '</div>';
  return h;
}

function renderOperationsLog(env, label) {
  const log = env.log || [];
  if (!log.length) return `<em style="color:var(--text2)">No actions recorded for ${label}</em>`;
  // Summary counts
  const counts = {};
  log.forEach(e => { counts[e.action] = (counts[e.action] || 0) + 1; });
  const total = log.length;
  let h = `<div style="font-size:0.78rem;color:var(--text2);margin-bottom:8px"><strong>${total}</strong> actions: `;
  h += Object.entries(counts).sort((a,b) => b[1]-a[1]).map(([a,c]) => {
    const cls = a.startsWith('FILE') ? 'file' : a.startsWith('SQL') ? 'sql' : a.startsWith('TOKEN') ? 'token' : a.startsWith('SIGNAL') ? 'signal' : a.startsWith('COUNTER') ? 'counter' : 'queue';
    return `<span class="ops-action ${cls}">${a}</span> ${c}`;
  }).join(' &bull; ');
  h += '</div>';
  // Timeline (capped at 500 rows for performance)
  h += '<div class="ops-log">';
  h += '<div class="ops-log-row header"><span>Tick</span><span>Processor</span><span>Action</span><span>Target</span><span>Details</span></div>';
  const shown = log.slice(0, 500);
  shown.forEach(e => {
    const cls = e.action.startsWith('FILE') ? 'file' : e.action.startsWith('SQL') ? 'sql' : e.action.startsWith('TOKEN') ? 'token' : e.action.startsWith('SIGNAL') ? 'signal' : e.action.startsWith('COUNTER') ? 'counter' : 'queue';
    let detail = '';
    if (e.action === 'FILE_WRITE' && e.after) detail = (e.after.size || 0) + 'B';
    else if (e.action === 'FILE_READ' && e.after) detail = typeof e.after === 'string' ? e.after.length + 'B' : '';
    else if (e.action === 'SQL_INSERT' && e.after) detail = (e.after.rowCount || 0) + ' rows';
    else if (e.action === 'SQL_QUERY' && e.after) detail = (e.after.rowCount || 0) + ' rows';
    else if (e.action === 'SQL_CREATE') detail = 'created';
    else if (e.action === 'COUNTER_INC' && e.after !== undefined) detail = String(e.after);
    h += `<div class="ops-log-row"><span>${e.tick}</span><span style="overflow:hidden;text-overflow:ellipsis;white-space:nowrap" title="${escapeHTML(e.processor)}">${escapeHTML(e.processor)}</span><span class="ops-action ${cls}">${e.action}</span><span style="overflow:hidden;text-overflow:ellipsis;white-space:nowrap" title="${escapeHTML(e.target)}">${escapeHTML(e.target)}</span><span>${detail}</span></div>`;
  });
  if (log.length > 500) h += `<div style="padding:8px;text-align:center;color:var(--text2);font-size:0.78rem">...and ${log.length - 500} more actions</div>`;
  h += '</div>';
  return h;
}

function renderResourceUsage(manifest, nifiEnv, dbxEnv) {
  if (!manifest) return '';
  const touchedFiles = new Set(), touchedTables = new Set(), touchedTokens = new Set(), touchedSignals = new Set();
  [nifiEnv, dbxEnv].forEach(env => {
    if (!env) return;
    (env.log || []).forEach(e => {
      if (e.action.startsWith('FILE_')) touchedFiles.add(e.target);
      else if (e.action.startsWith('SQL_')) touchedTables.add(e.target);
      else if (e.action.startsWith('TOKEN_')) touchedTokens.add(e.target);
      else if (e.action.startsWith('SIGNAL_')) touchedSignals.add(e.target);
    });
  });

  const allFiles = nifiEnv ? Object.keys(nifiEnv.filesystem) : [];
  const allTables = nifiEnv ? Object.keys(nifiEnv.sqlTables) : [];
  const allTokens = nifiEnv ? Object.keys(nifiEnv.tokens) : [];
  const allSignals = nifiEnv ? Object.keys(nifiEnv.signals) : [];

  const usedFiles = allFiles.filter(f => touchedFiles.has(f));
  const orphanedFiles = allFiles.filter(f => !touchedFiles.has(f));
  const usedTables = allTables.filter(t => touchedTables.has(t));
  const orphanedTables = allTables.filter(t => !touchedTables.has(t));
  const usedTokens = allTokens.filter(t => touchedTokens.has(t));
  const orphanedTokens = allTokens.filter(t => !touchedTokens.has(t));
  const usedSignals = allSignals.filter(s => touchedSignals.has(s));
  const orphanedSignals = allSignals.filter(s => !touchedSignals.has(s));

  // Detect conflicts: multiple processors writing same target
  const writeTargets = {};
  if (nifiEnv) nifiEnv.log.filter(e => e.action === 'FILE_WRITE' || e.action === 'SQL_INSERT').forEach(e => {
    if (!writeTargets[e.target]) writeTargets[e.target] = new Set();
    writeTargets[e.target].add(e.processor);
  });
  const conflicts = Object.entries(writeTargets).filter(([, procs]) => procs.size > 1).map(([target, procs]) => ({ target, processors: [...procs] }));

  let h = '<div style="font-size:0.82rem">';
  const bar = (label, used, total, orphaned) => {
    const pct = total > 0 ? Math.round(used / total * 100) : 100;
    return `<div style="margin:6px 0"><strong>${label}:</strong> ${used} of ${total} used (${pct}%)` +
      (orphaned > 0 ? ` <span style="color:var(--yellow)">— ${orphaned} orphaned</span>` : ' <span style="color:#21C354">all used</span>') + '</div>';
  };
  h += bar('Files', usedFiles.length, allFiles.length, orphanedFiles.length);
  h += bar('SQL Tables', usedTables.length, allTables.length, orphanedTables.length);
  h += bar('Tokens', usedTokens.length, allTokens.length, orphanedTokens.length);
  h += bar('Signals', usedSignals.length, allSignals.length, orphanedSignals.length);

  // List orphans
  if (orphanedFiles.length) {
    h += '<details style="margin:6px 0"><summary style="cursor:pointer;font-size:0.78rem;color:var(--yellow)">Orphaned Files (' + orphanedFiles.length + ')</summary>';
    h += '<div style="font-size:0.75rem;font-family:var(--mono);padding:4px 12px">' + orphanedFiles.map(f => `<span class="resource-dot orphaned"></span>${escapeHTML(f)}`).join('<br>') + '</div></details>';
  }
  if (orphanedTables.length) {
    h += '<details style="margin:6px 0"><summary style="cursor:pointer;font-size:0.78rem;color:var(--yellow)">Orphaned Tables (' + orphanedTables.length + ')</summary>';
    h += '<div style="font-size:0.75rem;font-family:var(--mono);padding:4px 12px">' + orphanedTables.map(t => `<span class="resource-dot orphaned"></span>${escapeHTML(t)}`).join('<br>') + '</div></details>';
  }
  // Conflicts
  if (conflicts.length) {
    h += '<div style="margin-top:8px"><strong style="color:var(--red)">Resource Conflicts (' + conflicts.length + ')</strong></div>';
    conflicts.forEach(c => {
      h += `<div style="font-size:0.78rem;padding:2px 0"><span class="resource-dot missing"></span><strong>${escapeHTML(c.target)}</strong> — written by: ${c.processors.map(escapeHTML).join(', ')}</div>`;
    });
  }
  h += '</div>';
  return h;
}

const PROCESSOR_SIM = {
  source: function(inputData, proc, tables, groupPool) {
    // Try table match first, then group pool, then default
    const tNames = Object.keys(tables);
    const props = proc.properties || {};
    const tableProp = props['Table Name'] || props['table-name'] || '';
    let match = tNames.find(t => t === tableProp);
    if (!match) match = tNames.find(t => proc.name.toLowerCase().includes(t.toLowerCase()));
    if (match && tables[match] && Object.keys(tables[match]).length) return deepCopyColumnar(tables[match]);
    return groupPool ? deepCopyColumnar(groupPool) : { _id: [1,2,3,4,5], _value: ['a','b','c','d','e'] };
  },
  route: function(inputData) {
    if (!inputData || !Object.keys(inputData).length) return inputData;
    const cols = Object.keys(inputData);
    const rc = inputData[cols[0]] ? inputData[cols[0]].length : 0;
    if (!rc) return inputData;
    const cutoff = Math.ceil(rc * 0.8);
    const r = {}; cols.forEach(c => { r[c] = inputData[c].slice(0, cutoff); }); return r;
  },
  transform: function(inputData, proc) {
    if (!inputData || !Object.keys(inputData).length) return inputData;
    const cols = Object.keys(inputData);
    const rc = inputData[cols[0]] ? inputData[cols[0]].length : 0;
    if (!rc) return inputData;
    const r = {}; cols.forEach(c => { r[c] = [...inputData[c]]; });
    const pt = proc.type;
    if (pt === 'UpdateAttribute' || pt === 'AttributesToJSON') {
      r['_transformed'] = Array(rc).fill(true);
    } else if (pt === 'ReplaceText' || pt === 'ExtractText') {
      const sc = cols.find(c => typeof inputData[c][0] === 'string');
      if (sc) r[sc] = inputData[sc].map(v => v != null ? String(v).toUpperCase() : v);
    } else if (pt === 'HashContent') {
      const sc = cols.find(c => typeof inputData[c][0] === 'string') || cols[0];
      r[sc + '_hash'] = inputData[sc].map(v => v != null ? simHash(String(v)) : null);
    } else if (pt === 'SplitContent' || pt === 'SplitJson' || pt === 'SplitXml' || pt === 'SplitText') {
      // Split duplicates rows
      const r2 = {};
      cols.forEach(c => { r2[c] = [...inputData[c], ...inputData[c].slice(0, Math.ceil(rc*0.5))]; });
      return r2;
    } else if (pt === 'MergeContent' || pt === 'MergeRecord') {
      // Merge reduces rows
      const keep = Math.max(1, Math.ceil(rc * 0.6));
      cols.forEach(c => { r[c] = inputData[c].slice(0, keep); });
    }
    return r;
  },
  process: function(inputData, proc) {
    if (!inputData || !Object.keys(inputData).length) return inputData;
    const cols = Object.keys(inputData);
    const rc = inputData[cols[0]] ? inputData[cols[0]].length : 0;
    if (!rc) return inputData;
    const r = {}; cols.forEach(c => { r[c] = [...inputData[c]]; });
    if (proc.type === 'LookupRecord' || proc.type === 'LookupAttribute') r['_lookup_found'] = Array(rc).fill(true);
    else if (/^Execute(SQL|Script|SQLRecord)/.test(proc.type)) r['_sql_processed'] = Array(rc).fill(1);
    else if (proc.type === 'InvokeHTTP') r['_http_status'] = Array(rc).fill(200);
    else if (proc.type === 'PutDatabaseRecord') r['_db_written'] = Array(rc).fill(true);
    return r;
  },
  sink: function(inputData) {
    if (!inputData || !Object.keys(inputData).length) return inputData;
    const r = {}; Object.keys(inputData).forEach(c => { r[c] = [...inputData[c]]; }); return r;
  },
  utility: function(inputData) {
    if (!inputData || !Object.keys(inputData).length) return inputData;
    const r = {}; Object.keys(inputData).forEach(c => { r[c] = [...inputData[c]]; }); return r;
  }
};

// ================================================================
// PROCESSOR_SIM_V2 — VirtualEnv-based simulation per processor type
// ================================================================
// NiFi Expression Language mini-evaluator
function evaluateNiFiEL(expr, attributes) {
  if (!expr || typeof expr !== 'string' || !expr.includes('${')) return expr;
  return expr.replace(/\$\{([^}]+)\}/g, (fullMatch, inner) => {
    const parts = inner.split(':');
    const attrName = parts[0].trim();
    let val;
    if (attrName === 'now()') val = new Date().toISOString();
    else if (attrName === 'nextInt()' || attrName === 'random()') val = String(Math.floor(Math.random() * 10000));
    else if (attrName === 'UUID()' || attrName === 'uuid()') val = 'ff_' + simHash(JSON.stringify(attributes) + Date.now());
    else if (attrName === 'hostname()') val = 'databricks-worker';
    else if (attrName.startsWith('literal(')) {
      const litMatch = attrName.match(/literal\(['"]([^'"]*)['"]\)/);
      val = litMatch ? litMatch[1] : '';
    } else {
      val = attributes[attrName];
    }
    if (val === undefined || val === null) val = fullMatch;
    for (let i = 1; i < parts.length; i++) {
      const fn = parts[i].trim();
      if (fn.startsWith('replaceAll(')) {
        const args = fn.match(/replaceAll\(['"]([^'"]*)['"]\s*,\s*['"]([^'"]*)['"]\)/);
        if (args) { try { val = String(val).replace(new RegExp(args[1], 'g'), args[2]); } catch(e) { val = String(val).split(args[1]).join(args[2]); } }
      } else if (fn.startsWith('replace(')) {
        const args = fn.match(/replace\(['"]([^'"]*)['"]\s*,\s*['"]([^'"]*)['"]\)/);
        if (args) val = String(val).split(args[1]).join(args[2]);
      } else if (fn.startsWith('substring(')) {
        const args = fn.match(/substring\((\d+)(?:\s*,\s*(\d+))?\)/);
        if (args) val = String(val).substring(parseInt(args[1]), args[2] ? parseInt(args[2]) : undefined);
      } else if (fn === 'toUpper()') val = String(val).toUpperCase();
      else if (fn === 'toLower()') val = String(val).toLowerCase();
      else if (fn === 'trim()') val = String(val).trim();
      else if (fn === 'length()') val = String(String(val).length);
      else if (fn === 'isEmpty()') val = String(!val || String(val).length === 0);
      else if (fn.startsWith('equals(')) {
        const arg = fn.match(/equals\(["']([^"']*)["']\)/);
        val = arg ? String(String(val) === arg[1]) : 'false';
      } else if (fn.startsWith('contains(')) {
        const arg = fn.match(/contains\(["']([^"']*)["']\)/);
        val = arg ? String(String(val).includes(arg[1])) : 'false';
      } else if (fn.startsWith('startsWith(')) {
        const arg = fn.match(/startsWith\(["']([^"']*)["']\)/);
        val = arg ? String(String(val).startsWith(arg[1])) : 'false';
      } else if (fn.startsWith('endsWith(')) {
        const arg = fn.match(/endsWith\(["']([^"']*)["']\)/);
        val = arg ? String(String(val).endsWith(arg[1])) : 'false';
      } else if (fn.startsWith('append(')) {
        const arg = fn.match(/append\(["']([^"']*)["']\)/);
        if (arg) val = String(val) + arg[1];
      } else if (fn.startsWith('prepend(')) {
        const arg = fn.match(/prepend\(["']([^"']*)["']\)/);
        if (arg) val = arg[1] + String(val);
      } else if (fn.startsWith('toDate(')) { /* keep string as-is */ }
      else if (fn.startsWith('format(')) {
        const arg = fn.match(/format\(["']([^"']*)["']\)/);
        if (arg) { try { const d = new Date(val); if (!isNaN(d)) { val = arg[1].replace('yyyy', d.getFullYear()).replace('MM', String(d.getMonth()+1).padStart(2,'0')).replace('dd', String(d.getDate()).padStart(2,'0')).replace('HH', String(d.getHours()).padStart(2,'0')).replace('mm', String(d.getMinutes()).padStart(2,'0')).replace('ss', String(d.getSeconds()).padStart(2,'0')); } } catch(e) {} }
      } else if (fn.startsWith('minus(')) {
        const arg = fn.match(/minus\((\d+)\)/); if (arg) { const n = parseFloat(val); if (!isNaN(n)) val = String(n - parseInt(arg[1])); }
      } else if (fn.startsWith('plus(')) {
        const arg = fn.match(/plus\((\d+)\)/); if (arg) { const n = parseFloat(val); if (!isNaN(n)) val = String(n + parseInt(arg[1])); }
      } else if (fn.startsWith('multiply(')) {
        const arg = fn.match(/multiply\((\d+)\)/); if (arg) { const n = parseFloat(val); if (!isNaN(n)) val = String(n * parseInt(arg[1])); }
      } else if (fn.startsWith('divide(')) {
        const arg = fn.match(/divide\((\d+)\)/); if (arg) { const n = parseFloat(val); if (!isNaN(n)) val = String(Math.floor(n / parseInt(arg[1]))); }
      } else if (fn.startsWith('literal(')) {
        const arg = fn.match(/literal\(["']([^"']*)["']\)/); if (arg) val = arg[1];
      } else if (fn === 'not()') { val = String(val === 'false' || val === '0' || val === '' || val === 'null'); }
      else if (fn.startsWith('ifElse(')) {
        const arg = fn.match(/ifElse\(["']([^"']*)["']\s*,\s*["']([^"']*)["']\)/);
        if (arg) val = (val === 'true') ? arg[1] : arg[2];
      }
    }
    return String(val);
  });
}

const PROCESSOR_SIM_V2 = {
  GetFile: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const dir = isDbx ? `/Volumes/input/${proc.group.replace(/\s+/g,'_').toLowerCase()}` : (props['Input Directory'] || `/data/input/${proc.group.replace(/\s+/g,'_').toLowerCase()}`);
    const files = env.listFiles(proc.name, dir);
    const outFFs = [];
    files.forEach(path => {
      if (path.endsWith('/.marker')) return;
      const content = env.readFile(proc.name, path);
      if (content !== null) {
        outFFs.push({ attributes: { filename: path.split('/').pop(), path, 'absolute.path': dir, uuid: 'ff_' + simHash(path) }, content });
        if (props['Keep Source File'] !== 'true') env.deleteFile(proc.name, path);
      }
    });
    if (!outFFs.length) outFFs.push({ attributes: { filename: 'empty.dat', path: dir }, content: '' });
    return outFFs;
  },
  FetchFile: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    return inputFF.map(ff => {
      const fname = ff.attributes.filename || props['filename'] || props['File to Fetch'] || 'data.csv';
      let filePath;
      if (ff.attributes['absolute.path']) {
        const absPath = ff.attributes['absolute.path'].replace(/\/$/, '');
        filePath = isDbx ? `/Volumes/fetch/${absPath.split('/').pop()}/${fname}` : `${absPath}/${fname}`;
      } else {
        const dir = isDbx ? `/Volumes/fetch/${proc.group.replace(/\s+/g,'_').toLowerCase()}` : (props['Input Directory'] || `/data/fetch/${proc.group.replace(/\s+/g,'_').toLowerCase()}`);
        filePath = `${dir}/${fname}`;
      }
      const content = env.readFile(proc.name, filePath) || ff.content;
      return { attributes: { ...ff.attributes, 'fetch.status': 'ok', 'fetch.path': filePath }, content };
    });
  },
  ListFile: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const dir = isDbx ? `/Volumes/list/${proc.group.replace(/\s+/g,'_').toLowerCase()}` : (props['Input Directory'] || `/data/list/${proc.group.replace(/\s+/g,'_').toLowerCase()}`);
    const filter = props['File Filter'] || '';
    const files = env.listFiles(proc.name, dir);
    const outFFs = [];
    files.forEach(path => {
      if (path.endsWith('/.marker')) return;
      const fname = path.split('/').pop();
      if (filter) { try { if (!new RegExp(filter).test(fname)) return; } catch(e) {} }
      const entry = env.filesystem[path];
      outFFs.push({ attributes: { filename: fname, path, 'absolute.path': dir + '/', 'file.size': entry ? String(entry.size || 0) : '0', 'file.lastModifiedTime': entry ? (entry.modified || new Date().toISOString()) : new Date().toISOString() }, content: '' });
    });
    if (!outFFs.length) outFFs.push({ attributes: { filename: 'empty', path: dir, 'absolute.path': dir + '/' }, content: '' });
    return outFFs;
  },
  PutFile: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const dir = isDbx ? `/Volumes/output/${proc.group.replace(/\s+/g,'_').toLowerCase()}` : (props['Directory'] || `/data/output/${proc.group.replace(/\s+/g,'_').toLowerCase()}`);
    return inputFF.map(ff => {
      const fname = ff.attributes.filename || `output_${simHash(ff.content.substring(0, 20))}.dat`;
      env.writeFile(proc.name, `${dir}/${fname}`, ff.content, ff.attributes.format || 'raw');
      return { attributes: { ...ff.attributes, 'put.status': 'ok', 'put.path': `${dir}/${fname}` }, content: ff.content };
    });
  },
  PutSFTP: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const host = props['Hostname'] || props['hostname'] || 'sftp.example.com';
    const remotePath = evaluateNiFiEL(props['Remote Path'] || 'upload', inputFF[0] ? inputFF[0].attributes : {});
    const dir = isDbx ? `/Volumes/sftp/${host}/${remotePath}` : `/sftp/${host}/${remotePath}`;
    return inputFF.map(ff => {
      let fname = ff.attributes.filename || 'uploaded.dat';
      if (fname.includes('${')) fname = evaluateNiFiEL(fname, ff.attributes);
      env.writeFile(proc.name, `${dir}/${fname}`, ff.content, 'raw');
      return { attributes: { ...ff.attributes, 'sftp.status': 'ok', 'sftp.host': host, 'sftp.remote.path': remotePath, 'sftp.path': `${dir}/${fname}` }, content: ff.content };
    });
  },
  PutHDFS: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const dir = isDbx ? `/Volumes/hdfs/${proc.group.replace(/\s+/g,'_').toLowerCase()}` : (props['Directory'] || props['directory'] || `/hdfs/output/${proc.group.replace(/\s+/g,'_').toLowerCase()}`);
    return inputFF.map(ff => {
      let fname = ff.attributes.filename || `hdfs_${simHash((ff.content || '').substring(0, 20))}.dat`;
      if (fname.includes('${')) fname = evaluateNiFiEL(fname, ff.attributes);
      env.writeFile(proc.name, `${dir}/${fname}`, ff.content, ff.attributes.format || 'raw');
      return { attributes: { ...ff.attributes, 'hdfs.status': 'ok', 'hdfs.path': `${dir}/${fname}` }, content: ff.content };
    });
  },
  ExecuteSQL: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    let sql = props['SQL select query'] || props['sql-select-query'] || '';
    // Resolve parameterized table references: ${external_table} -> default name
    sql = sql.replace(/\$\{(\w+)\}/g, (m, name) => {
      const defaults = { external_table: 'ext_data', staging_table: 'stg_data', prod_table: 'prod_data' };
      return defaults[name] || name;
    });
    // Oracle dual table handling
    if (/\bFROM\s+dual\b/i.test(sql)) {
      const content = JSON.stringify([{ DUMMY: 'X' }]);
      return inputFF.map(ff => ({ attributes: { ...ff.attributes, 'executesql.row.count': '1', 'sql.table': 'dual' }, content }));
    }
    const tableMatch = sql.match(/(?:FROM|JOIN)\s+([a-zA-Z_][\w.]*)/i);
    const tName = tableMatch ? tableMatch[1] : null;
    let data = tName ? env.queryTable(proc.name, tName) : null;
    if (!data) { const tables = Object.keys(env.sqlTables); data = tables.length ? env.queryTable(proc.name, tables[0]) : null; }
    const content = data ? JSON.stringify(Object.keys(data).reduce((arr, col) => { data[col].forEach((v, i) => { if (!arr[i]) arr[i] = {}; arr[i][col] = v; }); return arr; }, [])) : '[]';
    return inputFF.map(ff => ({ attributes: { ...ff.attributes, 'executesql.row.count': data ? (data[Object.keys(data)[0]] || []).length.toString() : '0', 'sql.table': tName || '' }, content }));
  },
  PutDatabaseRecord: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const tName = props['Table Name'] || props['table-name'] || `${proc.group.replace(/\s+/g,'_').toLowerCase()}_target`;
    return inputFF.map(ff => {
      let data = {};
      try {
        const rows = JSON.parse(ff.content);
        if (Array.isArray(rows) && rows.length) {
          Object.keys(rows[0]).forEach(c => { data[c] = rows.map(r => r[c]); });
        }
      } catch(e) {
        // Try CSV parse
        const lines = ff.content.split('\n').filter(l => l.trim());
        if (lines.length > 1) {
          const headers = lines[0].split(',');
          headers.forEach(h => { data[h.trim()] = []; });
          lines.slice(1).forEach(line => {
            const vals = line.split(',');
            headers.forEach((h, i) => { data[h.trim()].push(vals[i] ? vals[i].trim() : null); });
          });
        }
      }
      if (Object.keys(data).length) env.insertRows(proc.name, tName, data);
      return { attributes: { ...ff.attributes, 'db.write.status': 'ok', 'db.table': tName, 'db.rows': Object.keys(data).length ? data[Object.keys(data)[0]].length.toString() : '0' }, content: ff.content };
    });
  },
  ExecuteStreamCommand: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const cmd = props['Command'] || '';
    const args = props['Command Arguments'] || props['command-arguments'] || '';
    // Read script if exists
    const scriptPath = cmd.startsWith('/') ? cmd : `/usr/local/bin/${cmd}`;
    env.readFile(proc.name, scriptPath);
    // Detect patterns and simulate
    const isClearOrRm = /\b(rm|clear|clean|purge|delete)\b/i.test(proc.name) || /\brm\s+(-rf?|-f)?\s/i.test(args) || /\brm\s+(-rf?|-f)?\s/i.test(cmd + ' ' + args);
    if (cmd === 'hdfs' || args.includes('dfs ')) {
      const pathArgs = args.match(/\/([\w/._-]+)/g) || [];
      if (args.includes('-cp') || args.includes('-mv')) {
        if (pathArgs.length >= 2) {
          const src = pathArgs[pathArgs.length - 2], dst = pathArgs[pathArgs.length - 1];
          const srcContent = env.readFile(proc.name, src);
          if (srcContent) env.writeFile(proc.name, dst, srcContent, 'csv');
          if (args.includes('-mv')) env.deleteFile(proc.name, src);
        }
      } else if (args.includes('-rm')) {
        pathArgs.forEach(p => env.deleteFile(proc.name, p));
      } else if (args.includes('-ls')) {
        const pathArgs2 = args.match(/\/([\w/._-]+)/g) || [];
        pathArgs2.forEach(p => env.listFiles(proc.name, p));
      }
    } else if (isClearOrRm) {
      // Handle rm/clear/clean/purge commands
      const pathArgs = args.match(/\/([\w/._-]+)/g) || (cmd + ' ' + args).match(/\/([\w/._-]+)/g) || [];
      pathArgs.forEach(p => {
        const files = env.listFiles(proc.name, p);
        files.forEach(f => env.deleteFile(proc.name, f));
        env.deleteFile(proc.name, p);
      });
      if (isDbx) {
        // Databricks equivalent: dbutils.fs.rm(path, recurse=True)
        pathArgs.forEach(p => env.deleteFile(proc.name, `/Volumes${p}`));
      }
    } else if (cmd.includes('impala') || args.includes('REFRESH') || args.includes('INVALIDATE')) {
      const tableMatch = args.match(/(?:REFRESH|INVALIDATE\s+METADATA)\s+(\S+)/i);
      if (tableMatch && env.sqlTables[tableMatch[1]]) env.queryTable(proc.name, tableMatch[1]);
    } else if (cmd.includes('kinit')) {
      env.acquireToken(proc.name, 'kerberos_' + proc.name.replace(/\s+/g,'_'));
    }
    // Write command output
    const outputContent = `exit_code=0\nstdout=Command completed: ${cmd} ${args}\n`;
    env.writeFile(proc.name, `/tmp/cmd_output/${proc.name.replace(/\s+/g,'_')}.out`, outputContent, 'raw');
    return inputFF.map(ff => ({ attributes: { ...ff.attributes, 'execution.status': '0', 'execution.command': cmd }, content: ff.content || outputContent }));
  },
  RouteOnAttribute: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const routeProps = {};
    Object.entries(props).forEach(([k, v]) => { if (k !== 'Routing Strategy') routeProps[k] = v; });
    const routes = Object.keys(routeProps);
    if (!routes.length) return inputFF;
    return inputFF.map(ff => {
      let matchedRoute = 'unmatched';
      for (const routeName of routes) {
        const expr = routeProps[routeName];
        const result = evaluateNiFiEL(expr, ff.attributes);
        if (result === 'true' || result === routeName) { matchedRoute = routeName; break; }
      }
      return { attributes: { ...ff.attributes, 'route': matchedRoute, 'route.expression': routeProps[matchedRoute] || '' }, content: ff.content };
    });
  },
  UpdateAttribute: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    return inputFF.map(ff => {
      const newAttrs = { ...ff.attributes };
      Object.entries(props).forEach(([k, v]) => {
        if (k === 'Delete Attributes Expression' || k === 'Store State') return;
        newAttrs[k] = v.includes('${') ? evaluateNiFiEL(v, ff.attributes) : v;
      });
      return { attributes: newAttrs, content: ff.content };
    });
  },
  ReplaceText: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const search = props['Search Value'] || props['search-value'] || '';
    const replace = props['Replacement Value'] || props['replacement-value'] || '';
    const strategy = props['Replacement Strategy'] || 'Regex Replace';
    return inputFF.map(ff => {
      let content = ff.content;
      if (search && strategy === 'Literal Replace') content = content.split(search).join(replace);
      else if (search) { try { content = content.replace(new RegExp(search, 'g'), replace); } catch(e) {} }
      else if (replace) content = replace; // Entire content replacement
      return { attributes: { ...ff.attributes, 'replace.status': 'ok' }, content };
    });
  },
  MergeContent: function(env, proc, inputFF, isDbx) {
    if (inputFF.length <= 1) return inputFF;
    const merged = inputFF.map(ff => ff.content).join('\n');
    return [{ attributes: { ...inputFF[0].attributes, 'merge.count': inputFF.length.toString(), 'merge.bin.age': '0' }, content: merged }];
  },
  SplitContent: function(env, proc, inputFF, isDbx) {
    const outFFs = [];
    inputFF.forEach(ff => {
      const lines = ff.content.split('\n').filter(l => l.trim());
      if (lines.length <= 1) { outFFs.push(ff); return; }
      // Split into chunks (header + groups of lines)
      const header = lines[0];
      const chunkSize = Math.max(1, Math.ceil((lines.length - 1) / 3));
      for (let i = 1; i < lines.length; i += chunkSize) {
        const chunk = lines.slice(i, i + chunkSize);
        outFFs.push({ attributes: { ...ff.attributes, 'split.index': Math.floor((i - 1) / chunkSize).toString(), 'fragment.count': Math.ceil((lines.length - 1) / chunkSize).toString() }, content: header + '\n' + chunk.join('\n') });
      }
    });
    return outFFs.length ? outFFs : inputFF;
  },
  ConvertRecord: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const targetFormat = (props['output-format'] || props['Record Writer'] || '').toLowerCase().includes('json') ? 'json' : 'csv';
    return inputFF.map(ff => {
      let content = ff.content;
      try {
        // Try parsing as JSON -> convert to CSV or vice versa
        const parsed = JSON.parse(ff.content);
        if (Array.isArray(parsed) && parsed.length && targetFormat === 'csv') {
          const cols = Object.keys(parsed[0]);
          content = cols.join(',') + '\n' + parsed.map(r => cols.map(c => r[c] ?? '').join(',')).join('\n');
        }
      } catch(e) {
        // Try CSV -> JSON
        if (targetFormat === 'json') {
          const lines = ff.content.split('\n').filter(l => l.trim());
          if (lines.length > 1) {
            const headers = lines[0].split(',').map(h => h.trim());
            const rows = lines.slice(1).map(l => { const vals = l.split(','); const obj = {}; headers.forEach((h, i) => { obj[h] = vals[i] ? vals[i].trim() : null; }); return obj; });
            content = JSON.stringify(rows);
          }
        }
      }
      return { attributes: { ...ff.attributes, 'convert.format': targetFormat }, content };
    });
  },
  EvaluateJsonPath: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    return inputFF.map(ff => {
      const newAttrs = { ...ff.attributes };
      try {
        const data = JSON.parse(ff.content);
        const target = Array.isArray(data) ? data[0] : data;
        if (target) {
          Object.entries(props).forEach(([k, v]) => {
            if (k === 'Destination' || k === 'Return Type' || k === 'Null Value Representation') return;
            // Simple JSONPath: $.field
            const field = v.replace(/^\$\.?/, '');
            if (field && target[field] !== undefined) newAttrs[k] = String(target[field]);
          });
        }
      } catch(e) {}
      return { attributes: newAttrs, content: ff.content };
    });
  },
  LogMessage: function(env, proc, inputFF, isDbx) {
    env.incrementCounter(proc.name, `log_${proc.name.replace(/\s+/g,'_')}`, inputFF.length);
    return inputFF; // passthrough
  },
  Wait: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const sigName = props['Signal Counter Name'] || props['Release Signal Identifier'] || `wait_${proc.name.replace(/\s+/g,'_').toLowerCase()}`;
    const target = parseInt(props['Target Signal Count']) || 1;
    // In simulation, signals are pre-released by Notify processors (via topo order)
    // Force release for simulation purposes
    if (!env.signals[sigName]) env.signals[sigName] = { count: 0, target, released: false };
    env.signals[sigName].count = env.signals[sigName].target; // simulate signal received
    env.signals[sigName].released = true;
    env.waitSignal(proc.name, sigName, target);
    return inputFF;
  },
  Notify: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const sigName = props['Signal Counter Name'] || props['Release Signal Identifier'] || `notify_${proc.name.replace(/\s+/g,'_').toLowerCase()}`;
    env.sendSignal(proc.name, sigName, inputFF.length || 1);
    return inputFF;
  },
  ControlRate: function(env, proc, inputFF, isDbx) {
    const tokenName = `rate_${proc.name.replace(/\s+/g,'_').toLowerCase()}`;
    env.acquireToken(proc.name, tokenName);
    env.releaseToken(proc.name, tokenName);
    return inputFF;
  },
  GenerateFlowFile: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const content = props['Custom Text'] || props['custom-text'] || 'generated-content';
    const size = parseInt(props['File Size']) || content.length;
    const batchSize = parseInt(props['Batch Size']) || 1;
    const outFFs = [];
    for (let i = 0; i < batchSize; i++) {
      outFFs.push({ attributes: { filename: `generated_${proc.name.replace(/\s+/g,'_')}_${i}.dat`, 'mime.type': props['Mime Type'] || 'application/octet-stream', uuid: 'ff_gen_' + simHash(proc.name + i) }, content });
    }
    return outFFs;
  },
  InvokeHTTP: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const url = props['Remote URL'] || props['HTTP URL'] || 'http://api.example.com/data';
    // Read cached response from seed
    const respPath = `/tmp/http_responses/${proc.name.replace(/\s+/g,'_')}.json`;
    const responseContent = env.readFile(proc.name, respPath) || '{"status":"ok"}';
    return inputFF.map(ff => ({ attributes: { ...ff.attributes, 'invokehttp.status.code': '200', 'invokehttp.status.message': 'OK', 'invokehttp.request.url': url }, content: responseContent }));
  },
  LookupAttribute: function(env, proc, inputFF, isDbx) {
    const props = proc.properties || {};
    const lookupTable = props['lookup-table'] || props['Lookup Table'] || `lookup_${proc.name.replace(/\s+/g,'_').toLowerCase()}`;
    const data = env.queryTable(proc.name, lookupTable);
    return inputFF.map(ff => {
      const newAttrs = { ...ff.attributes, 'lookup.found': 'true' };
      if (data) {
        Object.keys(data).forEach(c => { if (data[c] && data[c][0] !== undefined) newAttrs['lookup.' + c] = String(data[c][0]); });
      }
      return { attributes: newAttrs, content: ff.content };
    });
  }
};

// Dispatch to PROCESSOR_SIM_V2 by type, fallback by role
function simV2Dispatch(env, proc, inputFF, isDbx) {
  const fn = PROCESSOR_SIM_V2[proc.type];
  if (fn) return fn(env, proc, inputFF, isDbx);
  // Role-based fallback
  const role = classifyNiFiProcessor(proc.type);
  if (role === 'source') return PROCESSOR_SIM_V2.GetFile(env, proc, inputFF, isDbx);
  if (role === 'sink') return PROCESSOR_SIM_V2.PutFile(env, proc, inputFF, isDbx);
  if (role === 'route') return PROCESSOR_SIM_V2.RouteOnAttribute(env, proc, inputFF, isDbx);
  if (role === 'transform') return PROCESSOR_SIM_V2.ReplaceText(env, proc, inputFF, isDbx);
  if (role === 'process') return PROCESSOR_SIM_V2.ExecuteSQL(env, proc, inputFF, isDbx);
  // Default: passthrough
  return inputFF;
}

// ================================================================
// FLOWFILE <-> COLUMNAR BRIDGE
// ================================================================
function flowfilesToColumnar(flowfiles) {
  if (!flowfiles || !flowfiles.length) return {};
  // Try to parse content as structured data
  const first = flowfiles[0];
  if (first.content) {
    try {
      const parsed = JSON.parse(first.content);
      if (Array.isArray(parsed) && parsed.length) {
        const cols = {};
        Object.keys(parsed[0]).forEach(c => { cols[c] = parsed.map(r => r[c]); });
        return cols;
      }
    } catch(e) {}
    // Try CSV
    const lines = first.content.split('\n').filter(l => l.trim());
    if (lines.length > 1) {
      const headers = lines[0].split(',').map(h => h.trim());
      if (headers.length > 1 && headers.every(h => h.length > 0)) {
        const cols = {};
        headers.forEach(h => { cols[h] = []; });
        // Combine all flowfiles
        flowfiles.forEach(ff => {
          const flines = ff.content.split('\n').filter(l => l.trim());
          flines.slice(1).forEach(line => {
            const vals = line.split(',');
            headers.forEach((h, i) => { cols[h].push(vals[i] ? vals[i].trim() : null); });
          });
        });
        return cols;
      }
    }
  }
  // Fallback: attributes-based columnar
  const cols = { _ff_index: [], _ff_filename: [], _ff_content_size: [] };
  const attrKeys = new Set();
  flowfiles.forEach(ff => Object.keys(ff.attributes).forEach(k => attrKeys.add(k)));
  attrKeys.forEach(k => { cols['attr_' + k] = []; });
  flowfiles.forEach((ff, i) => {
    cols._ff_index.push(i);
    cols._ff_filename.push(ff.attributes.filename || `ff_${i}`);
    cols._ff_content_size.push(ff.content ? ff.content.length : 0);
    attrKeys.forEach(k => { cols['attr_' + k].push(ff.attributes[k] || null); });
  });
  return cols;
}

function columnarToFlowfiles(columnar, format) {
  if (!columnar || !Object.keys(columnar).length) return [{ attributes: {}, content: '' }];
  const cols = Object.keys(columnar);
  const rc = columnar[cols[0]] ? columnar[cols[0]].length : 0;
  if (!rc) return [{ attributes: {}, content: '' }];
  const rows = [];
  for (let i = 0; i < rc; i++) { const row = {}; cols.forEach(c => { row[c] = columnar[c][i]; }); rows.push(row); }
  const content = format === 'json' ? JSON.stringify(rows) : (cols.join(',') + '\n' + rows.map(r => cols.map(c => r[c] ?? '').join(',')).join('\n'));
  return [{ attributes: { filename: 'data.' + (format || 'csv'), 'record.count': rc.toString() }, content }];
}

function simulateEngine(engineName, processors, connections, tables, mappings, env) {
  const {order, adj} = topoSortProcessors(processors, connections);
  const incoming = Array.from({length:processors.length}, () => []);
  adj.forEach((neighbors, src) => { neighbors.forEach(dst => { incoming[dst].push(src); }); });
  const isDbx = engineName === 'databricks';
  // Per-group data pools
  const groupPools = {};
  const groups = [...new Set(processors.map(p => p.group))];
  groups.forEach(g => {
    const gProcs = processors.filter(p => p.group === g);
    groupPools[g] = generateGroupDataPool(g, gProcs, tables);
  });
  // FlowFile outputs per processor (index-based)
  const ffOutputs = new Array(processors.length);
  const results = new Array(processors.length);
  const errors = [];
  const useV2 = !!env; // Use VirtualEnv-based sim if env provided

  for (const idx of order) {
    const proc = processors[idx];
    const mapping = mappings[idx] || {};
    const role = classifyNiFiProcessor(proc.type);
    // Take snapshot before this processor
    const snapBefore = useV2 ? env.snapshot() : null;
    // Gather input FlowFiles from upstream
    const inc = incoming[idx];
    let inputFF = [];
    if (useV2) {
      inc.forEach(srcIdx => {
        if (ffOutputs[srcIdx]) inputFF = inputFF.concat(ffOutputs[srcIdx]);
      });
      // If no upstream FFs, create from group pool
      if (!inputFF.length) {
        const pool = groupPools[proc.group] || {};
        if (Object.keys(pool).length) {
          inputFF = columnarToFlowfiles(pool, 'csv');
        } else {
          inputFF = [{ attributes: { filename: 'default.dat' }, content: '' }];
        }
      }
    }
    // Gather columnar input for backward compat
    let inputData = null;
    if (inc.length === 1 && results[inc[0]] && results[inc[0]].output) {
      inputData = deepCopyColumnar(results[inc[0]].output);
    } else if (inc.length > 1) {
      const merged = {};
      inc.forEach(srcIdx => {
        const d = results[srcIdx] ? results[srcIdx].output : null; if (!d) return;
        Object.keys(d).forEach(c => { if (!merged[c]) merged[c] = []; merged[c] = merged[c].concat(d[c]); });
      });
      inputData = Object.keys(merged).length ? merged : null;
    }
    if (!inputData || !Object.keys(inputData).length) {
      if (role !== 'source') inputData = deepCopyColumnar(groupPools[proc.group] || {});
    }
    // Skip unmapped in Databricks
    if (isDbx && mapping && !mapping.mapped) {
      ffOutputs[idx] = inputFF;
      const oc = inputData ? Object.keys(inputData) : [];
      const rc = oc.length && inputData[oc[0]] ? inputData[oc[0]].length : 0;
      results[idx] = { output: inputData, rows: rc, cols: oc.length, status: 'skipped', name: proc.name, group: proc.group, actions: [], inputFF, outputFF: inputFF };
      continue;
    }
    let outputFF, output;
    try {
      if (useV2) {
        outputFF = simV2Dispatch(env, proc, inputFF, isDbx);
        output = flowfilesToColumnar(outputFF);
      } else {
        const simFn = PROCESSOR_SIM[role] || PROCESSOR_SIM.utility;
        output = simFn(inputData, proc, tables, groupPools[proc.group]);
        outputFF = inputFF;
      }
    } catch(e) {
      output = inputData || deepCopyColumnar(groupPools[proc.group] || {});
      outputFF = inputFF;
      errors.push({idx, name: proc.name, error: e.message});
    }
    // Ensure output never empty
    if (!output || !Object.keys(output).length) {
      output = deepCopyColumnar(groupPools[proc.group] || {});
      if (useV2 && (!outputFF || !outputFF.length)) outputFF = columnarToFlowfiles(output, 'csv');
    }
    // Databricks confidence-based differences
    if (isDbx && mapping && mapping.mapped && output && Object.keys(output).length) {
      const oc = Object.keys(output);
      const rc = oc.length && output[oc[0]] ? output[oc[0]].length : 0;
      if (rc > 0 && mapping.confidence >= 0.50 && mapping.confidence < 0.80) {
        output['_dbx_processed'] = Array(rc).fill(proc.type);
      }
      if (rc > 0 && mapping.confidence < 0.50 && mapping.mapped) {
        output['_dbx_review'] = Array(rc).fill('NEEDS_REVIEW');
        const keepN = Math.max(1, Math.ceil(rc * Math.max(0.5, mapping.confidence)));
        Object.keys(output).forEach(c => { output[c] = output[c].slice(0, keepN); });
      }
    }
    ffOutputs[idx] = outputFF;
    const snapAfter = useV2 ? env.snapshot() : null;
    const procActions = useV2 ? env.getProcessorActions(proc.name) : [];
    const oc = output ? Object.keys(output) : [];
    const rc = oc.length && output[oc[0]] ? output[oc[0]].length : 0;
    results[idx] = {
      output, rows: rc, cols: oc.length, status: 'ok', name: proc.name, group: proc.group,
      actions: procActions, inputFF: useV2 ? inputFF : null, outputFF: useV2 ? outputFF : null,
      snapBefore, snapAfter
    };
  }
  return { results, order, errors, groupCount: groups.length, groupPools, env };
}

function compareSimOutputs(nifiOut, dbxOut) {
  if (!nifiOut || !dbxOut) return { rowMatch: 0, schemaMatch: 0, dataFidelity: 0, details: 'Missing output' };
  const nC = Object.keys(nifiOut), dC = Object.keys(dbxOut);
  if (!nC.length && !dC.length) return { rowMatch: 100, schemaMatch: 100, dataFidelity: 100, details: 'Both empty' };
  const common = nC.filter(c => dC.includes(c));
  const schemaMatch = nC.length ? Math.round(common.length / nC.length * 100) : 100;
  const nR = nC.length ? (nifiOut[nC[0]] || []).length : 0;
  const dR = dC.length ? (dbxOut[dC[0]] || []).length : 0;
  const rowMatch = Math.max(nR, dR) ? Math.round(Math.min(nR, dR) / Math.max(nR, dR) * 100) : 100;
  let mc = 0, tc = 0;
  common.forEach(c => {
    const mr = Math.min(nR, dR);
    for (let i = 0; i < mr; i++) { tc++; if (String(nifiOut[c][i]) === String(dbxOut[c][i])) mc++; }
  });
  const dataFidelity = tc ? Math.round(mc / tc * 100) : 100;
  const extra = dC.filter(c => !nC.includes(c));
  let details = `${common.length}/${nC.length} cols shared`;
  if (extra.length) details += `, +${extra.length} DBX cols`;
  return { rowMatch, schemaMatch, dataFidelity, details };
}

function compareActions(nifiActions, dbxActions) {
  if (!nifiActions.length && !dbxActions.length) return { matched: 0, mismatched: 0, coverage: 100 };
  // Normalize path for comparison (strip /Volumes prefix, /sftp vs /Volumes/sftp etc.)
  function normTarget(t) { return (t || '').replace(/^\/Volumes\//,'/').replace(/^\/Volumes/,'/').replace(/\/+/g,'/'); }
  const nTypes = nifiActions.map(a => a.action + ':' + normTarget(a.target));
  const dTypes = dbxActions.map(a => a.action + ':' + normTarget(a.target));
  let matched = 0;
  const used = new Set();
  nTypes.forEach(nt => {
    // Exact match first
    let idx = dTypes.findIndex((dt, i) => !used.has(i) && dt === nt);
    if (idx < 0) {
      // Fuzzy match: same action type, target ends with same filename
      const [nAct, nTgt] = nt.split(':');
      const nFile = (nTgt || '').split('/').pop();
      idx = dTypes.findIndex((dt, i) => {
        if (used.has(i)) return false;
        const [dAct, dTgt] = dt.split(':');
        return nAct === dAct && (dTgt || '').split('/').pop() === nFile;
      });
    }
    if (idx >= 0) { matched++; used.add(idx); }
  });
  const total = Math.max(nTypes.length, dTypes.length);
  return { matched, mismatched: total - matched, coverage: total ? Math.round(matched / total * 100) : 100, nifiCount: nTypes.length, dbxCount: dTypes.length };
}

function compareStateDiffs(nifiSnaps, dbxSnaps) {
  if (!nifiSnaps || !dbxSnaps) return { filesMatch: true, tablesMatch: true, tokensMatch: true, signalsMatch: true, overall: 100 };
  let score = 0, total = 0;
  // Normalize path for comparison
  function normPath(p) { return p.replace(/^\/Volumes\//,'/').replace(/\/+/g,'/'); }
  // Compare filesystem changes (count-based with path normalization)
  const nFileKeys = Object.keys(nifiSnaps.after ? nifiSnaps.after.filesystem : {}).map(normPath);
  const dFileKeys = Object.keys(dbxSnaps.after ? dbxSnaps.after.filesystem : {}).map(normPath);
  const nFileSet = new Set(nFileKeys), dFileSet = new Set(dFileKeys);
  const commonFiles = nFileKeys.filter(f => dFileSet.has(f)).length;
  const filesMatch = nFileSet.size > 0 ? (commonFiles / Math.max(nFileSet.size, dFileSet.size)) >= 0.7 : nFileSet.size === dFileSet.size;
  total++; if (filesMatch) score++;
  // Compare SQL table changes
  const nTables = nifiSnaps.after ? nifiSnaps.after.sqlTables : {};
  const dTables = dbxSnaps.after ? dbxSnaps.after.sqlTables : {};
  const tablesMatch = JSON.stringify(Object.keys(nTables).sort()) === JSON.stringify(Object.keys(dTables).sort());
  total++; if (tablesMatch) score++;
  // Compare tokens
  const tokensMatch = JSON.stringify(nifiSnaps.after ? nifiSnaps.after.tokens : {}) === JSON.stringify(dbxSnaps.after ? dbxSnaps.after.tokens : {});
  total++; if (tokensMatch) score++;
  // Compare signals
  const signalsMatch = JSON.stringify(nifiSnaps.after ? nifiSnaps.after.signals : {}) === JSON.stringify(dbxSnaps.after ? dbxSnaps.after.signals : {});
  total++; if (signalsMatch) score++;
  return { filesMatch, tablesMatch, tokensMatch, signalsMatch, overall: total ? Math.round(score / total * 100) : 100 };
}

function computeDualSimulation(nifiResults, dbxResults, order, mappings, processors, nifiEnv, dbxEnv) {
  let tRM = 0, tSM = 0, tDF = 0, tAC = 0, tSF = 0, cnt = 0, cntAction = 0;
  const perProc = [];
  const hasEnv = !!nifiEnv && !!dbxEnv;
  for (const idx of order) {
    const nr = nifiResults[idx], dr = dbxResults[idx];
    if (!nr) continue;
    const mapping = mappings[idx] || {};
    const proc = processors[idx] || {};
    const cmp = compareSimOutputs(nr.output, dr ? dr.output : null);
    // Action comparison
    const nActions = nr.actions || [];
    const dActions = dr ? (dr.actions || []) : [];
    const actionCmp = compareActions(nActions, dActions);
    // State diff comparison
    const stateCmp = (nr.snapBefore && nr.snapAfter && dr && dr.snapBefore && dr.snapAfter) ?
      compareStateDiffs({ before: nr.snapBefore, after: nr.snapAfter }, { before: dr.snapBefore, after: dr.snapAfter }) :
      { filesMatch: true, tablesMatch: true, tokensMatch: true, signalsMatch: true, overall: 100 };
    // Verdicts
    let dataVerdict, actionVerdict, stateVerdict, verdict, verdictClass;
    if (dr && dr.status === 'skipped') {
      dataVerdict = actionVerdict = stateVerdict = verdict = 'SKIPPED'; verdictClass = 'match-gap';
    } else {
      dataVerdict = (cmp.dataFidelity >= 95 && cmp.rowMatch >= 95 && cmp.schemaMatch >= 95) ? 'IDENTICAL' : cmp.dataFidelity >= 70 ? 'EQUIVALENT' : 'DIFFERS';
      actionVerdict = actionCmp.coverage >= 95 ? 'IDENTICAL' : actionCmp.coverage >= 70 ? 'EQUIVALENT' : 'DIFFERS';
      stateVerdict = stateCmp.overall >= 95 ? 'IDENTICAL' : stateCmp.overall >= 70 ? 'EQUIVALENT' : 'DIFFERS';
      // Overall = worst of the three
      if (dataVerdict === 'IDENTICAL' && actionVerdict === 'IDENTICAL' && stateVerdict === 'IDENTICAL') { verdict = 'IDENTICAL'; verdictClass = 'match-exact'; }
      else if (dataVerdict !== 'DIFFERS' && actionVerdict !== 'DIFFERS' && stateVerdict !== 'DIFFERS') { verdict = 'EQUIVALENT'; verdictClass = 'match-functional'; }
      else { verdict = 'DIFFERS'; verdictClass = 'match-gap'; }
    }
    perProc.push({
      idx, name: proc.name || nr.name, type: (proc.type || mapping.type || ''),
      group: proc.group || nr.group || '', role: mapping.role || classifyNiFiProcessor(proc.type || ''),
      confidence: mapping.confidence || 0, mapped: mapping.mapped !== false,
      nifiRows: nr.rows, nifiCols: nr.cols,
      dbxRows: dr ? dr.rows : 0, dbxCols: dr ? dr.cols : 0,
      rowMatch: cmp.rowMatch, schemaMatch: cmp.schemaMatch, dataFidelity: cmp.dataFidelity,
      dataVerdict, actionVerdict, stateVerdict,
      verdict, verdictClass, details: cmp.details,
      nifiOutput: nr.output, dbxOutput: dr ? dr.output : null,
      actions: { nifi: nActions, dbx: dActions, matched: actionCmp.matched, mismatched: actionCmp.mismatched, coverage: actionCmp.coverage },
      stateDiff: stateCmp,
      nifiActions: nActions, dbxActions: dActions
    });
    if (verdict !== 'SKIPPED') {
      tRM += cmp.rowMatch; tSM += cmp.schemaMatch; tDF += cmp.dataFidelity; cnt++;
      tAC += actionCmp.coverage; tSF += stateCmp.overall; cntAction++;
    }
  }
  return {
    perProc,
    rowMatchPct: cnt ? Math.round(tRM / cnt) : 0,
    schemaMatchPct: cnt ? Math.round(tSM / cnt) : 0,
    fidelityPct: cnt ? Math.round(tDF / cnt) : 0,
    actionCoveragePct: cntAction ? Math.round(tAC / cntAction) : 0,
    stateFidelityPct: cntAction ? Math.round(tSF / cntAction) : 0,
    functionalEquivPct: cnt ? Math.round((tRM + tSM + tDF + tAC + tSF) / (cnt * 3 + cntAction * 2)) : 0,
    summary: {
      total: perProc.length,
      identical: perProc.filter(p => p.verdict === 'IDENTICAL').length,
      equivalent: perProc.filter(p => p.verdict === 'EQUIVALENT').length,
      differs: perProc.filter(p => p.verdict === 'DIFFERS').length,
      skipped: perProc.filter(p => p.verdict === 'SKIPPED').length
    },
    envSummary: hasEnv ? { nifi: nifiEnv.getSummary(), dbx: dbxEnv.getSummary() } : null
  };
}

function columnarPreview(data, maxRows) {
  maxRows = maxRows || 5;
  if (!data || !Object.keys(data).length) return '<em style="color:var(--text2)">No data</em>';
  const cols = Object.keys(data);
  const rc = data[cols[0]] ? data[cols[0]].length : 0;
  if (!rc) return '<em style="color:var(--text2)">0 rows</em>';
  let h = '<div class="table-scroll"><table style="font-size:0.72rem"><thead><tr>';
  cols.slice(0,8).forEach(c => { h += `<th>${c}</th>`; });
  if (cols.length > 8) h += '<th style="color:var(--text2)">+' + (cols.length-8) + '</th>';
  h += '</tr></thead><tbody>';
  for (let i = 0; i < Math.min(rc, maxRows); i++) {
    h += '<tr>'; cols.slice(0,8).forEach(c => { const v = data[c][i]; h += `<td>${v == null ? '<span style="color:var(--text2)">null</span>' : String(v).substring(0, 30)}</td>`; });
    if (cols.length > 8) h += '<td style="color:var(--text2)">...</td>';
    h += '</tr>';
  }
  if (rc > maxRows) { h += '<tr>'; cols.slice(0,8).forEach(() => { h += '<td style="color:var(--text2)">...</td>'; }); if (cols.length > 8) h += '<td></td>'; h += '</tr>'; }
  h += '</tbody></table></div>';
  h += `<div style="font-size:0.7rem;color:var(--text2);margin-top:4px">${rc} rows, ${cols.length} columns</div>`;
  return h;
}

async function runDualSimulation() {
  if (!STATE.notebook || !STATE.parsed || !STATE.parsed._nifi || !STATE.tables) return;
  setTabStatus('simulate', 'processing');
  const nifi = STATE.parsed._nifi;
  const tables = STATE.tables;
  const mappings = STATE.notebook.mappings;
  const rDiv = document.getElementById('simulateResults');
  const hasVenv = !!STATE.virtualEnv;
  // Progress UI
  let h = '<div class="sim-progress" id="simProgressBox">';
  h += '<div class="sim-status"><span class="engine-label sim-running" id="simEngineLabel">Initializing simulation engines...</span><span id="simPctLabel">0%</span></div>';
  h += '<div class="sim-progress-bar"><div class="sim-progress-fill" id="simFill" style="width:0%"></div></div>';
  h += '<div id="simStepLabel" style="font-size:0.78rem;color:var(--text2);margin-top:4px"></div>';
  h += '</div>';
  rDiv.innerHTML = h;
  const fill = document.getElementById('simFill');
  const pctL = document.getElementById('simPctLabel');
  const stepL = document.getElementById('simStepLabel');
  const engL = document.getElementById('simEngineLabel');
  async function prog(pct, label) {
    fill.style.width = pct + '%'; pctL.textContent = pct + '%'; stepL.textContent = label;
    await new Promise(r => setTimeout(r, 120));
  }
  const procCount = nifi.processors.length;
  // Prepare VirtualEnv instances (fresh copies for simulation)
  let nifiEnv = null, dbxEnv = null;
  if (hasVenv) {
    await prog(3, 'Building VirtualEnv instances...');
    const seed = buildInitialVirtualEnv(nifi, tables, STATE.manifest);
    nifiEnv = seed.env;
    const seed2 = buildInitialVirtualEnv(nifi, tables, STATE.manifest);
    dbxEnv = seed2.env;
  }
  // Phase 1: NiFi
  await prog(5, hasVenv ? 'Building processor DAG + VirtualEnv...' : 'Building processor DAG...');
  engL.textContent = 'Running NiFi simulation engine...'; engL.style.color = '#728E9B';
  await prog(15, `Executing ${procCount} processors ${hasVenv ? 'with file I/O, SQL, tokens...' : 'in topological order...'}`);
  const nifiSim = simulateEngine('nifi', nifi.processors, nifi.connections, tables, mappings, nifiEnv);
  const nifiExec = nifiSim.results.filter(r => r && r.status === 'ok').length;
  const nifiActions = nifiEnv ? nifiEnv.log.length : 0;
  await prog(40, `NiFi complete — ${nifiExec}/${procCount} processors, ${nifiActions} actions across ${nifiSim.groupCount} groups`);
  // Phase 2: Databricks
  engL.textContent = 'Running Databricks simulation engine...'; engL.style.color = 'var(--primary)';
  await prog(55, `Executing ${procCount} processors via PySpark equivalents${hasVenv ? ' + VirtualEnv' : ''}...`);
  const dbxSim = simulateEngine('databricks', nifi.processors, nifi.connections, tables, mappings, dbxEnv);
  const dbxExec = dbxSim.results.filter(r => r && r.status === 'ok').length;
  const dbxSkip = dbxSim.results.filter(r => r && r.status === 'skipped').length;
  const dbxActions = dbxEnv ? dbxEnv.log.length : 0;
  await prog(75, `Databricks complete — ${dbxExec} executed, ${dbxSkip} skipped, ${dbxActions} actions`);
  // Phase 3: Compare
  engL.textContent = 'Comparing outputs + actions + state...'; engL.style.color = 'var(--text)';
  await prog(85, 'Computing data fidelity, action coverage, and state comparison...');
  const sim = computeDualSimulation(nifiSim.results, dbxSim.results, nifiSim.order, mappings, nifi.processors, nifiEnv, dbxEnv);
  STATE.simulation = sim;
  STATE.simulation._meta = {
    timestamp: new Date().toISOString(),
    processorCount: procCount,
    groupCount: nifiSim.groupCount,
    nifiExecuted: nifiExec, dbxExecuted: dbxExec, dbxSkipped: dbxSkip,
    nifiErrors: nifiSim.errors, dbxErrors: dbxSim.errors,
    nifiActions, dbxActions,
    hasVirtualEnv: hasVenv
  };
  if (nifiEnv) STATE.simulation._nifiEnv = nifiEnv;
  if (dbxEnv) STATE.simulation._dbxEnv = dbxEnv;
  await prog(100, 'Simulation complete');
  engL.textContent = 'Dual simulation complete'; engL.classList.remove('sim-running');
  // Render results
  h = '<hr class="divider">';
  // Row 1: Data donuts (existing)
  h += '<h3>Data Comparison</h3>';
  h += '<div class="sim-donuts">';
  h += donutSVG(sim.rowMatchPct, 'Row Match', `avg across ${sim.summary.total - sim.summary.skipped} procs`);
  h += donutSVG(sim.schemaMatchPct, 'Schema Match', `columns aligned`);
  h += donutSVG(sim.fidelityPct, 'Data Fidelity', `cell-level accuracy`);
  h += '</div>';
  // Row 2: Action donuts (new)
  if (hasVenv) {
    h += '<h3>Action & State Comparison</h3>';
    h += '<div class="sim-donuts">';
    h += donutSVG(sim.actionCoveragePct, 'Action Coverage', `${nifiActions} NiFi / ${dbxActions} DBX actions`);
    h += donutSVG(sim.stateFidelityPct, 'State Fidelity', `file/SQL/token match`);
    h += donutSVG(sim.functionalEquivPct, 'Functional Equiv', `weighted composite`);
    h += '</div>';
  }
  h += metricsHTML([
    ['Processors', sim.summary.total],
    ['Identical', `<span style="color:#21C354">${sim.summary.identical}</span>`],
    ['Equivalent', `<span style="color:#EAB308">${sim.summary.equivalent}</span>`],
    ['Differs', `<span style="color:#EF4444">${sim.summary.differs}</span>`],
    ['Skipped', `<span style="color:#808495">${sim.summary.skipped}</span>`]
  ]);
  h += '<div style="margin:12px 0;font-size:0.82rem;color:var(--text2)">';
  h += `<strong>${procCount}</strong> processors simulated across <strong>${nifiSim.groupCount}</strong> process groups`;
  if (hasVenv) h += ` &nbsp;|&nbsp; <strong>${nifiActions}</strong> NiFi actions, <strong>${dbxActions}</strong> DBX actions`;
  h += '</div>';
  if (nifiSim.errors.length || dbxSim.errors.length) {
    h += '<div class="alert alert-info" style="margin:8px 0;font-size:0.78rem">';
    h += `Simulation errors: ${nifiSim.errors.length} NiFi, ${dbxSim.errors.length} DBX — see Step 10 report for details`;
    h += '</div>';
  }
  // VirtualEnv Action Log Summary
  if (hasVenv && nifiEnv) {
    h += '<hr class="divider">';
    const nSummary = nifiEnv.getSummary();
    const dSummary = dbxEnv.getSummary();
    h += expanderHTML('<strong>VirtualEnv Final State</strong> — NiFi vs Databricks', (() => {
      let body = '<div class="state-diff">';
      body += '<div class="state-diff-panel"><h4 style="color:#728E9B">NiFi Engine</h4>';
      body += `<div style="font-size:0.78rem">Files: ${nSummary.files} (${nSummary.totalFileSize}B) | SQL Tables: ${nSummary.sqlTables} (${nSummary.totalSqlRows} rows) | Tokens: ${nSummary.tokens} | Signals: ${nSummary.signals} | Actions: ${nSummary.totalActions}</div>`;
      body += '</div>';
      body += '<div class="state-diff-panel"><h4 style="color:var(--primary)">Databricks Engine</h4>';
      body += `<div style="font-size:0.78rem">Files: ${dSummary.files} (${dSummary.totalFileSize}B) | SQL Tables: ${dSummary.sqlTables} (${dSummary.totalSqlRows} rows) | Tokens: ${dSummary.tokens} | Signals: ${dSummary.signals} | Actions: ${dSummary.totalActions}</div>`;
      body += '</div></div>';
      // Action type breakdown
      const nActTypes = {}, dActTypes = {};
      nifiEnv.log.forEach(e => { nActTypes[e.action] = (nActTypes[e.action] || 0) + 1; });
      dbxEnv.log.forEach(e => { dActTypes[e.action] = (dActTypes[e.action] || 0) + 1; });
      const allActTypes = [...new Set([...Object.keys(nActTypes), ...Object.keys(dActTypes)])].sort();
      body += '<div style="margin-top:12px"><strong style="font-size:0.82rem">Action Type Breakdown</strong></div>';
      body += '<div class="action-log" style="max-height:200px">';
      allActTypes.forEach(at => {
        const nC = nActTypes[at] || 0, dC = dActTypes[at] || 0;
        const match = nC === dC;
        const cls = at.startsWith('FILE') ? 'file-op' : at.startsWith('SQL') ? 'sql-op' : at.startsWith('TOKEN') ? 'token-op' : at.startsWith('SIGNAL') ? 'signal-op' : 'queue-op';
        body += `<div class="action-log-entry"><span class="action-type ${cls}">${at}</span><span>NiFi: ${nC}</span><span>DBX: ${dC} ${match ? '<span style="color:#21C354">&#10003;</span>' : '<span style="color:#EAB308">&ne;</span>'}</span></div>`;
      });
      body += '</div>';
      return body;
    })(), false);
    // Operations Log — NiFi
    h += expanderHTML(`<strong>Operations Log — NiFi Engine</strong> (${nifiEnv.log.length} actions)`, renderOperationsLog(nifiEnv, 'NiFi'), false);
    // Operations Log — Databricks
    h += expanderHTML(`<strong>Operations Log — Databricks Engine</strong> (${dbxEnv.log.length} actions)`, renderOperationsLog(dbxEnv, 'Databricks'), false);
    // Resource Usage
    h += expanderHTML('<strong>Resource Usage</strong> — seeded vs accessed', renderResourceUsage(STATE.manifest, nifiEnv, dbxEnv), false);
  }
  // Per-processor comparison grouped by process group
  h += '<hr class="divider">';
  const byGroup = {};
  sim.perProc.forEach(p => {
    const g = p.group || '(root)';
    if (!byGroup[g]) byGroup[g] = [];
    byGroup[g].push(p);
  });
  const groupNames = Object.keys(byGroup).sort();
  h += `<details class="comparison-detail" open><summary>Per-Processor Results — ${sim.perProc.length} processors in ${groupNames.length} groups</summary>`;
  h += '<div style="margin-top:8px">';
  groupNames.forEach(gn => {
    const gProcs = byGroup[gn];
    const gIdent = gProcs.filter(p => p.verdict === 'IDENTICAL').length;
    const gEquiv = gProcs.filter(p => p.verdict === 'EQUIVALENT').length;
    const gDiff = gProcs.filter(p => p.verdict === 'DIFFERS').length;
    const gSkip = gProcs.filter(p => p.verdict === 'SKIPPED').length;
    h += expanderHTML(
      `<strong>${gn}</strong> <span style="font-size:0.75rem;color:var(--text2)">(${gProcs.length} processors — `
      + `<span style="color:#21C354">${gIdent} identical</span>, `
      + `<span style="color:#EAB308">${gEquiv} equiv</span>, `
      + `<span style="color:#EF4444">${gDiff} diff</span>, `
      + `<span style="color:#808495">${gSkip} skip</span>)</span>`,
      gProcs.map((p, pidx) => {
        const roleColor = ROLE_TIER_COLORS[p.role] || '#808495';
        const confStr = p.mapped ? Math.round(p.confidence * 100) + '%' : '--';
        const confCls = p.confidence >= 0.8 ? 'conf-high' : p.confidence >= 0.5 ? 'conf-med' : p.confidence > 0 ? 'conf-low' : 'conf-none';
        let body = `<div style="display:flex;gap:12px;flex-wrap:wrap;margin-bottom:6px;font-size:0.76rem;color:var(--text2)">`;
        body += `<span>NiFi: ${p.nifiRows}r ${p.nifiCols}c</span>`;
        body += `<span>DBX: ${p.dbxRows}r ${p.dbxCols}c</span>`;
        body += `<span>Rows:${p.rowMatch}%</span><span>Schema:${p.schemaMatch}%</span><span>Fidelity:${p.dataFidelity}%</span>`;
        if (p.actions && p.actions.coverage !== undefined) body += `<span>Actions:${p.actions.coverage}%</span>`;
        if (p.stateDiff) body += `<span>State:${p.stateDiff.overall}%</span>`;
        body += `</div>`;
        // Action log for this processor
        if (p.nifiActions && p.nifiActions.length) {
          body += '<div style="margin:6px 0"><strong style="font-size:0.75rem">Actions performed:</strong></div>';
          body += '<div class="action-log" style="max-height:150px">';
          p.nifiActions.slice(0, 20).forEach(a => {
            const cls = a.action.startsWith('FILE') ? 'file-op' : a.action.startsWith('SQL') ? 'sql-op' : a.action.startsWith('TOKEN') ? 'token-op' : a.action.startsWith('SIGNAL') ? 'signal-op' : 'queue-op';
            body += `<div class="action-log-entry"><span class="action-type ${cls}">${a.action}</span><span>${a.target}</span><span style="font-size:0.72rem;color:var(--text2)">${a.after ? JSON.stringify(a.after).substring(0,60) : '—'}</span></div>`;
          });
          if (p.nifiActions.length > 20) body += `<div style="padding:4px 10px;font-size:0.72rem;color:var(--text2)">... +${p.nifiActions.length - 20} more actions</div>`;
          body += '</div>';
        }
        body += '<div class="sim-split">';
        body += '<div class="sim-split-header nifi-side">NiFi Output</div>';
        body += '<div class="sim-split-header dbx-side">Databricks Output</div>';
        body += `<div class="sim-split-cell nifi-side">${columnarPreview(p.nifiOutput, 2)}</div>`;
        body += `<div class="sim-split-cell dbx-side">${p.verdict === 'SKIPPED' ? '<em style="color:var(--text2)">SKIPPED</em>' : columnarPreview(p.dbxOutput, 2)}</div>`;
        body += '</div>';
        const verdictParts = [];
        if (p.dataVerdict) verdictParts.push(`D:${p.dataVerdict}`);
        if (p.actionVerdict && hasVenv) verdictParts.push(`A:${p.actionVerdict}`);
        if (p.stateVerdict && hasVenv) verdictParts.push(`S:${p.stateVerdict}`);
        const title = `<span style="color:${roleColor}">[${p.role}]</span> <strong>${p.name}</strong> `
          + `<span style="color:var(--text2);font-size:0.72rem">(${p.type})</span> `
          + `<span class="conf-badge ${confCls}" style="margin-left:4px">${confStr}</span> `
          + `<span class="match-badge ${p.verdictClass}" style="margin-left:4px">${p.verdict}</span>`
          + (hasVenv && p.nifiActions ? ` <span style="font-size:0.68rem;color:var(--text2)">${p.nifiActions.length} actions</span>` : '');
        return expanderHTML(title, body, false);
      }).join(''),
      false
    );
  });
  h += '</div></details>';
  rDiv.innerHTML = h;
  setTabStatus('simulate', 'done');
  // Unlock Step 10
  document.getElementById('reportFinalNotReady').classList.add('hidden');
  document.getElementById('reportFinalReady').classList.remove('hidden');
  unlockTab('reportFinal');
}

// ================================================================
// STEP 10 — FINAL REPORT & JSON DOWNLOAD
// ================================================================

function buildFinalReportJSON() {
  const nifi = STATE.parsed._nifi;
  const sim = STATE.simulation;
  const meta = sim._meta || {};
  const mappings = STATE.notebook.mappings;
  const comparison = STATE.comparison;
  const validation = STATE.validation;
  // Pipeline summary
  const report = {
    report_type: 'NiFi_to_Databricks_Migration_Simulation',
    generated_at: new Date().toISOString(),
    version: '2.0',
    // Section 1: Input metadata
    input: {
      source_name: STATE.parsed.source_name || 'NiFi Flow',
      source_type: STATE.parsed.source_type || 'nifi',
      total_processors: nifi.processors.length,
      total_connections: nifi.connections.length,
      total_process_groups: nifi.processGroups.length,
      total_controller_services: nifi.controllerServices.length,
      process_groups: nifi.processGroups.map(g => ({
        name: g.name,
        parent: g.parentGroup,
        processor_count: nifi.processors.filter(p => p.group === g.name).length
      })),
      processor_type_distribution: (() => {
        const dist = {};
        nifi.processors.forEach(p => { dist[p.type] = (dist[p.type] || 0) + 1; });
        return Object.entries(dist).sort((a,b) => b[1]-a[1]).map(([type, count]) => ({type, count, role: classifyNiFiProcessor(type)}));
      })(),
      sql_table_references: nifi.sqlTables || [],
      controller_services: nifi.controllerServices.map(s => ({name: s.name, type: s.type, state: s.state}))
    },
    // Section 2: Step-by-step pipeline results
    pipeline_steps: {
      step1_parse: {
        status: 'complete',
        tables_discovered: STATE.parsed.tables.length,
        warnings: STATE.parsed.parse_warnings || []
      },
      step2_blueprint: {
        status: STATE.blueprint ? 'complete' : 'skipped',
        table_count: STATE.blueprint ? STATE.blueprint.tables.length : 0
      },
      step3_generate: {
        status: STATE.tables ? 'complete' : 'skipped',
        tables_generated: STATE.tables ? Object.keys(STATE.tables).length : 0,
        total_rows: STATE.tables ? Object.values(STATE.tables).reduce((s,t) => {
          const cols = Object.keys(t); return s + (cols.length && t[cols[0]] ? t[cols[0]].length : 0);
        }, 0) : 0
      },
      step4_conform: {
        status: STATE.medallion ? 'complete' : 'skipped',
        tiers: STATE.medallion ? Object.keys(STATE.medallion).length : 0
      },
      step5_validate: (() => {
        if (!validation) return { status: 'skipped', checks_passed: 0, checks_total: 0 };
        // validation is an array of per-table results
        const valArr = Array.isArray(validation) ? validation : [];
        const checksTotal = valArr.length * 4; // 4 dimensions per table
        let checksPassed = 0;
        valArr.forEach(v => {
          if (v.schema_score >= 0.7) checksPassed++;
          if (v.fidelity_score >= 0.7) checksPassed++;
          if (v.quality_score >= 0.7) checksPassed++;
          if (v.pipeline_score >= 0.7) checksPassed++;
        });
        const avg = valArr.length ? valArr.reduce((a,v) => a + v.overall_score, 0) / valArr.length : 0;
        return {
          status: 'complete',
          confidence_score: Math.round(avg * 100),
          grade: avg >= 0.9 ? 'GREEN' : avg >= 0.7 ? 'AMBER' : 'RED',
          checks_passed: checksPassed,
          checks_total: checksTotal
        };
      })(),
      step6_notebook: {
        status: STATE.notebook ? 'complete' : 'skipped',
        cells_generated: STATE.notebook ? STATE.notebook.cells.length : 0,
        workflow_tasks: STATE.notebook && STATE.notebook.workflow ? STATE.notebook.workflow.tasks.length : 0
      },
      step7_report: {
        status: STATE.migrationReport ? 'complete' : 'skipped'
      },
      step8_compare: {
        status: comparison ? 'complete' : 'skipped',
        exact_match_pct: comparison && comparison.exact ? comparison.exact.pct : null,
        functional_match_pct: comparison && comparison.functional ? comparison.functional.pct : null,
        actions_converted_pct: comparison && comparison.actions ? comparison.actions.pct : null
      },
      step9_simulate: {
        status: 'complete',
        processors_simulated: meta.processorCount || 0,
        groups_simulated: meta.groupCount || 0,
        nifi_executed: meta.nifiExecuted || 0,
        dbx_executed: meta.dbxExecuted || 0,
        dbx_skipped: meta.dbxSkipped || 0,
        row_match_pct: sim.rowMatchPct,
        schema_match_pct: sim.schemaMatchPct,
        data_fidelity_pct: sim.fidelityPct,
        action_coverage_pct: sim.actionCoveragePct || 0,
        state_fidelity_pct: sim.stateFidelityPct || 0,
        functional_equiv_pct: sim.functionalEquivPct || 0,
        nifi_actions: meta.nifiActions || 0,
        dbx_actions: meta.dbxActions || 0,
        has_virtual_env: meta.hasVirtualEnv || false,
        verdicts: sim.summary
      }
    },
    // Section 3: Per-processor detail
    processors: sim.perProc.map((p, i) => ({
      index: p.idx,
      name: p.name,
      type: p.type,
      group: p.group,
      role: p.role,
      mapped: p.mapped,
      confidence: p.confidence,
      category: mappings[p.idx] ? mappings[p.idx].category : null,
      code_snippet: mappings[p.idx] ? mappings[p.idx].code.substring(0, 200) : null,
      simulation: {
        verdict: p.verdict,
        data_verdict: p.dataVerdict || p.verdict,
        action_verdict: p.actionVerdict || null,
        state_verdict: p.stateVerdict || null,
        nifi_rows: p.nifiRows,
        nifi_cols: p.nifiCols,
        dbx_rows: p.dbxRows,
        dbx_cols: p.dbxCols,
        row_match: p.rowMatch,
        schema_match: p.schemaMatch,
        data_fidelity: p.dataFidelity,
        action_coverage: p.actions ? p.actions.coverage : null,
        action_count_nifi: p.actions ? p.actions.nifi.length : 0,
        action_count_dbx: p.actions ? p.actions.dbx.length : 0,
        state_fidelity: p.stateDiff ? p.stateDiff.overall : null,
        details: p.details
      },
      actions: p.nifiActions ? p.nifiActions.map(a => ({ action: a.action, target: a.target })) : []
    })),
    // Section 4: Gap analysis
    gaps: {
      unmapped_processors: sim.perProc.filter(p => !p.mapped).map(p => ({
        name: p.name, type: p.type, group: p.group, role: p.role
      })),
      low_confidence: sim.perProc.filter(p => p.mapped && p.confidence < 0.5).map(p => ({
        name: p.name, type: p.type, group: p.group, confidence: p.confidence, verdict: p.verdict
      })),
      data_mismatches: sim.perProc.filter(p => p.verdict === 'DIFFERS').map(p => ({
        name: p.name, type: p.type, group: p.group, confidence: p.confidence,
        row_match: p.rowMatch, schema_match: p.schemaMatch, data_fidelity: p.dataFidelity, details: p.details
      })),
      zero_data_processors: sim.perProc.filter(p => p.nifiRows === 0 && p.dbxRows === 0).map(p => ({
        name: p.name, type: p.type, group: p.group
      })),
      // --- Enhanced gap categories (manifest + simulation-driven) ---
      missing_resources: (() => {
        if (!STATE.manifest) return [];
        const m = STATE.manifest, missing = [];
        const nEnv = sim._nifiEnv;
        if (nEnv) {
          Object.entries(m.directories).forEach(([dir, info]) => {
            if (info.type === 'input' && !Object.keys(nEnv.filesystem).some(f => f.startsWith(dir)))
              missing.push({ resource: dir, type: 'directory', direction: 'input', processors: info.processors.join(', ') });
          });
          Object.keys(m.sqlTables).forEach(tn => {
            if (!nEnv.sqlTables[tn]) missing.push({ resource: tn, type: 'sql_table', direction: (m.sqlTables[tn].readers.length ? 'read' : 'write'), processors: [...m.sqlTables[tn].readers, ...m.sqlTables[tn].writers].join(', ') });
          });
        }
        return missing;
      })(),
      resource_conflicts: (() => {
        const conflicts = [];
        const nEnv = sim._nifiEnv;
        if (nEnv) {
          const writers = {};
          nEnv.log.filter(e => ['FILE_WRITE','SQL_INSERT','SQL_CREATE'].includes(e.action)).forEach(e => {
            const k = e.target || e.path || 'unknown';
            if (!writers[k]) writers[k] = new Set();
            writers[k].add(e.processor);
          });
          Object.entries(writers).forEach(([target, procs]) => {
            if (procs.size > 1) conflicts.push({ target, type: target.includes('.') && !target.includes('/') ? 'sql_table' : 'file', writers: [...procs] });
          });
        }
        return conflicts;
      })(),
      orphaned_resources: (() => {
        if (!STATE.manifest) return [];
        const orphaned = [];
        const nEnv = sim._nifiEnv;
        if (nEnv) {
          const touched = new Set();
          nEnv.log.forEach(e => { if (e.target) touched.add(e.target); if (e.path) touched.add(e.path); });
          Object.keys(nEnv.filesystem).forEach(f => {
            if (!touched.has(f) && f.includes('/data_')) orphaned.push({ resource: f, type: 'file' });
          });
          Object.keys(nEnv.sqlTables).forEach(t => {
            if (!touched.has(t)) orphaned.push({ resource: t, type: 'sql_table' });
          });
        }
        return orphaned;
      })(),
      unresolved_expressions: (() => {
        if (!STATE.manifest) return [];
        return STATE.manifest.parameters.filter(p => !p.resolved).map(p => ({
          expression: p.expr, processor: p.processor
        }));
      })(),
      disconnected_processors: (() => {
        if (!STATE.manifest) return [];
        return STATE.manifest.disconnectedProcessors || [];
      })(),
      failed_operations: (() => {
        const failed = [];
        const nEnv = sim._nifiEnv, dEnv = sim._dbxEnv;
        if (nEnv) nEnv.log.filter(e => e.status === 'error' || e.error).forEach(e => failed.push({ engine: 'nifi', processor: e.processor, action: e.action, target: e.target || e.path, error: e.error || 'operation failed' }));
        if (dEnv) dEnv.log.filter(e => e.status === 'error' || e.error).forEach(e => failed.push({ engine: 'dbx', processor: e.processor, action: e.action, target: e.target || e.path, error: e.error || 'operation failed' }));
        return failed;
      })(),
      schema_mismatches: (() => {
        const mismatches = [];
        const nEnv = sim._nifiEnv;
        if (nEnv && STATE.parsed && STATE.parsed._nifi) {
          const nifi = STATE.parsed._nifi;
          const connMap = {};
          (nifi.connections || []).forEach(c => { connMap[c.destination] = c.source; });
          sim.perProc.forEach(p => {
            if (p.verdict === 'DIFFERS' && p.schemaMatch < 100) {
              mismatches.push({ processor: p.name, type: p.type, group: p.group, schema_match: p.schemaMatch, details: p.details || 'Column mismatch between source output and sink input' });
            }
          });
        }
        return mismatches;
      })()
    },
    // Section 5: Errors
    errors: {
      nifi_engine: (meta.nifiErrors || []).map(e => ({processor_index: e.idx, name: e.name, error: e.error})),
      dbx_engine: (meta.dbxErrors || []).map(e => ({processor_index: e.idx, name: e.name, error: e.error}))
    },
    // Section 6: Recommendations
    recommendations: (() => {
      const recs = [];
      const unmapped = sim.perProc.filter(p => !p.mapped);
      if (unmapped.length) recs.push({severity:'high', area:'mapping', message:`${unmapped.length} processors have no Databricks mapping — manual migration required`, types:[...new Set(unmapped.map(p=>p.type))]});
      const lowConf = sim.perProc.filter(p => p.mapped && p.confidence < 0.5);
      if (lowConf.length) recs.push({severity:'medium', area:'confidence', message:`${lowConf.length} processors have <50% confidence — review generated code`, types:[...new Set(lowConf.map(p=>p.type))]});
      const differs = sim.perProc.filter(p => p.verdict === 'DIFFERS');
      if (differs.length) recs.push({severity:'high', area:'simulation', message:`${differs.length} processors produce different outputs between NiFi and Databricks`, types:[...new Set(differs.map(p=>p.type))]});
      if (sim.fidelityPct < 80) recs.push({severity:'high', area:'fidelity', message:`Overall data fidelity is ${sim.fidelityPct}% — significant differences in data transformation`});
      if (sim.fidelityPct >= 80 && sim.fidelityPct < 95) recs.push({severity:'medium', area:'fidelity', message:`Data fidelity is ${sim.fidelityPct}% — minor differences, likely from metadata columns added by Databricks`});
      if (sim.fidelityPct >= 95) recs.push({severity:'info', area:'fidelity', message:`Data fidelity is ${sim.fidelityPct}% — migration produces nearly identical results`});
      // Action-based recommendations
      if (sim.actionCoveragePct && sim.actionCoveragePct < 80) recs.push({severity:'medium', area:'actions', message:`Action coverage is ${sim.actionCoveragePct}% — some NiFi operations have no Databricks equivalent`});
      if (sim.stateFidelityPct && sim.stateFidelityPct < 80) recs.push({severity:'medium', area:'state', message:`State fidelity is ${sim.stateFidelityPct}% — file/SQL/token operations differ between engines`});
      const actionDiffers = sim.perProc.filter(p => p.actionVerdict === 'DIFFERS');
      if (actionDiffers.length) recs.push({severity:'high', area:'actions', message:`${actionDiffers.length} processors have different action patterns — review file I/O and SQL operations`, types:[...new Set(actionDiffers.map(p=>p.type))]});
      // Resource & manifest-driven recommendations
      if (STATE.manifest) {
        const m = STATE.manifest;
        const unresolvedCount = m.parameters.filter(p => !p.resolved).length;
        if (unresolvedCount) recs.push({severity:'high', area:'parameters', message:`${unresolvedCount} unresolved \${} expressions — configure these parameters before deployment`});
        const disconnected = m.disconnectedProcessors || [];
        if (disconnected.length) recs.push({severity:'medium', area:'connectivity', message:`${disconnected.length} processors have no connections — they will never execute, verify intent`});
        const nEnv = sim._nifiEnv;
        if (nEnv) {
          // Orphaned resources
          const touched = new Set();
          nEnv.log.forEach(e => { if (e.target) touched.add(e.target); if (e.path) touched.add(e.path); });
          const orphanedFiles = Object.keys(nEnv.filesystem).filter(f => !touched.has(f) && f.includes('/data_')).length;
          const orphanedTables = Object.keys(nEnv.sqlTables).filter(t => !touched.has(t)).length;
          const totalOrphaned = orphanedFiles + orphanedTables;
          if (totalOrphaned) recs.push({severity:'low', area:'resources', message:`${totalOrphaned} seeded resources were never accessed — they may be unnecessary, verify`});
          // Conflicts
          const writers = {};
          nEnv.log.filter(e => ['FILE_WRITE','SQL_INSERT','SQL_CREATE'].includes(e.action)).forEach(e => {
            const k = e.target || e.path || 'unknown';
            if (!writers[k]) writers[k] = new Set();
            writers[k].add(e.processor);
          });
          const conflictCount = Object.values(writers).filter(s => s.size > 1).length;
          if (conflictCount) recs.push({severity:'medium', area:'conflicts', message:`${conflictCount} resources have multiple writers — add locking or sequence these processors`});
          // Failed ops
          const failedOps = nEnv.log.filter(e => e.status === 'error' || e.error).length;
          if (failedOps) recs.push({severity:'high', area:'operations', message:`${failedOps} operations failed during NiFi simulation — review processor configurations`});
        }
      }
      return recs;
    })(),
    // Section 7: VirtualEnv analysis
    virtual_environment: (() => {
      if (!meta.hasVirtualEnv || !sim.envSummary) return null;
      return {
        nifi_engine: sim.envSummary.nifi,
        dbx_engine: sim.envSummary.dbx,
        action_log_summary: (() => {
          const nEnv = sim._nifiEnv, dEnv = sim._dbxEnv;
          if (!nEnv || !dEnv) return null;
          const nTypes = {}, dTypes = {};
          nEnv.log.forEach(e => { nTypes[e.action] = (nTypes[e.action] || 0) + 1; });
          dEnv.log.forEach(e => { dTypes[e.action] = (dTypes[e.action] || 0) + 1; });
          return { nifi_action_types: nTypes, dbx_action_types: dTypes };
        })()
      };
    })()
  };
  return report;
}

async function generateFinalReport() {
  if (!STATE.simulation || !STATE.parsed || !STATE.parsed._nifi) return;
  setTabStatus('reportFinal', 'processing');
  const rDiv = document.getElementById('reportFinalResults');
  // Progress bar UI
  rDiv.innerHTML = '<div class="sim-progress" id="rptProgressBox">'
    + '<div class="sim-status"><span class="engine-label sim-running" id="rptEngineLabel">Initializing report...</span><span id="rptPctLabel">0%</span></div>'
    + '<div class="sim-progress-bar"><div class="sim-progress-fill" id="rptFill" style="width:0%"></div></div>'
    + '<div id="rptStepLabel" style="font-size:0.78rem;color:var(--text2);margin-top:4px"></div>'
    + '</div>';
  const fill = document.getElementById('rptFill');
  const pctL = document.getElementById('rptPctLabel');
  const stepL = document.getElementById('rptStepLabel');
  const engL = document.getElementById('rptEngineLabel');
  async function prog(pct, label) {
    fill.style.width = pct + '%'; pctL.textContent = pct + '%'; stepL.textContent = label;
    if (engL.textContent === 'Initializing report...') engL.textContent = 'Generating final report...';
    await new Promise(r => setTimeout(r, 60));
  }
  try {
    await prog(5, 'Collecting pipeline metadata...');
    const report = buildFinalReportJSON();
    STATE.finalReport = report;
    await prog(20, 'Building summary donuts...');
    const sim = STATE.simulation;
    const gaps = report.gaps;
    const recs = report.recommendations;
    let h = '<hr class="divider">';
    // Overview donuts
    h += '<div class="sim-donuts">';
    h += donutSVG(sim.rowMatchPct, 'Row Match', `${sim.summary.total} processors`);
    h += donutSVG(sim.schemaMatchPct, 'Schema Match', `columns aligned`);
    h += donutSVG(sim.fidelityPct, 'Data Fidelity', `cell accuracy`);
    const mappedPct = sim.summary.total ? Math.round((sim.summary.total - sim.summary.skipped) / sim.summary.total * 100) : 0;
    h += donutSVG(mappedPct, 'Mapped', `${sim.summary.total - sim.summary.skipped}/${sim.summary.total}`);
    h += '</div>';
    await prog(30, 'Rendering pipeline metrics...');
    // Pipeline summary
    h += metricsHTML([
      ['Processors', report.input.total_processors],
      ['Connections', report.input.total_connections],
      ['Groups', report.input.total_process_groups],
      ['Steps', '10/10'],
      ['Verdict', sim.fidelityPct >= 90 ? '<span style="color:#21C354">PASS</span>' : sim.fidelityPct >= 70 ? '<span style="color:#EAB308">REVIEW</span>' : '<span style="color:#EF4444">FAIL</span>']
    ]);
    await prog(40, 'Generating recommendations...');
    // Recommendations
    if (recs.length) {
      h += '<hr class="divider">';
      h += '<h3 style="margin:12px 0 8px">Recommendations</h3>';
      recs.forEach(r => {
        const icon = r.severity === 'high' ? '&#9888;' : r.severity === 'medium' ? '&#9432;' : '&#10003;';
        const color = r.severity === 'high' ? '#EF4444' : r.severity === 'medium' ? '#EAB308' : '#21C354';
        h += `<div style="padding:8px 12px;margin:4px 0;border-left:3px solid ${color};background:var(--surface);border-radius:4px;font-size:0.82rem">`;
        h += `<span style="color:${color}">${icon}</span> <strong>${r.area.toUpperCase()}</strong>: ${r.message}`;
        if (r.types && r.types.length) h += `<br><span style="color:var(--text2);font-size:0.75rem">Types: ${r.types.join(', ')}</span>`;
        h += '</div>';
      });
    }
    await prog(55, 'Analyzing gaps...');
    // Gap Analysis
    h += '<hr class="divider">';
    h += '<h3 style="margin:12px 0 8px">Gap Analysis</h3>';
    h += metricsHTML([
      ['Unmapped', `<span style="color:${gaps.unmapped_processors.length ? '#EF4444':'#21C354'}">${gaps.unmapped_processors.length}</span>`],
      ['Low Conf (<50%)', `<span style="color:${gaps.low_confidence.length ? '#EAB308':'#21C354'}">${gaps.low_confidence.length}</span>`],
      ['Data Mismatches', `<span style="color:${gaps.data_mismatches.length ? '#EF4444':'#21C354'}">${gaps.data_mismatches.length}</span>`],
      ['Zero Data', `<span style="color:${gaps.zero_data_processors.length ? '#808495':'#21C354'}">${gaps.zero_data_processors.length}</span>`]
    ]);
    // Enhanced gap metrics row
    const enhancedGapCount = (gaps.missing_resources||[]).length + (gaps.resource_conflicts||[]).length + (gaps.orphaned_resources||[]).length + (gaps.unresolved_expressions||[]).length + (gaps.disconnected_processors||[]).length + (gaps.failed_operations||[]).length + (gaps.schema_mismatches||[]).length;
    if (enhancedGapCount > 0) {
      h += '<div style="margin:8px 0 4px;font-size:0.78rem;color:var(--text2);font-weight:600">Resource & Connectivity Gaps</div>';
      h += metricsHTML([
        ['Missing Resources', `<span style="color:${(gaps.missing_resources||[]).length ? '#EF4444':'#21C354'}">${(gaps.missing_resources||[]).length}</span>`],
        ['Conflicts', `<span style="color:${(gaps.resource_conflicts||[]).length ? '#EAB308':'#21C354'}">${(gaps.resource_conflicts||[]).length}</span>`],
        ['Orphaned', `<span style="color:${(gaps.orphaned_resources||[]).length ? '#FACA15':'#21C354'}">${(gaps.orphaned_resources||[]).length}</span>`],
        ['Unresolved Expr', `<span style="color:${(gaps.unresolved_expressions||[]).length ? '#EF4444':'#21C354'}">${(gaps.unresolved_expressions||[]).length}</span>`],
        ['Disconnected', `<span style="color:${(gaps.disconnected_processors||[]).length ? '#EAB308':'#21C354'}">${(gaps.disconnected_processors||[]).length}</span>`],
        ['Failed Ops', `<span style="color:${(gaps.failed_operations||[]).length ? '#EF4444':'#21C354'}">${(gaps.failed_operations||[]).length}</span>`],
        ['Schema Gaps', `<span style="color:${(gaps.schema_mismatches||[]).length ? '#EF4444':'#21C354'}">${(gaps.schema_mismatches||[]).length}</span>`]
      ]);
    }
    if (gaps.unmapped_processors.length) {
      h += expanderHTML(`Unmapped Processors (${gaps.unmapped_processors.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Name</th><th>Type</th><th>Group</th><th>Role</th></tr></thead><tbody>'
        + gaps.unmapped_processors.map(p => `<tr><td>${p.name}</td><td>${p.type}</td><td>${p.group}</td><td>${p.role}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    if (gaps.data_mismatches.length) {
      h += expanderHTML(`Data Mismatches (${gaps.data_mismatches.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Name</th><th>Type</th><th>Group</th><th>Conf</th><th>Rows%</th><th>Schema%</th><th>Fidelity%</th><th>Details</th></tr></thead><tbody>'
        + gaps.data_mismatches.map(p => `<tr><td>${p.name}</td><td>${p.type}</td><td>${p.group}</td><td>${Math.round(p.confidence*100)}%</td><td>${p.row_match}%</td><td>${p.schema_match}%</td><td>${p.data_fidelity}%</td><td style="font-size:0.72rem">${p.details}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    // Enhanced gap expanders
    if ((gaps.missing_resources||[]).length) {
      h += expanderHTML(`Missing Resources (${gaps.missing_resources.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Resource</th><th>Type</th><th>Direction</th><th>Processors</th></tr></thead><tbody>'
        + gaps.missing_resources.map(r => `<tr><td><span class="resource-dot missing"></span>${escapeHTML(r.resource)}</td><td>${r.type}</td><td>${r.direction}</td><td>${escapeHTML(r.processors)}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    if ((gaps.resource_conflicts||[]).length) {
      h += expanderHTML(`Resource Conflicts (${gaps.resource_conflicts.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Target</th><th>Type</th><th>Conflicting Writers</th></tr></thead><tbody>'
        + gaps.resource_conflicts.map(c => `<tr><td><span class="resource-dot missing"></span>${escapeHTML(c.target)}</td><td>${c.type}</td><td>${escapeHTML(c.writers.join(', '))}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    if ((gaps.orphaned_resources||[]).length) {
      h += expanderHTML(`Orphaned Resources (${gaps.orphaned_resources.length})`,
        '<div style="font-size:0.78rem">'
        + gaps.orphaned_resources.map(r => `<div style="margin:2px 0"><span class="resource-dot orphaned"></span>${escapeHTML(r.resource)} <span style="color:var(--text2)">(${r.type})</span></div>`).join('')
        + '</div>', false);
    }
    if ((gaps.unresolved_expressions||[]).length) {
      h += expanderHTML(`Unresolved Expressions (${gaps.unresolved_expressions.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Expression</th><th>Processor</th></tr></thead><tbody>'
        + gaps.unresolved_expressions.map(e => `<tr><td><code style="color:#EF4444">${escapeHTML(e.expression)}</code></td><td>${escapeHTML(e.processor)}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    if ((gaps.disconnected_processors||[]).length) {
      h += expanderHTML(`Disconnected Processors (${gaps.disconnected_processors.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Processor</th><th>Type</th><th>Issue</th></tr></thead><tbody>'
        + gaps.disconnected_processors.map(d => `<tr><td>${escapeHTML(d.name)}</td><td>${escapeHTML(d.type)}</td><td>${d.noInbound && d.noOutbound ? 'No connections' : d.noInbound ? 'No inbound' : 'No outbound'}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    if ((gaps.failed_operations||[]).length) {
      h += expanderHTML(`Failed Operations (${gaps.failed_operations.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Engine</th><th>Processor</th><th>Action</th><th>Target</th><th>Error</th></tr></thead><tbody>'
        + gaps.failed_operations.map(f => `<tr><td>${f.engine.toUpperCase()}</td><td>${escapeHTML(f.processor)}</td><td>${f.action}</td><td>${escapeHTML(f.target||'')}</td><td style="color:#EF4444;font-size:0.72rem">${escapeHTML(f.error)}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    if ((gaps.schema_mismatches||[]).length) {
      h += expanderHTML(`Schema Mismatches (${gaps.schema_mismatches.length})`,
        '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Processor</th><th>Type</th><th>Group</th><th>Schema%</th><th>Details</th></tr></thead><tbody>'
        + gaps.schema_mismatches.map(s => `<tr><td>${escapeHTML(s.processor)}</td><td>${escapeHTML(s.type)}</td><td>${escapeHTML(s.group)}</td><td>${s.schema_match}%</td><td style="font-size:0.72rem">${escapeHTML(s.details)}</td></tr>`).join('')
        + '</tbody></table></div>', false);
    }
    await prog(70, 'Compiling error log...');
    // Errors
    const totalErrors = (report.errors.nifi_engine.length + report.errors.dbx_engine.length);
    if (totalErrors) {
      h += '<hr class="divider">';
      h += expanderHTML(`Simulation Errors (${totalErrors})`,
        '<div style="font-size:0.78rem">'
        + report.errors.nifi_engine.map(e => `<div style="margin:2px 0;color:#728E9B">[NiFi] #${e.processor_index} ${e.name}: ${e.error}</div>`).join('')
        + report.errors.dbx_engine.map(e => `<div style="margin:2px 0;color:var(--primary)">[DBX] #${e.processor_index} ${e.name}: ${e.error}</div>`).join('')
        + '</div>', false);
    }
    await prog(80, 'Building processor type coverage...');
    // Processor type coverage
    h += '<hr class="divider">';
    const typeDist = report.input.processor_type_distribution;
    h += expanderHTML(`Processor Type Distribution (${typeDist.length} types, ${report.input.total_processors} total)`,
      '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Type</th><th>Count</th><th>Role</th><th>Mapped</th></tr></thead><tbody>'
      + typeDist.map(t => {
        const hasMapped = !!NIFI_DATABRICKS_MAP[t.type];
        return `<tr><td>${t.type}</td><td>${t.count}</td><td>${t.role}</td><td style="color:${hasMapped?'#21C354':'#EF4444'}">${hasMapped?'Yes':'No'}</td></tr>`;
      }).join('')
      + '</tbody></table></div>', false);
    await prog(90, 'Building process group summary...');
    // Per-group summary
    h += expanderHTML(`Process Group Summary (${report.input.process_groups.length} groups)`,
      '<div class="table-scroll"><table style="font-size:0.78rem"><thead><tr><th>Group</th><th>Parent</th><th>Processors</th><th>Identical</th><th>Equiv</th><th>Differs</th><th>Skipped</th></tr></thead><tbody>'
      + report.input.process_groups.map(g => {
        const gProcs = sim.perProc.filter(p => p.group === g.name);
        return `<tr><td>${g.name}</td><td>${g.parent}</td><td>${g.processor_count}</td>`
          + `<td style="color:#21C354">${gProcs.filter(p=>p.verdict==='IDENTICAL').length}</td>`
          + `<td style="color:#EAB308">${gProcs.filter(p=>p.verdict==='EQUIVALENT').length}</td>`
          + `<td style="color:#EF4444">${gProcs.filter(p=>p.verdict==='DIFFERS').length}</td>`
          + `<td style="color:#808495">${gProcs.filter(p=>p.verdict==='SKIPPED').length}</td></tr>`;
      }).join('')
      + '</tbody></table></div>', false);
    await prog(95, 'Preparing downloads...');
    // Download buttons
    h += '<hr class="divider">';
    h += '<div style="display:flex;gap:12px;flex-wrap:wrap;margin:16px 0">';
    h += '<button class="btn btn-primary" onclick="downloadFinalReport(\'json\')">Download Full Report (JSON)</button>';
    h += '<button class="btn" onclick="downloadFinalReport(\'summary\')">Download Summary (JSON)</button>';
    h += '<button class="btn" onclick="downloadFinalReport(\'gaps\')">Download Gap Analysis (JSON)</button>';
    h += '</div>';
    h += '<div style="font-size:0.75rem;color:var(--text2);margin-top:4px">Full report includes all per-processor simulation data for external analysis</div>';
    await prog(100, 'Report complete');
    engL.textContent = 'Final report generated'; engL.classList.remove('sim-running');
    await new Promise(r => setTimeout(r, 300));
    rDiv.innerHTML = h;
    setTabStatus('reportFinal', 'done');
  } catch(e) {
    rDiv.innerHTML = '<div class="alert" style="border-left:3px solid #EF4444;padding:12px;margin:12px 0"><strong>Report generation error:</strong> ' + escapeHTML(e.message) + '<br><pre style="font-size:0.72rem;margin-top:8px;white-space:pre-wrap">' + escapeHTML(e.stack || '') + '</pre></div>';
    setTabStatus('reportFinal', 'ready');
  }
}

function sanitizeReportJSON(obj) {
  // Deep-clone and strip sensitive NiFi properties from exported reports
  if (obj === null || obj === undefined) return obj;
  if (Array.isArray(obj)) return obj.map(sanitizeReportJSON);
  if (typeof obj !== 'object') return obj;
  const out = {};
  for (const [k, v] of Object.entries(obj)) {
    if (SENSITIVE_PROP_RE.test(k) && typeof v === 'string') { out[k] = '********'; continue; }
    if (k === 'properties' && typeof v === 'object' && v !== null) {
      out[k] = {};
      for (const [pk, pv] of Object.entries(v)) { out[k][pk] = isSensitiveProp(pk) ? '********' : pv; }
      continue;
    }
    out[k] = sanitizeReportJSON(v);
  }
  return out;
}

function downloadFinalReport(type) {
  if (!STATE.finalReport) return;
  let data, filename;
  if (type === 'summary') {
    const r = STATE.finalReport;
    data = {
      report_type: r.report_type, generated_at: r.generated_at,
      input_summary: { processors: r.input.total_processors, connections: r.input.total_connections, groups: r.input.total_process_groups },
      pipeline_steps: r.pipeline_steps,
      simulation_results: r.pipeline_steps.step9_simulate,
      gap_summary: {
        unmapped: r.gaps.unmapped_processors.length,
        low_confidence: r.gaps.low_confidence.length,
        data_mismatches: r.gaps.data_mismatches.length,
        zero_data: r.gaps.zero_data_processors.length,
        missing_resources: (r.gaps.missing_resources||[]).length,
        resource_conflicts: (r.gaps.resource_conflicts||[]).length,
        orphaned_resources: (r.gaps.orphaned_resources||[]).length,
        unresolved_expressions: (r.gaps.unresolved_expressions||[]).length,
        disconnected_processors: (r.gaps.disconnected_processors||[]).length,
        failed_operations: (r.gaps.failed_operations||[]).length,
        schema_mismatches: (r.gaps.schema_mismatches||[]).length
      },
      recommendations: r.recommendations
    };
    filename = 'migration_summary.json';
  } else if (type === 'gaps') {
    data = { generated_at: STATE.finalReport.generated_at, gaps: STATE.finalReport.gaps, recommendations: STATE.finalReport.recommendations };
    filename = 'migration_gaps.json';
  } else {
    data = STATE.finalReport;
    filename = 'migration_full_report.json';
  }
  // Strip credentials before export
  data = sanitizeReportJSON(data);
  const blob = new Blob([JSON.stringify(data, null, 2)], {type: 'application/json'});
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url; a.download = filename; a.click();
  URL.revokeObjectURL(url);
}

// ================================================================
// TIER DIAGRAM — Progressive Updates
// ================================================================
function updateTierDiagramBadges(tables) {
  const container = document.getElementById('tierDiagram');
  if (!container) return;
  container.querySelectorAll('.tier-node').forEach(el => {
    const nodeId = el.dataset.nodeId;
    if (!nodeId) return;
    // Find matching table data
    const name = nodeId.split('_')[0] || nodeId;
    for (const [tn, data] of Object.entries(tables)) {
      if (nodeId === tn || nodeId.startsWith(tn)) {
        const cols = Object.keys(data);
        const rc = data[cols[0]] ? data[cols[0]].length : 0;
        let badge = el.querySelector('.node-badge');
        if (!badge) { badge = document.createElement('div'); badge.className = 'node-badge'; el.appendChild(badge); }
        badge.textContent = rc >= 1000 ? Math.round(rc/1000) + 'K' : rc;
        badge.classList.add('green');
        break;
      }
    }
  });
}

function addMedallionTiers() {
  const container = document.getElementById('tierDiagram');
  if (!container) return;
  // Add medallion tier bands
  const medallionTiers = [
    {label:'BRONZE — Raw Ingestion', color:'#CD7F32', bg:'rgba(205,127,50,0.08)'},
    {label:'SILVER — Cleansed & Deduped', color:'#C0C0C0', bg:'rgba(192,192,192,0.08)'},
    {label:'GOLD — Aggregated & Profiled', color:'#FFD700', bg:'rgba(255,215,0,0.08)'},
  ];
  medallionTiers.forEach((tier, i) => {
    const band = document.createElement('div');
    band.className = 'tier-band';
    band.style.background = tier.bg;
    band.style.borderLeft = `3px solid ${tier.color}`;
    const label = document.createElement('div');
    label.className = 'tier-band-label';
    label.style.color = tier.color;
    label.textContent = tier.label;
    band.appendChild(label);
    const nodesDiv = document.createElement('div');
    nodesDiv.className = 'tier-nodes';
    // Add a flow arrow node
    const arrow = document.createElement('div');
    arrow.className = 'tier-node';
    arrow.style.borderTopWidth = '3px';
    arrow.style.borderTopColor = tier.color;
    arrow.style.minWidth = '80px';
    arrow.innerHTML = `<div class="node-name" style="font-size:1.2rem">${i===0?'&#x2B07;':i===1?'&#x2B07;':'&#x2705;'}</div><div class="node-meta">${['Raw data loaded','Cleaned & validated','Ready for analytics'][i]}</div>`;
    nodesDiv.appendChild(arrow);
    band.appendChild(nodesDiv);
    container.appendChild(band);
  });
  // Add connections between medallion tiers
  requestAnimationFrame(() => renderConnections(container, [], {}));
}

function addValidationTier(val, avg) {
  const container = document.getElementById('tierDiagram');
  if (!container) return;
  const color = avg >= 0.9 ? '#21C354' : avg >= 0.7 ? '#FACA15' : '#FF4B4B';
  const level = avg >= 0.9 ? 'GREEN' : avg >= 0.7 ? 'AMBER' : 'RED';
  const band = document.createElement('div');
  band.className = 'tier-band';
  band.style.background = avg >= 0.9 ? 'rgba(33,195,84,0.08)' : avg >= 0.7 ? 'rgba(250,202,21,0.08)' : 'rgba(255,75,75,0.08)';
  band.style.borderLeft = `3px solid ${color}`;
  const label = document.createElement('div');
  label.className = 'tier-band-label';
  label.style.color = color;
  label.textContent = `VALIDATION — ${level} ${Math.round(avg*100)}%`;
  band.appendChild(label);
  const nodesDiv = document.createElement('div');
  nodesDiv.className = 'tier-nodes';
  // Per-table validation nodes
  val.forEach(v => {
    const el = document.createElement('div');
    el.className = 'tier-node';
    const nc = v.overall_score >= 0.9 ? '#21C354' : v.overall_score >= 0.7 ? '#FACA15' : '#FF4B4B';
    el.style.borderTopWidth = '3px';
    el.style.borderTopColor = nc;
    el.innerHTML = `<div class="node-name">${escapeHTML(v.table)}</div><div class="node-meta">${Math.round(v.overall_score*100)}%</div>`;
    const badge = document.createElement('div');
    badge.className = 'node-badge ' + (v.overall_score >= 0.9 ? 'green' : v.overall_score >= 0.7 ? 'amber' : '');
    badge.textContent = v.overall_score >= 0.9 ? '✓' : v.overall_score >= 0.7 ? '!' : '✗';
    el.appendChild(badge);
    nodesDiv.appendChild(el);
  });
  band.appendChild(nodesDiv);
  container.appendChild(band);
  // Color existing nodes by health
  container.querySelectorAll('.tier-node[data-node-id]').forEach(el => {
    const nodeId = el.dataset.nodeId;
    const vResult = val.find(v => nodeId === v.table || nodeId.startsWith(v.table));
    if (vResult) {
      const sc = vResult.overall_score;
      el.style.borderColor = sc >= 0.9 ? '#21C354' : sc >= 0.7 ? '#FACA15' : '#FF4B4B';
    }
  });
}

// Initialize config form from localStorage
(function initDbxConfig() {
  const cfg = loadDbxConfig();
  const fields = {cfgCatalog:'catalog',cfgSchema:'schema',cfgScope:'secretScope',cfgCloud:'cloudProvider',cfgSparkVersion:'sparkVersion',cfgNodeType:'nodeType',cfgWorkers:'numWorkers',cfgWorkspacePath:'workspacePath'};
  Object.entries(fields).forEach(([id, key]) => {
    const el = document.getElementById(id);
    if (el && cfg[key]) el.value = cfg[key];
  });
})();
</script>
</body>
</html>
